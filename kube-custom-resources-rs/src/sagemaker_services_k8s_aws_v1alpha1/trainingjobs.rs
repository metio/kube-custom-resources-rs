// WARNING: generated by kopium - manual changes will be overwritten
// kopium command: kopium --auto --filename ./crd-catalog/aws-controllers-k8s/sagemaker-controller/sagemaker.services.k8s.aws/v1alpha1/trainingjobs.yaml
// kopium version: 0.16.1

use kube::CustomResource;
use schemars::JsonSchema;
use serde::{Serialize, Deserialize};
use std::collections::BTreeMap;

/// TrainingJobSpec defines the desired state of TrainingJob. 
///  Contains information about a training job.
#[derive(CustomResource, Serialize, Deserialize, Clone, Debug, JsonSchema)]
#[kube(group = "sagemaker.services.k8s.aws", version = "v1alpha1", kind = "TrainingJob", plural = "trainingjobs")]
#[kube(namespaced)]
#[kube(status = "TrainingJobStatus")]
pub struct TrainingJobSpec {
    /// The registry path of the Docker image that contains the training algorithm and algorithm-specific metadata, including the input mode. For more information about algorithms provided by SageMaker, see Algorithms (https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html). For information about providing your own algorithms, see Using Your Own Algorithms with Amazon SageMaker (https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html).
    #[serde(rename = "algorithmSpecification")]
    pub algorithm_specification: TrainingJobAlgorithmSpecification,
    /// Contains information about the output location for managed spot training checkpoint data.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "checkpointConfig")]
    pub checkpoint_config: Option<TrainingJobCheckpointConfig>,
    /// Configuration information for the Amazon SageMaker Debugger hook parameters, metric and tensor collections, and storage paths. To learn more about how to configure the DebugHookConfig parameter, see Use the SageMaker and Debugger Configuration API Operations to Create, Update, and Debug Your Training Job (https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-createtrainingjob-api.html).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "debugHookConfig")]
    pub debug_hook_config: Option<TrainingJobDebugHookConfig>,
    /// Configuration information for Amazon SageMaker Debugger rules for debugging output tensors.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "debugRuleConfigurations")]
    pub debug_rule_configurations: Option<Vec<TrainingJobDebugRuleConfigurations>>,
    /// To encrypt all communications between ML compute instances in distributed training, choose True. Encryption provides greater security for distributed training, but training might take longer. How long it takes depends on the amount of communication between compute instances, especially if you use a deep learning algorithm in distributed training. For more information, see Protect Communications Between ML Compute Instances in a Distributed Training Job (https://docs.aws.amazon.com/sagemaker/latest/dg/train-encrypt.html).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableInterContainerTrafficEncryption")]
    pub enable_inter_container_traffic_encryption: Option<bool>,
    /// To train models using managed spot training, choose True. Managed spot training provides a fully managed and scalable infrastructure for training machine learning models. this option is useful when training jobs can be interrupted and when there is flexibility when the training job is run. 
    ///  The complete and intermediate results of jobs are stored in an Amazon S3 bucket, and can be used as a starting point to train models incrementally. Amazon SageMaker provides metrics and logs in CloudWatch. They can be used to see when managed spot training jobs are running, interrupted, resumed, or completed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableManagedSpotTraining")]
    pub enable_managed_spot_training: Option<bool>,
    /// Isolates the training container. No inbound or outbound network calls can be made, except for calls between peers within a training cluster for distributed training. If you enable network isolation for training jobs that are configured to use a VPC, SageMaker downloads and uploads customer data and model artifacts through the specified VPC, but the training container does not have network access.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableNetworkIsolation")]
    pub enable_network_isolation: Option<bool>,
    /// The environment variables to set in the Docker container.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub environment: Option<BTreeMap<String, String>>,
    /// Associates a SageMaker job as a trial component with an experiment and trial. Specified when you call the following APIs: 
    ///  * CreateProcessingJob 
    ///  * CreateTrainingJob 
    ///  * CreateTransformJob
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "experimentConfig")]
    pub experiment_config: Option<TrainingJobExperimentConfig>,
    /// Algorithm-specific parameters that influence the quality of the model. You set hyperparameters before you start the learning process. For a list of hyperparameters for each training algorithm provided by SageMaker, see Algorithms (https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html). 
    ///  You can specify a maximum of 100 hyperparameters. Each hyperparameter is a key-value pair. Each key and value is limited to 256 characters, as specified by the Length Constraint. 
    ///  Do not include any security-sensitive information including account access IDs, secrets or tokens in any hyperparameter field. If the use of security-sensitive credentials are detected, SageMaker will reject your training job request and return an exception error.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "hyperParameters")]
    pub hyper_parameters: Option<BTreeMap<String, String>>,
    /// An array of Channel objects. Each channel is a named input source. InputDataConfig describes the input data and its location. 
    ///  Algorithms can accept input data from one or more channels. For example, an algorithm might have two channels of input data, training_data and validation_data. The configuration for each channel provides the S3, EFS, or FSx location where the input data is stored. It also provides information about the stored data: the MIME type, compression method, and whether the data is wrapped in RecordIO format. 
    ///  Depending on the input mode that the algorithm supports, SageMaker either copies input data files from an S3 bucket to a local directory in the Docker container, or makes it available as input streams. For example, if you specify an EFS location, input data files are available as input streams. They do not need to be downloaded.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inputDataConfig")]
    pub input_data_config: Option<Vec<TrainingJobInputDataConfig>>,
    /// Specifies the path to the S3 location where you want to store model artifacts. SageMaker creates subfolders for the artifacts.
    #[serde(rename = "outputDataConfig")]
    pub output_data_config: TrainingJobOutputDataConfig,
    /// Configuration information for Amazon SageMaker Debugger system monitoring, framework profiling, and storage paths.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "profilerConfig")]
    pub profiler_config: Option<TrainingJobProfilerConfig>,
    /// Configuration information for Amazon SageMaker Debugger rules for profiling system and framework metrics.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "profilerRuleConfigurations")]
    pub profiler_rule_configurations: Option<Vec<TrainingJobProfilerRuleConfigurations>>,
    /// The resources, including the ML compute instances and ML storage volumes, to use for model training. 
    ///  ML storage volumes store model artifacts and incremental states. Training algorithms might also use ML storage volumes for scratch space. If you want SageMaker to use the ML storage volume to store the training data, choose File as the TrainingInputMode in the algorithm specification. For distributed training algorithms, specify an instance count greater than 1.
    #[serde(rename = "resourceConfig")]
    pub resource_config: TrainingJobResourceConfig,
    /// The number of times to retry the job when the job fails due to an InternalServerError.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "retryStrategy")]
    pub retry_strategy: Option<TrainingJobRetryStrategy>,
    /// The Amazon Resource Name (ARN) of an IAM role that SageMaker can assume to perform tasks on your behalf. 
    ///  During model training, SageMaker needs your permission to read input data from an S3 bucket, download a Docker image that contains training code, write model artifacts to an S3 bucket, write logs to Amazon CloudWatch Logs, and publish metrics to Amazon CloudWatch. You grant permissions for all of these tasks to an IAM role. For more information, see SageMaker Roles (https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html). 
    ///  To be able to pass this role to SageMaker, the caller of this API must have the iam:PassRole permission.
    #[serde(rename = "roleARN")]
    pub role_arn: String,
    /// Specifies a limit to how long a model training job can run. It also specifies how long a managed Spot training job has to complete. When the job reaches the time limit, SageMaker ends the training job. Use this API to cap model training costs. 
    ///  To stop a job, SageMaker sends the algorithm the SIGTERM signal, which delays job termination for 120 seconds. Algorithms can use this 120-second window to save the model artifacts, so the results of training are not lost.
    #[serde(rename = "stoppingCondition")]
    pub stopping_condition: TrainingJobStoppingCondition,
    /// An array of key-value pairs. You can use tags to categorize your Amazon Web Services resources in different ways, for example, by purpose, owner, or environment. For more information, see Tagging Amazon Web Services Resources (https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html).
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tags: Option<Vec<TrainingJobTags>>,
    /// Configuration of storage locations for the Amazon SageMaker Debugger TensorBoard output data.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tensorBoardOutputConfig")]
    pub tensor_board_output_config: Option<TrainingJobTensorBoardOutputConfig>,
    /// The name of the training job. The name must be unique within an Amazon Web Services Region in an Amazon Web Services account.
    #[serde(rename = "trainingJobName")]
    pub training_job_name: String,
    /// A VpcConfig object that specifies the VPC that you want your training job to connect to. Control access to and from your training container by configuring the VPC. For more information, see Protect Training Jobs by Using an Amazon Virtual Private Cloud (https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "vpcConfig")]
    pub vpc_config: Option<TrainingJobVpcConfig>,
}

/// The registry path of the Docker image that contains the training algorithm and algorithm-specific metadata, including the input mode. For more information about algorithms provided by SageMaker, see Algorithms (https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html). For information about providing your own algorithms, see Using Your Own Algorithms with Amazon SageMaker (https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html).
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobAlgorithmSpecification {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "algorithmName")]
    pub algorithm_name: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableSageMakerMetricsTimeSeries")]
    pub enable_sage_maker_metrics_time_series: Option<bool>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "metricDefinitions")]
    pub metric_definitions: Option<Vec<TrainingJobAlgorithmSpecificationMetricDefinitions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "trainingImage")]
    pub training_image: Option<String>,
    /// The training input mode that the algorithm supports. For more information about input modes, see Algorithms (https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html). 
    ///  Pipe mode 
    ///  If an algorithm supports Pipe mode, Amazon SageMaker streams data directly from Amazon S3 to the container. 
    ///  File mode 
    ///  If an algorithm supports File mode, SageMaker downloads the training data from S3 to the provisioned ML storage volume, and mounts the directory to the Docker volume for the training container. 
    ///  You must provision the ML storage volume with sufficient capacity to accommodate the data downloaded from S3. In addition to the training data, the ML storage volume also stores the output model. The algorithm container uses the ML storage volume to also store intermediate information, if any. 
    ///  For distributed algorithms, training data is distributed uniformly. Your training duration is predictable if the input data objects sizes are approximately the same. SageMaker does not split the files any further for model training. If the object sizes are skewed, training won't be optimal as the data distribution is also skewed when one host in a training cluster is overloaded, thus becoming a bottleneck in training. 
    ///  FastFile mode 
    ///  If an algorithm supports FastFile mode, SageMaker streams data directly from S3 to the container with no code changes, and provides file system access to the data. Users can author their training script to interact with these files as if they were stored on disk. 
    ///  FastFile mode works best when the data is read sequentially. Augmented manifest files aren't supported. The startup time is lower when there are fewer files in the S3 bucket provided.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "trainingInputMode")]
    pub training_input_mode: Option<String>,
}

/// Specifies a metric that the training algorithm writes to stderr or stdout. SageMakerhyperparameter tuning captures all defined metrics. You specify one metric that a hyperparameter tuning job uses as its objective metric to choose the best training job.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobAlgorithmSpecificationMetricDefinitions {
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub regex: Option<String>,
}

/// Contains information about the output location for managed spot training checkpoint data.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobCheckpointConfig {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "localPath")]
    pub local_path: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3URI")]
    pub s3_uri: Option<String>,
}

/// Configuration information for the Amazon SageMaker Debugger hook parameters, metric and tensor collections, and storage paths. To learn more about how to configure the DebugHookConfig parameter, see Use the SageMaker and Debugger Configuration API Operations to Create, Update, and Debug Your Training Job (https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-createtrainingjob-api.html).
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobDebugHookConfig {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "collectionConfigurations")]
    pub collection_configurations: Option<Vec<TrainingJobDebugHookConfigCollectionConfigurations>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "hookParameters")]
    pub hook_parameters: Option<BTreeMap<String, String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "localPath")]
    pub local_path: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3OutputPath")]
    pub s3_output_path: Option<String>,
}

/// Configuration information for the Amazon SageMaker Debugger output tensor collections.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobDebugHookConfigCollectionConfigurations {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "collectionName")]
    pub collection_name: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "collectionParameters")]
    pub collection_parameters: Option<BTreeMap<String, String>>,
}

/// Configuration information for SageMaker Debugger rules for debugging. To learn more about how to configure the DebugRuleConfiguration parameter, see Use the SageMaker and Debugger Configuration API Operations to Create, Update, and Debug Your Training Job (https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-createtrainingjob-api.html).
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobDebugRuleConfigurations {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "instanceType")]
    pub instance_type: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "localPath")]
    pub local_path: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ruleConfigurationName")]
    pub rule_configuration_name: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ruleEvaluatorImage")]
    pub rule_evaluator_image: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ruleParameters")]
    pub rule_parameters: Option<BTreeMap<String, String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3OutputPath")]
    pub s3_output_path: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeSizeInGB")]
    pub volume_size_in_gb: Option<i64>,
}

/// Associates a SageMaker job as a trial component with an experiment and trial. Specified when you call the following APIs: 
///  * CreateProcessingJob 
///  * CreateTrainingJob 
///  * CreateTransformJob
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobExperimentConfig {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "experimentName")]
    pub experiment_name: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "trialComponentDisplayName")]
    pub trial_component_display_name: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "trialName")]
    pub trial_name: Option<String>,
}

/// A channel is a named input source that training algorithms can consume.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobInputDataConfig {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "channelName")]
    pub channel_name: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "compressionType")]
    pub compression_type: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "contentType")]
    pub content_type: Option<String>,
    /// Describes the location of the channel data.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataSource")]
    pub data_source: Option<TrainingJobInputDataConfigDataSource>,
    /// The training input mode that the algorithm supports. For more information about input modes, see Algorithms (https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html). 
    ///  Pipe mode 
    ///  If an algorithm supports Pipe mode, Amazon SageMaker streams data directly from Amazon S3 to the container. 
    ///  File mode 
    ///  If an algorithm supports File mode, SageMaker downloads the training data from S3 to the provisioned ML storage volume, and mounts the directory to the Docker volume for the training container. 
    ///  You must provision the ML storage volume with sufficient capacity to accommodate the data downloaded from S3. In addition to the training data, the ML storage volume also stores the output model. The algorithm container uses the ML storage volume to also store intermediate information, if any. 
    ///  For distributed algorithms, training data is distributed uniformly. Your training duration is predictable if the input data objects sizes are approximately the same. SageMaker does not split the files any further for model training. If the object sizes are skewed, training won't be optimal as the data distribution is also skewed when one host in a training cluster is overloaded, thus becoming a bottleneck in training. 
    ///  FastFile mode 
    ///  If an algorithm supports FastFile mode, SageMaker streams data directly from S3 to the container with no code changes, and provides file system access to the data. Users can author their training script to interact with these files as if they were stored on disk. 
    ///  FastFile mode works best when the data is read sequentially. Augmented manifest files aren't supported. The startup time is lower when there are fewer files in the S3 bucket provided.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inputMode")]
    pub input_mode: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "recordWrapperType")]
    pub record_wrapper_type: Option<String>,
    /// A configuration for a shuffle option for input data in a channel. If you use S3Prefix for S3DataType, the results of the S3 key prefix matches are shuffled. If you use ManifestFile, the order of the S3 object references in the ManifestFile is shuffled. If you use AugmentedManifestFile, the order of the JSON lines in the AugmentedManifestFile is shuffled. The shuffling order is determined using the Seed value. 
    ///  For Pipe input mode, when ShuffleConfig is specified shuffling is done at the start of every epoch. With large datasets, this ensures that the order of the training data is different for each epoch, and it helps reduce bias and possible overfitting. In a multi-node training job when ShuffleConfig is combined with S3DataDistributionType of ShardedByS3Key, the data is shuffled across nodes so that the content sent to a particular node on the first epoch might be sent to a different node on the second epoch.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "shuffleConfig")]
    pub shuffle_config: Option<TrainingJobInputDataConfigShuffleConfig>,
}

/// Describes the location of the channel data.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobInputDataConfigDataSource {
    /// Specifies a file system data source for a channel.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fileSystemDataSource")]
    pub file_system_data_source: Option<TrainingJobInputDataConfigDataSourceFileSystemDataSource>,
    /// Describes the S3 data source.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3DataSource")]
    pub s3_data_source: Option<TrainingJobInputDataConfigDataSourceS3DataSource>,
}

/// Specifies a file system data source for a channel.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobInputDataConfigDataSourceFileSystemDataSource {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "directoryPath")]
    pub directory_path: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fileSystemAccessMode")]
    pub file_system_access_mode: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fileSystemID")]
    pub file_system_id: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fileSystemType")]
    pub file_system_type: Option<String>,
}

/// Describes the S3 data source.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobInputDataConfigDataSourceS3DataSource {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "attributeNames")]
    pub attribute_names: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "instanceGroupNames")]
    pub instance_group_names: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3DataDistributionType")]
    pub s3_data_distribution_type: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3DataType")]
    pub s3_data_type: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3URI")]
    pub s3_uri: Option<String>,
}

/// A configuration for a shuffle option for input data in a channel. If you use S3Prefix for S3DataType, the results of the S3 key prefix matches are shuffled. If you use ManifestFile, the order of the S3 object references in the ManifestFile is shuffled. If you use AugmentedManifestFile, the order of the JSON lines in the AugmentedManifestFile is shuffled. The shuffling order is determined using the Seed value. 
///  For Pipe input mode, when ShuffleConfig is specified shuffling is done at the start of every epoch. With large datasets, this ensures that the order of the training data is different for each epoch, and it helps reduce bias and possible overfitting. In a multi-node training job when ShuffleConfig is combined with S3DataDistributionType of ShardedByS3Key, the data is shuffled across nodes so that the content sent to a particular node on the first epoch might be sent to a different node on the second epoch.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobInputDataConfigShuffleConfig {
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub seed: Option<i64>,
}

/// Specifies the path to the S3 location where you want to store model artifacts. SageMaker creates subfolders for the artifacts.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobOutputDataConfig {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyID")]
    pub kms_key_id: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3OutputPath")]
    pub s3_output_path: Option<String>,
}

/// Configuration information for Amazon SageMaker Debugger system monitoring, framework profiling, and storage paths.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobProfilerConfig {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "profilingIntervalInMilliseconds")]
    pub profiling_interval_in_milliseconds: Option<i64>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "profilingParameters")]
    pub profiling_parameters: Option<BTreeMap<String, String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3OutputPath")]
    pub s3_output_path: Option<String>,
}

/// Configuration information for profiling rules.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobProfilerRuleConfigurations {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "instanceType")]
    pub instance_type: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "localPath")]
    pub local_path: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ruleConfigurationName")]
    pub rule_configuration_name: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ruleEvaluatorImage")]
    pub rule_evaluator_image: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ruleParameters")]
    pub rule_parameters: Option<BTreeMap<String, String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3OutputPath")]
    pub s3_output_path: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeSizeInGB")]
    pub volume_size_in_gb: Option<i64>,
}

/// The resources, including the ML compute instances and ML storage volumes, to use for model training. 
///  ML storage volumes store model artifacts and incremental states. Training algorithms might also use ML storage volumes for scratch space. If you want SageMaker to use the ML storage volume to store the training data, choose File as the TrainingInputMode in the algorithm specification. For distributed training algorithms, specify an instance count greater than 1.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobResourceConfig {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "instanceCount")]
    pub instance_count: Option<i64>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "instanceGroups")]
    pub instance_groups: Option<Vec<TrainingJobResourceConfigInstanceGroups>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "instanceType")]
    pub instance_type: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "keepAlivePeriodInSeconds")]
    pub keep_alive_period_in_seconds: Option<i64>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeKMSKeyID")]
    pub volume_kms_key_id: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeSizeInGB")]
    pub volume_size_in_gb: Option<i64>,
}

/// Defines an instance group for heterogeneous cluster training. When requesting a training job using the CreateTrainingJob (https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html) API, you can configure multiple instance groups .
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobResourceConfigInstanceGroups {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "instanceCount")]
    pub instance_count: Option<i64>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "instanceGroupName")]
    pub instance_group_name: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "instanceType")]
    pub instance_type: Option<String>,
}

/// The number of times to retry the job when the job fails due to an InternalServerError.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobRetryStrategy {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumRetryAttempts")]
    pub maximum_retry_attempts: Option<i64>,
}

/// Specifies a limit to how long a model training job can run. It also specifies how long a managed Spot training job has to complete. When the job reaches the time limit, SageMaker ends the training job. Use this API to cap model training costs. 
///  To stop a job, SageMaker sends the algorithm the SIGTERM signal, which delays job termination for 120 seconds. Algorithms can use this 120-second window to save the model artifacts, so the results of training are not lost.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobStoppingCondition {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxRuntimeInSeconds")]
    pub max_runtime_in_seconds: Option<i64>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxWaitTimeInSeconds")]
    pub max_wait_time_in_seconds: Option<i64>,
}

/// A tag object that consists of a key and an optional value, used to manage metadata for SageMaker Amazon Web Services resources. 
///  You can add tags to notebook instances, training jobs, hyperparameter tuning jobs, batch transform jobs, models, labeling jobs, work teams, endpoint configurations, and endpoints. For more information on adding tags to SageMaker resources, see AddTags. 
///  For more information on adding metadata to your Amazon Web Services resources with tagging, see Tagging Amazon Web Services resources (https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html). For advice on best practices for managing Amazon Web Services resources with tagging, see Tagging Best Practices: Implement an Effective Amazon Web Services Resource Tagging Strategy (https://d1.awsstatic.com/whitepapers/aws-tagging-best-practices.pdf).
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobTags {
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub key: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<String>,
}

/// Configuration of storage locations for the Amazon SageMaker Debugger TensorBoard output data.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobTensorBoardOutputConfig {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "localPath")]
    pub local_path: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3OutputPath")]
    pub s3_output_path: Option<String>,
}

/// A VpcConfig object that specifies the VPC that you want your training job to connect to. Control access to and from your training container by configuring the VPC. For more information, see Protect Training Jobs by Using an Amazon Virtual Private Cloud (https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html).
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobVpcConfig {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "securityGroupIDs")]
    pub security_group_i_ds: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub subnets: Option<Vec<String>>,
}

/// TrainingJobStatus defines the observed state of TrainingJob
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobStatus {
    /// All CRs managed by ACK have a common `Status.ACKResourceMetadata` member that is used to contain resource sync state, account ownership, constructed ARN for the resource
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ackResourceMetadata")]
    pub ack_resource_metadata: Option<TrainingJobStatusAckResourceMetadata>,
    /// All CRS managed by ACK have a common `Status.Conditions` member that contains a collection of `ackv1alpha1.Condition` objects that describe the various terminal states of the CR and its backend AWS service API resource
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub conditions: Option<Vec<TrainingJobStatusConditions>>,
    /// A timestamp that indicates when the training job was created.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "creationTime")]
    pub creation_time: Option<String>,
    /// Evaluation status of Amazon SageMaker Debugger rules for debugging on a training job.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "debugRuleEvaluationStatuses")]
    pub debug_rule_evaluation_statuses: Option<Vec<TrainingJobStatusDebugRuleEvaluationStatuses>>,
    /// If the training job failed, the reason it failed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "failureReason")]
    pub failure_reason: Option<String>,
    /// A timestamp that indicates when the status of the training job was last modified.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "lastModifiedTime")]
    pub last_modified_time: Option<String>,
    /// Information about the Amazon S3 location that is configured for storing model artifacts.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelArtifacts")]
    pub model_artifacts: Option<TrainingJobStatusModelArtifacts>,
    /// Evaluation status of Amazon SageMaker Debugger rules for profiling on a training job.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "profilerRuleEvaluationStatuses")]
    pub profiler_rule_evaluation_statuses: Option<Vec<TrainingJobStatusProfilerRuleEvaluationStatuses>>,
    /// Profiling status of a training job.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "profilingStatus")]
    pub profiling_status: Option<String>,
    /// Provides detailed information about the state of the training job. For detailed information on the secondary status of the training job, see StatusMessage under SecondaryStatusTransition. 
    ///  SageMaker provides primary statuses and secondary statuses that apply to each of them: 
    ///  InProgress 
    ///  * Starting - Starting the training job. 
    ///  * Downloading - An optional stage for algorithms that support File training input mode. It indicates that data is being downloaded to the ML storage volumes. 
    ///  * Training - Training is in progress. 
    ///  * Interrupted - The job stopped because the managed spot training instances were interrupted. 
    ///  * Uploading - Training is complete and the model artifacts are being uploaded to the S3 location. 
    ///  Completed 
    ///  * Completed - The training job has completed. 
    ///  Failed 
    ///  * Failed - The training job has failed. The reason for the failure is returned in the FailureReason field of DescribeTrainingJobResponse. 
    ///  Stopped 
    ///  * MaxRuntimeExceeded - The job stopped because it exceeded the maximum allowed runtime. 
    ///  * MaxWaitTimeExceeded - The job stopped because it exceeded the maximum allowed wait time. 
    ///  * Stopped - The training job has stopped. 
    ///  Stopping 
    ///  * Stopping - Stopping the training job. 
    ///  Valid values for SecondaryStatus are subject to change. 
    ///  We no longer support the following secondary statuses: 
    ///  * LaunchingMLInstances 
    ///  * PreparingTraining 
    ///  * DownloadingTrainingImage
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "secondaryStatus")]
    pub secondary_status: Option<String>,
    /// The status of the training job. 
    ///  SageMaker provides the following training job statuses: 
    ///  * InProgress - The training is in progress. 
    ///  * Completed - The training job has completed. 
    ///  * Failed - The training job has failed. To see the reason for the failure, see the FailureReason field in the response to a DescribeTrainingJobResponse call. 
    ///  * Stopping - The training job is stopping. 
    ///  * Stopped - The training job has stopped. 
    ///  For more detailed information, see SecondaryStatus.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "trainingJobStatus")]
    pub training_job_status: Option<String>,
    /// The status of the warm pool associated with the training job.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "warmPoolStatus")]
    pub warm_pool_status: Option<TrainingJobStatusWarmPoolStatus>,
}

/// All CRs managed by ACK have a common `Status.ACKResourceMetadata` member that is used to contain resource sync state, account ownership, constructed ARN for the resource
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobStatusAckResourceMetadata {
    /// ARN is the Amazon Resource Name for the resource. This is a globally-unique identifier and is set only by the ACK service controller once the controller has orchestrated the creation of the resource OR when it has verified that an "adopted" resource (a resource where the ARN annotation was set by the Kubernetes user on the CR) exists and matches the supplied CR's Spec field values. TODO(vijat@): Find a better strategy for resources that do not have ARN in CreateOutputResponse https://github.com/aws/aws-controllers-k8s/issues/270
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub arn: Option<String>,
    /// OwnerAccountID is the AWS Account ID of the account that owns the backend AWS service API resource.
    #[serde(rename = "ownerAccountID")]
    pub owner_account_id: String,
    /// Region is the AWS region in which the resource exists or will exist.
    pub region: String,
}

/// Condition is the common struct used by all CRDs managed by ACK service controllers to indicate terminal states  of the CR and its backend AWS service API resource
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobStatusConditions {
    /// Last time the condition transitioned from one status to another.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "lastTransitionTime")]
    pub last_transition_time: Option<String>,
    /// A human readable message indicating details about the transition.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub message: Option<String>,
    /// The reason for the condition's last transition.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub reason: Option<String>,
    /// Status of the condition, one of True, False, Unknown.
    pub status: String,
    /// Type is the type of the Condition
    #[serde(rename = "type")]
    pub r#type: String,
}

/// Information about the status of the rule evaluation.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobStatusDebugRuleEvaluationStatuses {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "lastModifiedTime")]
    pub last_modified_time: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ruleConfigurationName")]
    pub rule_configuration_name: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ruleEvaluationJobARN")]
    pub rule_evaluation_job_arn: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ruleEvaluationStatus")]
    pub rule_evaluation_status: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "statusDetails")]
    pub status_details: Option<String>,
}

/// Information about the Amazon S3 location that is configured for storing model artifacts.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobStatusModelArtifacts {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3ModelArtifacts")]
    pub s3_model_artifacts: Option<String>,
}

/// Information about the status of the rule evaluation.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobStatusProfilerRuleEvaluationStatuses {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "lastModifiedTime")]
    pub last_modified_time: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ruleConfigurationName")]
    pub rule_configuration_name: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ruleEvaluationJobARN")]
    pub rule_evaluation_job_arn: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ruleEvaluationStatus")]
    pub rule_evaluation_status: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "statusDetails")]
    pub status_details: Option<String>,
}

/// The status of the warm pool associated with the training job.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TrainingJobStatusWarmPoolStatus {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "resourceRetainedBillableTimeInSeconds")]
    pub resource_retained_billable_time_in_seconds: Option<i64>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "reusedByJob")]
    pub reused_by_job: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub status: Option<String>,
}

