// WARNING: generated by kopium - manual changes will be overwritten
// kopium command: kopium --docs --filename=./crd-catalog/netobserv/network-observability-operator/flows.netobserv.io/v1beta2/flowcollectors.yaml --derive=PartialEq
// kopium version: 0.17.2

use kube::CustomResource;
use serde::{Serialize, Deserialize};
use std::collections::BTreeMap;
use k8s_openapi::apimachinery::pkg::util::intstr::IntOrString;
use k8s_openapi::apimachinery::pkg::apis::meta::v1::Condition;

/// Defines the desired state of the FlowCollector resource. <br><br> *: the mention of "unsupported", or "deprecated" for a feature throughout this document means that this feature is not officially supported by Red Hat. It might have been, for example, contributed by the community and accepted without a formal agreement for maintenance. The product maintainers might provide some support for these features as a best effort only.
#[derive(CustomResource, Serialize, Deserialize, Clone, Debug, PartialEq)]
#[kube(group = "flows.netobserv.io", version = "v1beta2", kind = "FlowCollector", plural = "flowcollectors")]
#[kube(status = "FlowCollectorStatus")]
#[kube(schema = "disabled")]
pub struct FlowCollectorSpec {
    /// Agent configuration for flows extraction.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub agent: Option<FlowCollectorAgent>,
    /// `consolePlugin` defines the settings related to the OpenShift Console plugin, when available.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "consolePlugin")]
    pub console_plugin: Option<FlowCollectorConsolePlugin>,
    /// `deploymentModel` defines the desired type of deployment for flow processing. Possible values are:<br> - `Direct` (default) to make the flow processor listening directly from the agents.<br> - `Kafka` to make flows sent to a Kafka pipeline before consumption by the processor.<br> Kafka can provide better scalability, resiliency, and high availability (for more details, see https://www.redhat.com/en/topics/integration/what-is-apache-kafka).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "deploymentModel")]
    pub deployment_model: Option<FlowCollectorDeploymentModel>,
    /// `exporters` define additional optional exporters for custom consumption or storage.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub exporters: Option<Vec<FlowCollectorExporters>>,
    /// Kafka configuration, allowing to use Kafka as a broker as part of the flow collection pipeline. Available when the `spec.deploymentModel` is `Kafka`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub kafka: Option<FlowCollectorKafka>,
    /// `loki`, the flow store, client settings.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub loki: Option<FlowCollectorLoki>,
    /// Namespace where NetObserv pods are deployed.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// `processor` defines the settings of the component that receives the flows from the agent, enriches them, generates metrics, and forwards them to the Loki persistence layer and/or any available exporter.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub processor: Option<FlowCollectorProcessor>,
}

/// Agent configuration for flows extraction.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgent {
    /// `ebpf` describes the settings related to the eBPF-based flow reporter when `spec.agent.type` is set to `eBPF`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub ebpf: Option<FlowCollectorAgentEbpf>,
    /// `ipfix` [deprecated (*)] - describes the settings related to the IPFIX-based flow reporter when `spec.agent.type` is set to `IPFIX`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub ipfix: Option<FlowCollectorAgentIpfix>,
    /// `type` [deprecated (*)] selects the flows tracing agent. The only possible value is `eBPF` (default), to use NetObserv eBPF agent.<br> Previously, using an IPFIX collector was allowed, but was deprecated and it is now removed.<br> Setting `IPFIX` is ignored and still use the eBPF Agent. Since there is only a single option here, this field will be remove in a future API version.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorAgentType>,
}

/// `ebpf` describes the settings related to the eBPF-based flow reporter when `spec.agent.type` is set to `eBPF`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpf {
    /// `advanced` allows setting some aspects of the internal configuration of the eBPF agent. This section is aimed mostly for debugging and fine-grained performance optimizations, such as `GOGC` and `GOMAXPROCS` env vars. Set these values at your own risk.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub advanced: Option<FlowCollectorAgentEbpfAdvanced>,
    /// `cacheActiveTimeout` is the max period during which the reporter aggregates flows before sending. Increasing `cacheMaxFlows` and `cacheActiveTimeout` can decrease the network traffic overhead and the CPU load, however you can expect higher memory consumption and an increased latency in the flow collection.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "cacheActiveTimeout")]
    pub cache_active_timeout: Option<String>,
    /// `cacheMaxFlows` is the max number of flows in an aggregate; when reached, the reporter sends the flows. Increasing `cacheMaxFlows` and `cacheActiveTimeout` can decrease the network traffic overhead and the CPU load, however you can expect higher memory consumption and an increased latency in the flow collection.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "cacheMaxFlows")]
    pub cache_max_flows: Option<i32>,
    /// `excludeInterfaces` contains the interface names that are excluded from flow tracing. An entry enclosed by slashes, such as `/br-/`, is matched as a regular expression. Otherwise it is matched as a case-sensitive string.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "excludeInterfaces")]
    pub exclude_interfaces: Option<Vec<String>>,
    /// List of additional features to enable. They are all disabled by default. Enabling additional features might have performance impacts. Possible values are:<br> - `PacketDrop`: enable the packets drop flows logging feature. This feature requires mounting the kernel debug filesystem, so the eBPF pod has to run as privileged. If the `spec.agent.ebpf.privileged` parameter is not set, an error is reported.<br> - `DNSTracking`: enable the DNS tracking feature.<br> - `FlowRTT`: enable flow latency (RTT) calculations in the eBPF agent during TCP handshakes. This feature better works with `sampling` set to 1.<br>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub features: Option<Vec<String>>,
    /// `imagePullPolicy` is the Kubernetes pull policy for the image defined above
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "imagePullPolicy")]
    pub image_pull_policy: Option<FlowCollectorAgentEbpfImagePullPolicy>,
    /// `interfaces` contains the interface names from where flows are collected. If empty, the agent fetches all the interfaces in the system, excepting the ones listed in ExcludeInterfaces. An entry enclosed by slashes, such as `/br-/`, is matched as a regular expression. Otherwise it is matched as a case-sensitive string.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub interfaces: Option<Vec<String>>,
    /// `kafkaBatchSize` limits the maximum size of a request in bytes before being sent to a partition. Ignored when not using Kafka. Default: 1MB.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kafkaBatchSize")]
    pub kafka_batch_size: Option<i64>,
    /// `logLevel` defines the log level for the NetObserv eBPF Agent
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "logLevel")]
    pub log_level: Option<FlowCollectorAgentEbpfLogLevel>,
    /// `metrics` defines the eBPF agent configuration regarding metrics
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metrics: Option<FlowCollectorAgentEbpfMetrics>,
    /// Privileged mode for the eBPF Agent container. When ignored or set to `false`, the operator sets granular capabilities (BPF, PERFMON, NET_ADMIN, SYS_RESOURCE) to the container. If for some reason these capabilities cannot be set, such as if an old kernel version not knowing CAP_BPF is in use, then you can turn on this mode for more global privileges. Some agent features require the privileged mode, such as packet drops tracking (see `features`) and SR-IOV support.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub privileged: Option<bool>,
    /// `resources` are the compute resources required by this container. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resources: Option<FlowCollectorAgentEbpfResources>,
    /// Sampling rate of the flow reporter. 100 means one flow on 100 is sent. 0 or 1 means all flows are sampled.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub sampling: Option<i32>,
}

/// `advanced` allows setting some aspects of the internal configuration of the eBPF agent. This section is aimed mostly for debugging and fine-grained performance optimizations, such as `GOGC` and `GOMAXPROCS` env vars. Set these values at your own risk.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvanced {
    /// If specified, the pod's scheduling constraints. For documentation, refer to https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub affinity: Option<FlowCollectorAgentEbpfAdvancedAffinity>,
    /// `env` allows passing custom environment variables to underlying components. Useful for passing some very concrete performance-tuning options, such as `GOGC` and `GOMAXPROCS`, that should not be publicly exposed as part of the FlowCollector descriptor, as they are only useful in edge debug or support scenarios.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub env: Option<BTreeMap<String, String>>,
    /// NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeSelector")]
    pub node_selector: Option<BTreeMap<String, String>>,
    /// If specified, indicates the pod's priority. "system-node-critical" and "system-cluster-critical" are two special keywords which indicate the highest priorities with the former being the highest priority. Any other name must be defined by creating a PriorityClass object with that name. If not specified, the pod priority will be default or zero if there is no default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "priorityClassName")]
    pub priority_class_name: Option<String>,
}

/// If specified, the pod's scheduling constraints. For documentation, refer to https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinity {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeAffinity")]
    pub node_affinity: Option<FlowCollectorAgentEbpfAdvancedAffinityNodeAffinity>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podAffinity")]
    pub pod_affinity: Option<FlowCollectorAgentEbpfAdvancedAffinityPodAffinity>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podAntiAffinity")]
    pub pod_anti_affinity: Option<FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinity>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityNodeAffinity {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorAgentEbpfAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<FlowCollectorAgentEbpfAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    pub preference: FlowCollectorAgentEbpfAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference,
    pub weight: i32,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchFields")]
    pub match_fields: Option<Vec<FlowCollectorAgentEbpfAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    #[serde(rename = "nodeSelectorTerms")]
    pub node_selector_terms: Vec<FlowCollectorAgentEbpfAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchFields")]
    pub match_fields: Option<Vec<FlowCollectorAgentEbpfAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAffinity {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorAgentEbpfAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorAgentEbpfAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    #[serde(rename = "podAffinityTerm")]
    pub pod_affinity_term: FlowCollectorAgentEbpfAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm,
    pub weight: i32,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorAgentEbpfAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorAgentEbpfAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorAgentEbpfAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorAgentEbpfAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinity {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    #[serde(rename = "podAffinityTerm")]
    pub pod_affinity_term: FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm,
    pub weight: i32,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// `ebpf` describes the settings related to the eBPF-based flow reporter when `spec.agent.type` is set to `eBPF`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfImagePullPolicy {
    IfNotPresent,
    Always,
    Never,
}

/// `ebpf` describes the settings related to the eBPF-based flow reporter when `spec.agent.type` is set to `eBPF`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfLogLevel {
    #[serde(rename = "trace")]
    Trace,
    #[serde(rename = "debug")]
    Debug,
    #[serde(rename = "info")]
    Info,
    #[serde(rename = "warn")]
    Warn,
    #[serde(rename = "error")]
    Error,
    #[serde(rename = "fatal")]
    Fatal,
    #[serde(rename = "panic")]
    Panic,
}

/// `metrics` defines the eBPF agent configuration regarding metrics
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfMetrics {
    /// Set `enable` to `true` to enable eBPF agent metrics collection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// Metrics server endpoint configuration for Prometheus scraper
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub server: Option<FlowCollectorAgentEbpfMetricsServer>,
}

/// Metrics server endpoint configuration for Prometheus scraper
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfMetricsServer {
    /// The prometheus HTTP port
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub port: Option<i32>,
    /// TLS configuration.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<FlowCollectorAgentEbpfMetricsServerTls>,
}

/// TLS configuration.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfMetricsServerTls {
    /// `insecureSkipVerify` allows skipping client-side verification of the provided certificate. If set to `true`, the `providedCaFile` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// TLS configuration when `type` is set to `Provided`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub provided: Option<FlowCollectorAgentEbpfMetricsServerTlsProvided>,
    /// Reference to the CA file when `type` is set to `Provided`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "providedCaFile")]
    pub provided_ca_file: Option<FlowCollectorAgentEbpfMetricsServerTlsProvidedCaFile>,
    /// Select the type of TLS configuration:<br> - `Disabled` (default) to not configure TLS for the endpoint. - `Provided` to manually provide cert file and a key file. [Unsupported (*)]. - `Auto` to use OpenShift auto generated certificate using annotations.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorAgentEbpfMetricsServerTlsType>,
}

/// TLS configuration when `type` is set to `Provided`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfMetricsServerTlsProvided {
    /// `certFile` defines the path to the certificate file name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorAgentEbpfMetricsServerTlsProvidedType>,
}

/// TLS configuration when `type` is set to `Provided`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfMetricsServerTlsProvidedType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// Reference to the CA file when `type` is set to `Provided`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfMetricsServerTlsProvidedCaFile {
    /// File name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub file: Option<String>,
    /// Name of the config map or secret containing the file
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing the file. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the file reference: "configmap" or "secret"
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorAgentEbpfMetricsServerTlsProvidedCaFileType>,
}

/// Reference to the CA file when `type` is set to `Provided`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfMetricsServerTlsProvidedCaFileType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// TLS configuration.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfMetricsServerTlsType {
    Disabled,
    Provided,
    Auto,
}

/// `resources` are the compute resources required by this container. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfResources {
    /// Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container. 
    ///  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate. 
    ///  This field is immutable. It can only be set for containers.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub claims: Option<Vec<FlowCollectorAgentEbpfResourcesClaims>>,
    /// Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub limits: Option<BTreeMap<String, IntOrString>>,
    /// Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub requests: Option<BTreeMap<String, IntOrString>>,
}

/// ResourceClaim references one entry in PodSpec.ResourceClaims.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfResourcesClaims {
    /// Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
    pub name: String,
}

/// `ipfix` [deprecated (*)] - describes the settings related to the IPFIX-based flow reporter when `spec.agent.type` is set to `IPFIX`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentIpfix {
    /// `cacheActiveTimeout` is the max period during which the reporter aggregates flows before sending.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "cacheActiveTimeout")]
    pub cache_active_timeout: Option<String>,
    /// `cacheMaxFlows` is the max number of flows in an aggregate; when reached, the reporter sends the flows.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "cacheMaxFlows")]
    pub cache_max_flows: Option<i32>,
    /// `clusterNetworkOperator` defines the settings related to the OpenShift Cluster Network Operator, when available.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clusterNetworkOperator")]
    pub cluster_network_operator: Option<FlowCollectorAgentIpfixClusterNetworkOperator>,
    /// `forceSampleAll` allows disabling sampling in the IPFIX-based flow reporter. It is not recommended to sample all the traffic with IPFIX, as it might generate cluster instability. If you REALLY want to do that, set this flag to `true`. Use at your own risk. When it is set to `true`, the value of `sampling` is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "forceSampleAll")]
    pub force_sample_all: Option<bool>,
    /// `ovnKubernetes` defines the settings of the OVN-Kubernetes CNI, when available. This configuration is used when using OVN's IPFIX exports, without OpenShift. When using OpenShift, refer to the `clusterNetworkOperator` property instead.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ovnKubernetes")]
    pub ovn_kubernetes: Option<FlowCollectorAgentIpfixOvnKubernetes>,
    /// `sampling` is the sampling rate on the reporter. 100 means one flow on 100 is sent. To ensure cluster stability, it is not possible to set a value below 2. If you really want to sample every packet, which might impact the cluster stability, refer to `forceSampleAll`. Alternatively, you can use the eBPF Agent instead of IPFIX.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub sampling: Option<i32>,
}

/// `clusterNetworkOperator` defines the settings related to the OpenShift Cluster Network Operator, when available.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentIpfixClusterNetworkOperator {
    /// Namespace  where the config map is going to be deployed.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
}

/// `ovnKubernetes` defines the settings of the OVN-Kubernetes CNI, when available. This configuration is used when using OVN's IPFIX exports, without OpenShift. When using OpenShift, refer to the `clusterNetworkOperator` property instead.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentIpfixOvnKubernetes {
    /// `containerName` defines the name of the container to configure for IPFIX.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "containerName")]
    pub container_name: Option<String>,
    /// `daemonSetName` defines the name of the DaemonSet controlling the OVN-Kubernetes pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "daemonSetName")]
    pub daemon_set_name: Option<String>,
    /// Namespace where OVN-Kubernetes pods are deployed.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
}

/// Agent configuration for flows extraction.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentType {
    #[serde(rename = "eBPF")]
    EBpf,
    #[serde(rename = "IPFIX")]
    Ipfix,
}

/// `consolePlugin` defines the settings related to the OpenShift Console plugin, when available.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePlugin {
    /// `advanced` allows setting some aspects of the internal configuration of the console plugin. This section is aimed mostly for debugging and fine-grained performance optimizations, such as `GOGC` and `GOMAXPROCS` env vars. Set these values at your own risk.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub advanced: Option<FlowCollectorConsolePluginAdvanced>,
    /// `autoscaler` spec of a horizontal pod autoscaler to set up for the plugin Deployment.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub autoscaler: Option<FlowCollectorConsolePluginAutoscaler>,
    /// Enables the console plugin deployment. `spec.loki.enable` must also be `true`
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `imagePullPolicy` is the Kubernetes pull policy for the image defined above
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "imagePullPolicy")]
    pub image_pull_policy: Option<FlowCollectorConsolePluginImagePullPolicy>,
    /// `logLevel` for the console plugin backend
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "logLevel")]
    pub log_level: Option<FlowCollectorConsolePluginLogLevel>,
    /// `portNaming` defines the configuration of the port-to-service name translation
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "portNaming")]
    pub port_naming: Option<FlowCollectorConsolePluginPortNaming>,
    /// `quickFilters` configures quick filter presets for the Console plugin
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "quickFilters")]
    pub quick_filters: Option<Vec<FlowCollectorConsolePluginQuickFilters>>,
    /// `replicas` defines the number of replicas (pods) to start.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub replicas: Option<i32>,
    /// `resources`, in terms of compute resources, required by this container. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resources: Option<FlowCollectorConsolePluginResources>,
}

/// `advanced` allows setting some aspects of the internal configuration of the console plugin. This section is aimed mostly for debugging and fine-grained performance optimizations, such as `GOGC` and `GOMAXPROCS` env vars. Set these values at your own risk.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvanced {
    /// If specified, the pod's scheduling constraints. For documentation, refer to https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub affinity: Option<FlowCollectorConsolePluginAdvancedAffinity>,
    /// `args` allows passing custom arguments to underlying components. Useful for overriding some parameters, such as an url or a configuration path, that should not be publicly exposed as part of the FlowCollector descriptor, as they are only useful in edge debug or support scenarios.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub args: Option<Vec<String>>,
    /// `env` allows passing custom environment variables to underlying components. Useful for passing some very concrete performance-tuning options, such as `GOGC` and `GOMAXPROCS`, that should not be publicly exposed as part of the FlowCollector descriptor, as they are only useful in edge debug or support scenarios.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub env: Option<BTreeMap<String, String>>,
    /// NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeSelector")]
    pub node_selector: Option<BTreeMap<String, String>>,
    /// `port` is the plugin service port. Do not use 9002, which is reserved for metrics.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub port: Option<i32>,
    /// If specified, indicates the pod's priority. "system-node-critical" and "system-cluster-critical" are two special keywords which indicate the highest priorities with the former being the highest priority. Any other name must be defined by creating a PriorityClass object with that name. If not specified, the pod priority will be default or zero if there is no default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "priorityClassName")]
    pub priority_class_name: Option<String>,
    /// `register` allows, when set to `true`, to automatically register the provided console plugin with the OpenShift Console operator. When set to `false`, you can still register it manually by editing console.operator.openshift.io/cluster with the following command: `oc patch console.operator.openshift.io cluster --type='json' -p '[{"op": "add", "path": "/spec/plugins/-", "value": "netobserv-plugin"}]'`
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub register: Option<bool>,
}

/// If specified, the pod's scheduling constraints. For documentation, refer to https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinity {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeAffinity")]
    pub node_affinity: Option<FlowCollectorConsolePluginAdvancedAffinityNodeAffinity>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podAffinity")]
    pub pod_affinity: Option<FlowCollectorConsolePluginAdvancedAffinityPodAffinity>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podAntiAffinity")]
    pub pod_anti_affinity: Option<FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinity>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityNodeAffinity {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorConsolePluginAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<FlowCollectorConsolePluginAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    pub preference: FlowCollectorConsolePluginAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference,
    pub weight: i32,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchFields")]
    pub match_fields: Option<Vec<FlowCollectorConsolePluginAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    #[serde(rename = "nodeSelectorTerms")]
    pub node_selector_terms: Vec<FlowCollectorConsolePluginAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchFields")]
    pub match_fields: Option<Vec<FlowCollectorConsolePluginAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAffinity {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorConsolePluginAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorConsolePluginAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    #[serde(rename = "podAffinityTerm")]
    pub pod_affinity_term: FlowCollectorConsolePluginAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm,
    pub weight: i32,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorConsolePluginAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorConsolePluginAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorConsolePluginAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorConsolePluginAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinity {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    #[serde(rename = "podAffinityTerm")]
    pub pod_affinity_term: FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm,
    pub weight: i32,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// `autoscaler` spec of a horizontal pod autoscaler to set up for the plugin Deployment.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscaler {
    /// `maxReplicas` is the upper limit for the number of pods that can be set by the autoscaler; cannot be smaller than MinReplicas.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxReplicas")]
    pub max_replicas: Option<i32>,
    /// Metrics used by the pod autoscaler. For documentation, refer to https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/horizontal-pod-autoscaler-v2/
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metrics: Option<Vec<FlowCollectorConsolePluginAutoscalerMetrics>>,
    /// `minReplicas` is the lower limit for the number of replicas to which the autoscaler can scale down. It defaults to 1 pod. minReplicas is allowed to be 0 if the alpha feature gate HPAScaleToZero is enabled and at least one Object or External metric is configured. Scaling is active as long as at least one metric value is available.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "minReplicas")]
    pub min_replicas: Option<i32>,
    /// `status` describes the desired status regarding deploying an horizontal pod autoscaler.<br> - `Disabled` does not deploy an horizontal pod autoscaler.<br> - `Enabled` deploys an horizontal pod autoscaler.<br>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub status: Option<FlowCollectorConsolePluginAutoscalerStatus>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetrics {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "containerResource")]
    pub container_resource: Option<FlowCollectorConsolePluginAutoscalerMetricsContainerResource>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub external: Option<FlowCollectorConsolePluginAutoscalerMetricsExternal>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub object: Option<FlowCollectorConsolePluginAutoscalerMetricsObject>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub pods: Option<FlowCollectorConsolePluginAutoscalerMetricsPods>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resource: Option<FlowCollectorConsolePluginAutoscalerMetricsResource>,
    #[serde(rename = "type")]
    pub r#type: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsContainerResource {
    pub container: String,
    pub name: String,
    pub target: FlowCollectorConsolePluginAutoscalerMetricsContainerResourceTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsContainerResourceTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsExternal {
    pub metric: FlowCollectorConsolePluginAutoscalerMetricsExternalMetric,
    pub target: FlowCollectorConsolePluginAutoscalerMetricsExternalTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsExternalMetric {
    pub name: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selector: Option<FlowCollectorConsolePluginAutoscalerMetricsExternalMetricSelector>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsExternalMetricSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAutoscalerMetricsExternalMetricSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsExternalMetricSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsExternalTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsObject {
    #[serde(rename = "describedObject")]
    pub described_object: FlowCollectorConsolePluginAutoscalerMetricsObjectDescribedObject,
    pub metric: FlowCollectorConsolePluginAutoscalerMetricsObjectMetric,
    pub target: FlowCollectorConsolePluginAutoscalerMetricsObjectTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsObjectDescribedObject {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiVersion")]
    pub api_version: Option<String>,
    pub kind: String,
    pub name: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsObjectMetric {
    pub name: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selector: Option<FlowCollectorConsolePluginAutoscalerMetricsObjectMetricSelector>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsObjectMetricSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAutoscalerMetricsObjectMetricSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsObjectMetricSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsObjectTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsPods {
    pub metric: FlowCollectorConsolePluginAutoscalerMetricsPodsMetric,
    pub target: FlowCollectorConsolePluginAutoscalerMetricsPodsTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsPodsMetric {
    pub name: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selector: Option<FlowCollectorConsolePluginAutoscalerMetricsPodsMetricSelector>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsPodsMetricSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAutoscalerMetricsPodsMetricSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsPodsMetricSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsPodsTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsResource {
    pub name: String,
    pub target: FlowCollectorConsolePluginAutoscalerMetricsResourceTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsResourceTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

/// `autoscaler` spec of a horizontal pod autoscaler to set up for the plugin Deployment.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorConsolePluginAutoscalerStatus {
    Disabled,
    Enabled,
}

/// `consolePlugin` defines the settings related to the OpenShift Console plugin, when available.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorConsolePluginImagePullPolicy {
    IfNotPresent,
    Always,
    Never,
}

/// `consolePlugin` defines the settings related to the OpenShift Console plugin, when available.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorConsolePluginLogLevel {
    #[serde(rename = "trace")]
    Trace,
    #[serde(rename = "debug")]
    Debug,
    #[serde(rename = "info")]
    Info,
    #[serde(rename = "warn")]
    Warn,
    #[serde(rename = "error")]
    Error,
    #[serde(rename = "fatal")]
    Fatal,
    #[serde(rename = "panic")]
    Panic,
}

/// `portNaming` defines the configuration of the port-to-service name translation
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginPortNaming {
    /// Enable the console plugin port-to-service name translation
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `portNames` defines additional port names to use in the console, for example, `portNames: {"3100": "loki"}`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "portNames")]
    pub port_names: Option<BTreeMap<String, String>>,
}

/// `QuickFilter` defines preset configuration for Console's quick filters
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginQuickFilters {
    /// `default` defines whether this filter should be active by default or not
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub default: Option<bool>,
    /// `filter` is a set of keys and values to be set when this filter is selected. Each key can relate to a list of values using a coma-separated string, for example, `filter: {"src_namespace": "namespace1,namespace2"}`.
    pub filter: BTreeMap<String, String>,
    /// Name of the filter, that is displayed in the Console
    pub name: String,
}

/// `resources`, in terms of compute resources, required by this container. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginResources {
    /// Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container. 
    ///  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate. 
    ///  This field is immutable. It can only be set for containers.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub claims: Option<Vec<FlowCollectorConsolePluginResourcesClaims>>,
    /// Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub limits: Option<BTreeMap<String, IntOrString>>,
    /// Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub requests: Option<BTreeMap<String, IntOrString>>,
}

/// ResourceClaim references one entry in PodSpec.ResourceClaims.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorConsolePluginResourcesClaims {
    /// Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
    pub name: String,
}

/// Defines the desired state of the FlowCollector resource. <br><br> *: the mention of "unsupported", or "deprecated" for a feature throughout this document means that this feature is not officially supported by Red Hat. It might have been, for example, contributed by the community and accepted without a formal agreement for maintenance. The product maintainers might provide some support for these features as a best effort only.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorDeploymentModel {
    Direct,
    Kafka,
}

/// `FlowCollectorExporter` defines an additional exporter to send enriched flows to.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorExporters {
    /// IPFIX configuration, such as the IP address and port to send enriched IPFIX flows to.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub ipfix: Option<FlowCollectorExportersIpfix>,
    /// Kafka configuration, such as the address and topic, to send enriched flows to.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub kafka: Option<FlowCollectorExportersKafka>,
    /// `type` selects the type of exporters. The available options are `Kafka` and `IPFIX`.
    #[serde(rename = "type")]
    pub r#type: FlowCollectorExportersType,
}

/// IPFIX configuration, such as the IP address and port to send enriched IPFIX flows to.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorExportersIpfix {
    /// Address of the IPFIX external receiver
    #[serde(rename = "targetHost")]
    pub target_host: String,
    /// Port for the IPFIX external receiver
    #[serde(rename = "targetPort")]
    pub target_port: i64,
    /// Transport protocol (`TCP` or `UDP`) to be used for the IPFIX connection, defaults to `TCP`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub transport: Option<FlowCollectorExportersIpfixTransport>,
}

/// IPFIX configuration, such as the IP address and port to send enriched IPFIX flows to.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorExportersIpfixTransport {
    #[serde(rename = "TCP")]
    Tcp,
    #[serde(rename = "UDP")]
    Udp,
}

/// Kafka configuration, such as the address and topic, to send enriched flows to.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorExportersKafka {
    /// Address of the Kafka server
    pub address: String,
    /// SASL authentication configuration. [Unsupported (*)].
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub sasl: Option<FlowCollectorExportersKafkaSasl>,
    /// TLS client configuration. When using TLS, verify that the address matches the Kafka port used for TLS, generally 9093.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<FlowCollectorExportersKafkaTls>,
    /// Kafka topic to use. It must exist. NetObserv does not create it.
    pub topic: String,
}

/// SASL authentication configuration. [Unsupported (*)].
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorExportersKafkaSasl {
    /// Reference to the secret or config map containing the client ID
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clientIDReference")]
    pub client_id_reference: Option<FlowCollectorExportersKafkaSaslClientIdReference>,
    /// Reference to the secret or config map containing the client secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clientSecretReference")]
    pub client_secret_reference: Option<FlowCollectorExportersKafkaSaslClientSecretReference>,
    /// Type of SASL authentication to use, or `Disabled` if SASL is not used
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorExportersKafkaSaslType>,
}

/// Reference to the secret or config map containing the client ID
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorExportersKafkaSaslClientIdReference {
    /// File name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub file: Option<String>,
    /// Name of the config map or secret containing the file
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing the file. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the file reference: "configmap" or "secret"
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorExportersKafkaSaslClientIdReferenceType>,
}

/// Reference to the secret or config map containing the client ID
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorExportersKafkaSaslClientIdReferenceType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// Reference to the secret or config map containing the client secret
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorExportersKafkaSaslClientSecretReference {
    /// File name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub file: Option<String>,
    /// Name of the config map or secret containing the file
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing the file. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the file reference: "configmap" or "secret"
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorExportersKafkaSaslClientSecretReferenceType>,
}

/// Reference to the secret or config map containing the client secret
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorExportersKafkaSaslClientSecretReferenceType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// SASL authentication configuration. [Unsupported (*)].
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorExportersKafkaSaslType {
    Disabled,
    Plain,
    #[serde(rename = "ScramSHA512")]
    ScramSha512,
}

/// TLS client configuration. When using TLS, verify that the address matches the Kafka port used for TLS, generally 9093.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorExportersKafkaTls {
    /// `caCert` defines the reference of the certificate for the Certificate Authority
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "caCert")]
    pub ca_cert: Option<FlowCollectorExportersKafkaTlsCaCert>,
    /// Enable TLS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `insecureSkipVerify` allows skipping client-side verification of the server certificate. If set to `true`, the `caCert` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userCert")]
    pub user_cert: Option<FlowCollectorExportersKafkaTlsUserCert>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorExportersKafkaTlsCaCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorExportersKafkaTlsCaCertType>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorExportersKafkaTlsCaCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorExportersKafkaTlsUserCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorExportersKafkaTlsUserCertType>,
}

/// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorExportersKafkaTlsUserCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `FlowCollectorExporter` defines an additional exporter to send enriched flows to.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorExportersType {
    Kafka,
    #[serde(rename = "IPFIX")]
    Ipfix,
}

/// Kafka configuration, allowing to use Kafka as a broker as part of the flow collection pipeline. Available when the `spec.deploymentModel` is `Kafka`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorKafka {
    /// Address of the Kafka server
    pub address: String,
    /// SASL authentication configuration. [Unsupported (*)].
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub sasl: Option<FlowCollectorKafkaSasl>,
    /// TLS client configuration. When using TLS, verify that the address matches the Kafka port used for TLS, generally 9093.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<FlowCollectorKafkaTls>,
    /// Kafka topic to use. It must exist. NetObserv does not create it.
    pub topic: String,
}

/// SASL authentication configuration. [Unsupported (*)].
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorKafkaSasl {
    /// Reference to the secret or config map containing the client ID
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clientIDReference")]
    pub client_id_reference: Option<FlowCollectorKafkaSaslClientIdReference>,
    /// Reference to the secret or config map containing the client secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clientSecretReference")]
    pub client_secret_reference: Option<FlowCollectorKafkaSaslClientSecretReference>,
    /// Type of SASL authentication to use, or `Disabled` if SASL is not used
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorKafkaSaslType>,
}

/// Reference to the secret or config map containing the client ID
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorKafkaSaslClientIdReference {
    /// File name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub file: Option<String>,
    /// Name of the config map or secret containing the file
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing the file. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the file reference: "configmap" or "secret"
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorKafkaSaslClientIdReferenceType>,
}

/// Reference to the secret or config map containing the client ID
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorKafkaSaslClientIdReferenceType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// Reference to the secret or config map containing the client secret
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorKafkaSaslClientSecretReference {
    /// File name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub file: Option<String>,
    /// Name of the config map or secret containing the file
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing the file. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the file reference: "configmap" or "secret"
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorKafkaSaslClientSecretReferenceType>,
}

/// Reference to the secret or config map containing the client secret
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorKafkaSaslClientSecretReferenceType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// SASL authentication configuration. [Unsupported (*)].
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorKafkaSaslType {
    Disabled,
    Plain,
    #[serde(rename = "ScramSHA512")]
    ScramSha512,
}

/// TLS client configuration. When using TLS, verify that the address matches the Kafka port used for TLS, generally 9093.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorKafkaTls {
    /// `caCert` defines the reference of the certificate for the Certificate Authority
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "caCert")]
    pub ca_cert: Option<FlowCollectorKafkaTlsCaCert>,
    /// Enable TLS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `insecureSkipVerify` allows skipping client-side verification of the server certificate. If set to `true`, the `caCert` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userCert")]
    pub user_cert: Option<FlowCollectorKafkaTlsUserCert>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorKafkaTlsCaCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorKafkaTlsCaCertType>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorKafkaTlsCaCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorKafkaTlsUserCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorKafkaTlsUserCertType>,
}

/// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorKafkaTlsUserCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `loki`, the flow store, client settings.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLoki {
    /// `advanced` allows setting some aspects of the internal configuration of the Loki clients. This section is aimed mostly for debugging and fine-grained performance optimizations.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub advanced: Option<FlowCollectorLokiAdvanced>,
    /// Set `enable` to `true` to store flows in Loki. It is required for the OpenShift Console plugin installation.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// Loki configuration for `LokiStack` mode. This is useful for an easy loki-operator configuration. It is ignored for other modes.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "lokiStack")]
    pub loki_stack: Option<FlowCollectorLokiLokiStack>,
    /// Loki configuration for `Manual` mode. This is the most flexible configuration. It is ignored for other modes.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub manual: Option<FlowCollectorLokiManual>,
    /// Loki configuration for `Microservices` mode. Use this option when Loki is installed using the microservices deployment mode (https://grafana.com/docs/loki/latest/fundamentals/architecture/deployment-modes/#microservices-mode). It is ignored for other modes.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub microservices: Option<FlowCollectorLokiMicroservices>,
    /// `mode` must be set according to the installation mode of Loki:<br> - Use `LokiStack` when Loki is managed using the Loki Operator<br> - Use `Monolithic` when Loki is installed as a monolithic workload<br> - Use `Microservices` when Loki is installed as microservices, but without Loki Operator<br> - Use `Manual` if none of the options above match your setup<br>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub mode: Option<FlowCollectorLokiMode>,
    /// Loki configuration for `Monolithic` mode. Use this option when Loki is installed using the monolithic deployment mode (https://grafana.com/docs/loki/latest/fundamentals/architecture/deployment-modes/#monolithic-mode). It is ignored for other modes.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub monolithic: Option<FlowCollectorLokiMonolithic>,
    /// `readTimeout` is the maximum console plugin loki query total time limit. A timeout of zero means no timeout.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "readTimeout")]
    pub read_timeout: Option<String>,
    /// `writeBatchSize` is the maximum batch size (in bytes) of Loki logs to accumulate before sending.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeBatchSize")]
    pub write_batch_size: Option<i64>,
    /// `writeBatchWait` is the maximum time to wait before sending a Loki batch.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeBatchWait")]
    pub write_batch_wait: Option<String>,
    /// `writeTimeout` is the maximum Loki time connection / request limit. A timeout of zero means no timeout.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeTimeout")]
    pub write_timeout: Option<String>,
}

/// `advanced` allows setting some aspects of the internal configuration of the Loki clients. This section is aimed mostly for debugging and fine-grained performance optimizations.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLokiAdvanced {
    /// `staticLabels` is a map of common labels to set on each flow in Loki storage.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "staticLabels")]
    pub static_labels: Option<BTreeMap<String, String>>,
    /// `writeMaxBackoff` is the maximum backoff time for Loki client connection between retries.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeMaxBackoff")]
    pub write_max_backoff: Option<String>,
    /// `writeMaxRetries` is the maximum number of retries for Loki client connections.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeMaxRetries")]
    pub write_max_retries: Option<i32>,
    /// `writeMinBackoff` is the initial backoff time for Loki client connection between retries.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeMinBackoff")]
    pub write_min_backoff: Option<String>,
}

/// Loki configuration for `LokiStack` mode. This is useful for an easy loki-operator configuration. It is ignored for other modes.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLokiLokiStack {
    /// Name of an existing LokiStack resource to use.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace where this `LokiStack` resource is located. If omitted, it is assumed to be the same as `spec.namespace`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
}

/// Loki configuration for `Manual` mode. This is the most flexible configuration. It is ignored for other modes.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLokiManual {
    /// `authToken` describes the way to get a token to authenticate to Loki.<br> - `Disabled` does not send any token with the request.<br> - `Forward` forwards the user token for authorization.<br> - `Host` [deprecated (*)] - uses the local pod service account to authenticate to Loki.<br> When using the Loki Operator, this must be set to `Forward`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "authToken")]
    pub auth_token: Option<FlowCollectorLokiManualAuthToken>,
    /// `ingesterUrl` is the address of an existing Loki ingester service to push the flows to. When using the Loki Operator, set it to the Loki gateway service with the `network` tenant set in path, for example https://loki-gateway-http.netobserv.svc:8080/api/logs/v1/network.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ingesterUrl")]
    pub ingester_url: Option<String>,
    /// `querierUrl` specifies the address of the Loki querier service. When using the Loki Operator, set it to the Loki gateway service with the `network` tenant set in path, for example https://loki-gateway-http.netobserv.svc:8080/api/logs/v1/network.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "querierUrl")]
    pub querier_url: Option<String>,
    /// TLS client configuration for Loki status URL.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "statusTls")]
    pub status_tls: Option<FlowCollectorLokiManualStatusTls>,
    /// `statusUrl` specifies the address of the Loki `/ready`, `/metrics` and `/config` endpoints, in case it is different from the Loki querier URL. If empty, the `querierUrl` value is used. This is useful to show error messages and some context in the frontend. When using the Loki Operator, set it to the Loki HTTP query frontend service, for example https://loki-query-frontend-http.netobserv.svc:3100/. `statusTLS` configuration is used when `statusUrl` is set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "statusUrl")]
    pub status_url: Option<String>,
    /// `tenantID` is the Loki `X-Scope-OrgID` that identifies the tenant for each request. When using the Loki Operator, set it to `network`, which corresponds to a special tenant mode.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tenantID")]
    pub tenant_id: Option<String>,
    /// TLS client configuration for Loki URL.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<FlowCollectorLokiManualTls>,
}

/// Loki configuration for `Manual` mode. This is the most flexible configuration. It is ignored for other modes.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiManualAuthToken {
    Disabled,
    Host,
    Forward,
}

/// TLS client configuration for Loki status URL.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLokiManualStatusTls {
    /// `caCert` defines the reference of the certificate for the Certificate Authority
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "caCert")]
    pub ca_cert: Option<FlowCollectorLokiManualStatusTlsCaCert>,
    /// Enable TLS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `insecureSkipVerify` allows skipping client-side verification of the server certificate. If set to `true`, the `caCert` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userCert")]
    pub user_cert: Option<FlowCollectorLokiManualStatusTlsUserCert>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLokiManualStatusTlsCaCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorLokiManualStatusTlsCaCertType>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiManualStatusTlsCaCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLokiManualStatusTlsUserCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorLokiManualStatusTlsUserCertType>,
}

/// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiManualStatusTlsUserCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// TLS client configuration for Loki URL.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLokiManualTls {
    /// `caCert` defines the reference of the certificate for the Certificate Authority
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "caCert")]
    pub ca_cert: Option<FlowCollectorLokiManualTlsCaCert>,
    /// Enable TLS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `insecureSkipVerify` allows skipping client-side verification of the server certificate. If set to `true`, the `caCert` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userCert")]
    pub user_cert: Option<FlowCollectorLokiManualTlsUserCert>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLokiManualTlsCaCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorLokiManualTlsCaCertType>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiManualTlsCaCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLokiManualTlsUserCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorLokiManualTlsUserCertType>,
}

/// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiManualTlsUserCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// Loki configuration for `Microservices` mode. Use this option when Loki is installed using the microservices deployment mode (https://grafana.com/docs/loki/latest/fundamentals/architecture/deployment-modes/#microservices-mode). It is ignored for other modes.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLokiMicroservices {
    /// `ingesterUrl` is the address of an existing Loki ingester service to push the flows to.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ingesterUrl")]
    pub ingester_url: Option<String>,
    /// `querierURL` specifies the address of the Loki querier service.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "querierUrl")]
    pub querier_url: Option<String>,
    /// `tenantID` is the Loki `X-Scope-OrgID` header that identifies the tenant for each request.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tenantID")]
    pub tenant_id: Option<String>,
    /// TLS client configuration for Loki URL.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<FlowCollectorLokiMicroservicesTls>,
}

/// TLS client configuration for Loki URL.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLokiMicroservicesTls {
    /// `caCert` defines the reference of the certificate for the Certificate Authority
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "caCert")]
    pub ca_cert: Option<FlowCollectorLokiMicroservicesTlsCaCert>,
    /// Enable TLS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `insecureSkipVerify` allows skipping client-side verification of the server certificate. If set to `true`, the `caCert` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userCert")]
    pub user_cert: Option<FlowCollectorLokiMicroservicesTlsUserCert>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLokiMicroservicesTlsCaCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorLokiMicroservicesTlsCaCertType>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiMicroservicesTlsCaCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLokiMicroservicesTlsUserCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorLokiMicroservicesTlsUserCertType>,
}

/// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiMicroservicesTlsUserCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `loki`, the flow store, client settings.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiMode {
    Manual,
    LokiStack,
    Monolithic,
    Microservices,
}

/// Loki configuration for `Monolithic` mode. Use this option when Loki is installed using the monolithic deployment mode (https://grafana.com/docs/loki/latest/fundamentals/architecture/deployment-modes/#monolithic-mode). It is ignored for other modes.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLokiMonolithic {
    /// `tenantID` is the Loki `X-Scope-OrgID` header that identifies the tenant for each request.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tenantID")]
    pub tenant_id: Option<String>,
    /// TLS client configuration for Loki URL.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<FlowCollectorLokiMonolithicTls>,
    /// `url` is the unique address of an existing Loki service that points to both the ingester and the querier.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub url: Option<String>,
}

/// TLS client configuration for Loki URL.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLokiMonolithicTls {
    /// `caCert` defines the reference of the certificate for the Certificate Authority
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "caCert")]
    pub ca_cert: Option<FlowCollectorLokiMonolithicTlsCaCert>,
    /// Enable TLS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `insecureSkipVerify` allows skipping client-side verification of the server certificate. If set to `true`, the `caCert` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userCert")]
    pub user_cert: Option<FlowCollectorLokiMonolithicTlsUserCert>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLokiMonolithicTlsCaCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorLokiMonolithicTlsCaCertType>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiMonolithicTlsCaCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLokiMonolithicTlsUserCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorLokiMonolithicTlsUserCertType>,
}

/// `userCert` defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiMonolithicTlsUserCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `processor` defines the settings of the component that receives the flows from the agent, enriches them, generates metrics, and forwards them to the Loki persistence layer and/or any available exporter.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessor {
    /// `addZone` allows availability zone awareness by labelling flows with their source and destination zones. This feature requires the "topology.kubernetes.io/zone" label to be set on nodes.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "addZone")]
    pub add_zone: Option<bool>,
    /// `advanced` allows setting some aspects of the internal configuration of the flow processor. This section is aimed mostly for debugging and fine-grained performance optimizations, such as `GOGC` and `GOMAXPROCS` env vars. Set these values at your own risk.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub advanced: Option<FlowCollectorProcessorAdvanced>,
    /// `clusterName` is the name of the cluster to appear in the flows data. This is useful in a multi-cluster context. When using OpenShift, leave empty to make it automatically determined.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clusterName")]
    pub cluster_name: Option<String>,
    /// `imagePullPolicy` is the Kubernetes pull policy for the image defined above
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "imagePullPolicy")]
    pub image_pull_policy: Option<FlowCollectorProcessorImagePullPolicy>,
    /// `kafkaConsumerAutoscaler` is the spec of a horizontal pod autoscaler to set up for `flowlogs-pipeline-transformer`, which consumes Kafka messages. This setting is ignored when Kafka is disabled.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kafkaConsumerAutoscaler")]
    pub kafka_consumer_autoscaler: Option<FlowCollectorProcessorKafkaConsumerAutoscaler>,
    /// `kafkaConsumerBatchSize` indicates to the broker the maximum batch size, in bytes, that the consumer accepts. Ignored when not using Kafka. Default: 10MB.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kafkaConsumerBatchSize")]
    pub kafka_consumer_batch_size: Option<i64>,
    /// `kafkaConsumerQueueCapacity` defines the capacity of the internal message queue used in the Kafka consumer client. Ignored when not using Kafka.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kafkaConsumerQueueCapacity")]
    pub kafka_consumer_queue_capacity: Option<i64>,
    /// `kafkaConsumerReplicas` defines the number of replicas (pods) to start for `flowlogs-pipeline-transformer`, which consumes Kafka messages. This setting is ignored when Kafka is disabled.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kafkaConsumerReplicas")]
    pub kafka_consumer_replicas: Option<i32>,
    /// `logLevel` of the processor runtime
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "logLevel")]
    pub log_level: Option<FlowCollectorProcessorLogLevel>,
    /// `logTypes` defines the desired record types to generate. Possible values are:<br> - `Flows` (default) to export regular network flows<br> - `Conversations` to generate events for started conversations, ended conversations as well as periodic "tick" updates<br> - `EndedConversations` to generate only ended conversations events<br> - `All` to generate both network flows and all conversations events<br>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "logTypes")]
    pub log_types: Option<FlowCollectorProcessorLogTypes>,
    /// `Metrics` define the processor configuration regarding metrics
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metrics: Option<FlowCollectorProcessorMetrics>,
    /// Set `multiClusterDeployment` to `true` to enable multi clusters feature. This adds `clusterName` label to flows data
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "multiClusterDeployment")]
    pub multi_cluster_deployment: Option<bool>,
    /// `resources` are the compute resources required by this container. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resources: Option<FlowCollectorProcessorResources>,
    /// `SubnetLabels` allows to define custom labels on subnets and IPs or to enable automatic labelling of recognized subnets in OpenShift.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "subnetLabels")]
    pub subnet_labels: Option<FlowCollectorProcessorSubnetLabels>,
}

/// `advanced` allows setting some aspects of the internal configuration of the flow processor. This section is aimed mostly for debugging and fine-grained performance optimizations, such as `GOGC` and `GOMAXPROCS` env vars. Set these values at your own risk.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvanced {
    /// If specified, the pod's scheduling constraints. For documentation, refer to https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub affinity: Option<FlowCollectorProcessorAdvancedAffinity>,
    /// `conversationEndTimeout` is the time to wait after a network flow is received, to consider the conversation ended. This delay is ignored when a FIN packet is collected for TCP flows (see `conversationTerminatingTimeout` instead).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "conversationEndTimeout")]
    pub conversation_end_timeout: Option<String>,
    /// `conversationHeartbeatInterval` is the time to wait between "tick" events of a conversation
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "conversationHeartbeatInterval")]
    pub conversation_heartbeat_interval: Option<String>,
    /// `conversationTerminatingTimeout` is the time to wait from detected FIN flag to end a conversation. Only relevant for TCP flows.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "conversationTerminatingTimeout")]
    pub conversation_terminating_timeout: Option<String>,
    /// `dropUnusedFields` [deprecated (*)] this setting is not used anymore.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dropUnusedFields")]
    pub drop_unused_fields: Option<bool>,
    /// `enableKubeProbes` is a flag to enable or disable Kubernetes liveness and readiness probes
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableKubeProbes")]
    pub enable_kube_probes: Option<bool>,
    /// `env` allows passing custom environment variables to underlying components. Useful for passing some very concrete performance-tuning options, such as `GOGC` and `GOMAXPROCS`, that should not be publicly exposed as part of the FlowCollector descriptor, as they are only useful in edge debug or support scenarios.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub env: Option<BTreeMap<String, String>>,
    /// `healthPort` is a collector HTTP port in the Pod that exposes the health check API
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "healthPort")]
    pub health_port: Option<i32>,
    /// NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeSelector")]
    pub node_selector: Option<BTreeMap<String, String>>,
    /// Port of the flow collector (host port). By convention, some values are forbidden. It must be greater than 1024 and different from 4500, 4789 and 6081.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub port: Option<i32>,
    /// If specified, indicates the pod's priority. "system-node-critical" and "system-cluster-critical" are two special keywords which indicate the highest priorities with the former being the highest priority. Any other name must be defined by creating a PriorityClass object with that name. If not specified, the pod priority will be default or zero if there is no default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "priorityClassName")]
    pub priority_class_name: Option<String>,
    /// `profilePort` allows setting up a Go pprof profiler listening to this port
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "profilePort")]
    pub profile_port: Option<i32>,
}

/// If specified, the pod's scheduling constraints. For documentation, refer to https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinity {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeAffinity")]
    pub node_affinity: Option<FlowCollectorProcessorAdvancedAffinityNodeAffinity>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podAffinity")]
    pub pod_affinity: Option<FlowCollectorProcessorAdvancedAffinityPodAffinity>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podAntiAffinity")]
    pub pod_anti_affinity: Option<FlowCollectorProcessorAdvancedAffinityPodAntiAffinity>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityNodeAffinity {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorProcessorAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<FlowCollectorProcessorAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    pub preference: FlowCollectorProcessorAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference,
    pub weight: i32,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchFields")]
    pub match_fields: Option<Vec<FlowCollectorProcessorAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    #[serde(rename = "nodeSelectorTerms")]
    pub node_selector_terms: Vec<FlowCollectorProcessorAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchFields")]
    pub match_fields: Option<Vec<FlowCollectorProcessorAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAffinity {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorProcessorAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorProcessorAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    #[serde(rename = "podAffinityTerm")]
    pub pod_affinity_term: FlowCollectorProcessorAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm,
    pub weight: i32,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorProcessorAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorProcessorAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorProcessorAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorProcessorAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAntiAffinity {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorProcessorAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorProcessorAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    #[serde(rename = "podAffinityTerm")]
    pub pod_affinity_term: FlowCollectorProcessorAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm,
    pub weight: i32,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorProcessorAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorProcessorAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorProcessorAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorProcessorAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorAdvancedAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// `processor` defines the settings of the component that receives the flows from the agent, enriches them, generates metrics, and forwards them to the Loki persistence layer and/or any available exporter.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorImagePullPolicy {
    IfNotPresent,
    Always,
    Never,
}

/// `kafkaConsumerAutoscaler` is the spec of a horizontal pod autoscaler to set up for `flowlogs-pipeline-transformer`, which consumes Kafka messages. This setting is ignored when Kafka is disabled.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscaler {
    /// `maxReplicas` is the upper limit for the number of pods that can be set by the autoscaler; cannot be smaller than MinReplicas.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxReplicas")]
    pub max_replicas: Option<i32>,
    /// Metrics used by the pod autoscaler. For documentation, refer to https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/horizontal-pod-autoscaler-v2/
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metrics: Option<Vec<FlowCollectorProcessorKafkaConsumerAutoscalerMetrics>>,
    /// `minReplicas` is the lower limit for the number of replicas to which the autoscaler can scale down. It defaults to 1 pod. minReplicas is allowed to be 0 if the alpha feature gate HPAScaleToZero is enabled and at least one Object or External metric is configured. Scaling is active as long as at least one metric value is available.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "minReplicas")]
    pub min_replicas: Option<i32>,
    /// `status` describes the desired status regarding deploying an horizontal pod autoscaler.<br> - `Disabled` does not deploy an horizontal pod autoscaler.<br> - `Enabled` deploys an horizontal pod autoscaler.<br>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub status: Option<FlowCollectorProcessorKafkaConsumerAutoscalerStatus>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetrics {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "containerResource")]
    pub container_resource: Option<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsContainerResource>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub external: Option<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternal>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub object: Option<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObject>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub pods: Option<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPods>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resource: Option<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsResource>,
    #[serde(rename = "type")]
    pub r#type: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsContainerResource {
    pub container: String,
    pub name: String,
    pub target: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsContainerResourceTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsContainerResourceTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternal {
    pub metric: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternalMetric,
    pub target: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternalTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternalMetric {
    pub name: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selector: Option<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternalMetricSelector>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternalMetricSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternalMetricSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternalMetricSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternalTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObject {
    #[serde(rename = "describedObject")]
    pub described_object: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectDescribedObject,
    pub metric: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectMetric,
    pub target: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectDescribedObject {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiVersion")]
    pub api_version: Option<String>,
    pub kind: String,
    pub name: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectMetric {
    pub name: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selector: Option<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectMetricSelector>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectMetricSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectMetricSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectMetricSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPods {
    pub metric: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPodsMetric,
    pub target: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPodsTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPodsMetric {
    pub name: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selector: Option<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPodsMetricSelector>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPodsMetricSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPodsMetricSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPodsMetricSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPodsTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsResource {
    pub name: String,
    pub target: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsResourceTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsResourceTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

/// `kafkaConsumerAutoscaler` is the spec of a horizontal pod autoscaler to set up for `flowlogs-pipeline-transformer`, which consumes Kafka messages. This setting is ignored when Kafka is disabled.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorKafkaConsumerAutoscalerStatus {
    Disabled,
    Enabled,
}

/// `processor` defines the settings of the component that receives the flows from the agent, enriches them, generates metrics, and forwards them to the Loki persistence layer and/or any available exporter.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorLogLevel {
    #[serde(rename = "trace")]
    Trace,
    #[serde(rename = "debug")]
    Debug,
    #[serde(rename = "info")]
    Info,
    #[serde(rename = "warn")]
    Warn,
    #[serde(rename = "error")]
    Error,
    #[serde(rename = "fatal")]
    Fatal,
    #[serde(rename = "panic")]
    Panic,
}

/// `processor` defines the settings of the component that receives the flows from the agent, enriches them, generates metrics, and forwards them to the Loki persistence layer and/or any available exporter.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorLogTypes {
    Flows,
    Conversations,
    EndedConversations,
    All,
}

/// `Metrics` define the processor configuration regarding metrics
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorMetrics {
    /// `disableAlerts` is a list of alerts that should be disabled. Possible values are:<br> `NetObservNoFlows`, which is triggered when no flows are being observed for a certain period.<br> `NetObservLokiError`, which is triggered when flows are being dropped due to Loki errors.<br>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "disableAlerts")]
    pub disable_alerts: Option<Vec<String>>,
    /// `includeList` is a list of metric names to specify which ones to generate. The names correspond to the names in Prometheus without the prefix. For example, `namespace_egress_packets_total` shows up as `netobserv_namespace_egress_packets_total` in Prometheus. Note that the more metrics you add, the bigger is the impact on Prometheus workload resources. Metrics enabled by default are: `namespace_flows_total`, `node_ingress_bytes_total`, `workload_ingress_bytes_total`, `namespace_drop_packets_total` (when `PacketDrop` feature is enabled), `namespace_rtt_seconds` (when `FlowRTT` feature is enabled), `namespace_dns_latency_seconds` (when `DNSTracking` feature is enabled). More information, with full list of available metrics: https://github.com/netobserv/network-observability-operator/blob/main/docs/Metrics.md
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "includeList")]
    pub include_list: Option<Vec<String>>,
    /// Metrics server endpoint configuration for Prometheus scraper
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub server: Option<FlowCollectorProcessorMetricsServer>,
}

/// Metrics server endpoint configuration for Prometheus scraper
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorMetricsServer {
    /// The prometheus HTTP port
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub port: Option<i32>,
    /// TLS configuration.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<FlowCollectorProcessorMetricsServerTls>,
}

/// TLS configuration.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorMetricsServerTls {
    /// `insecureSkipVerify` allows skipping client-side verification of the provided certificate. If set to `true`, the `providedCaFile` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// TLS configuration when `type` is set to `Provided`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub provided: Option<FlowCollectorProcessorMetricsServerTlsProvided>,
    /// Reference to the CA file when `type` is set to `Provided`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "providedCaFile")]
    pub provided_ca_file: Option<FlowCollectorProcessorMetricsServerTlsProvidedCaFile>,
    /// Select the type of TLS configuration:<br> - `Disabled` (default) to not configure TLS for the endpoint. - `Provided` to manually provide cert file and a key file. [Unsupported (*)]. - `Auto` to use OpenShift auto generated certificate using annotations.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorProcessorMetricsServerTlsType>,
}

/// TLS configuration when `type` is set to `Provided`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorMetricsServerTlsProvided {
    /// `certFile` defines the path to the certificate file name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorProcessorMetricsServerTlsProvidedType>,
}

/// TLS configuration when `type` is set to `Provided`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorMetricsServerTlsProvidedType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// Reference to the CA file when `type` is set to `Provided`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorMetricsServerTlsProvidedCaFile {
    /// File name within the config map or secret
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub file: Option<String>,
    /// Name of the config map or secret containing the file
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing the file. If omitted, the default is to use the same namespace as where NetObserv is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the file reference: "configmap" or "secret"
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorProcessorMetricsServerTlsProvidedCaFileType>,
}

/// Reference to the CA file when `type` is set to `Provided`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorMetricsServerTlsProvidedCaFileType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// TLS configuration.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorMetricsServerTlsType {
    Disabled,
    Provided,
    Auto,
}

/// `resources` are the compute resources required by this container. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorResources {
    /// Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container. 
    ///  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate. 
    ///  This field is immutable. It can only be set for containers.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub claims: Option<Vec<FlowCollectorProcessorResourcesClaims>>,
    /// Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub limits: Option<BTreeMap<String, IntOrString>>,
    /// Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub requests: Option<BTreeMap<String, IntOrString>>,
}

/// ResourceClaim references one entry in PodSpec.ResourceClaims.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorResourcesClaims {
    /// Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
    pub name: String,
}

/// `SubnetLabels` allows to define custom labels on subnets and IPs or to enable automatic labelling of recognized subnets in OpenShift.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorSubnetLabels {
    /// `customLabels` allows to customize subnets and IPs labelling, such as to identify cluster-external workloads or web services. If you enable `openShiftAutoDetect`, `customLabels` can override the detected subnets in case they overlap.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "customLabels")]
    pub custom_labels: Option<Vec<FlowCollectorProcessorSubnetLabelsCustomLabels>>,
    /// `openShiftAutoDetect` allows, when set to `true`, to detect automatically the machines, pods and services subnets based on the OpenShift install configuration and the Cluster Network Operator configuration.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "openShiftAutoDetect")]
    pub open_shift_auto_detect: Option<bool>,
}

/// SubnetLabel allows to label subnets and IPs, such as to identify cluster-external workloads or web services.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorSubnetLabelsCustomLabels {
    /// List of CIDRs, such as `["1.2.3.4/32"]`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub cidrs: Option<Vec<String>>,
    /// Label name, used to flag matching flows.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// `FlowCollectorStatus` defines the observed state of FlowCollector
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorStatus {
    /// `conditions` represent the latest available observations of an object's state
    pub conditions: Vec<Condition>,
    /// Namespace where console plugin and flowlogs-pipeline have been deployed. Deprecated: annotations are used instead
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
}

