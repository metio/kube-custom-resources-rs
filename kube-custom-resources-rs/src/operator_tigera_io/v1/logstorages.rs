// WARNING: generated by kopium - manual changes will be overwritten
// kopium command: kopium --docs --filename=./crd-catalog/tigera/operator/operator.tigera.io/v1/logstorages.yaml --derive=PartialEq
// kopium version: 0.16.5

use kube::CustomResource;
use serde::{Serialize, Deserialize};
use std::collections::BTreeMap;
use k8s_openapi::apimachinery::pkg::util::intstr::IntOrString;

/// Specification of the desired state for Tigera log storage.
#[derive(CustomResource, Serialize, Deserialize, Clone, Debug, PartialEq)]
#[kube(group = "operator.tigera.io", version = "v1", kind = "LogStorage", plural = "logstorages")]
#[kube(status = "LogStorageStatus")]
#[kube(schema = "disabled")]
pub struct LogStorageSpec {
    /// ComponentResources can be used to customize the resource requirements for each component. Only ECKOperator is supported for this spec.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "componentResources")]
    pub component_resources: Option<Vec<LogStorageComponentResources>>,
    /// DataNodeSelector gives you more control over the node that Elasticsearch will run on. The contents of DataNodeSelector will be added to the PodSpec of the Elasticsearch nodes. For the pod to be eligible to run on a node, the node must have each of the indicated key-value pairs as labels as well as access to the specified StorageClassName.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataNodeSelector")]
    pub data_node_selector: Option<BTreeMap<String, String>>,
    /// Index defines the configuration for the indices in the Elasticsearch cluster.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub indices: Option<LogStorageIndices>,
    /// Nodes defines the configuration for a set of identical Elasticsearch cluster nodes, each of type master, data, and ingest.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub nodes: Option<LogStorageNodes>,
    /// Retention defines how long data is retained in the Elasticsearch cluster before it is cleared.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub retention: Option<LogStorageRetention>,
    /// StorageClassName will populate the PersistentVolumeClaim.StorageClassName that is used to provision disks to the Tigera Elasticsearch cluster. The StorageClassName should only be modified when no LogStorage is currently active. We recommend choosing a storage class dedicated to Tigera LogStorage only. Otherwise, data retention cannot be guaranteed during upgrades. See https://docs.tigera.io/maintenance/upgrading for up-to-date instructions. Default: tigera-elasticsearch
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "storageClassName")]
    pub storage_class_name: Option<String>,
}

/// The ComponentResource struct associates a ResourceRequirements with a component by name
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogStorageComponentResources {
    /// ComponentName is an enum which identifies the component
    #[serde(rename = "componentName")]
    pub component_name: LogStorageComponentResourcesComponentName,
    /// ResourceRequirements allows customization of limits and requests for compute resources such as cpu and memory.
    #[serde(rename = "resourceRequirements")]
    pub resource_requirements: LogStorageComponentResourcesResourceRequirements,
}

/// The ComponentResource struct associates a ResourceRequirements with a component by name
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum LogStorageComponentResourcesComponentName {
    #[serde(rename = "ECKOperator")]
    EckOperator,
}

/// ResourceRequirements allows customization of limits and requests for compute resources such as cpu and memory.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogStorageComponentResourcesResourceRequirements {
    /// Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container. 
    ///  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate. 
    ///  This field is immutable. It can only be set for containers.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub claims: Option<Vec<LogStorageComponentResourcesResourceRequirementsClaims>>,
    /// Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub limits: Option<BTreeMap<String, IntOrString>>,
    /// Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub requests: Option<BTreeMap<String, IntOrString>>,
}

/// ResourceClaim references one entry in PodSpec.ResourceClaims.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogStorageComponentResourcesResourceRequirementsClaims {
    /// Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
    pub name: String,
}

/// Index defines the configuration for the indices in the Elasticsearch cluster.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogStorageIndices {
    /// Replicas defines how many replicas each index will have. See https://www.elastic.co/guide/en/elasticsearch/reference/current/scalability.html
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub replicas: Option<i32>,
}

/// Nodes defines the configuration for a set of identical Elasticsearch cluster nodes, each of type master, data, and ingest.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogStorageNodes {
    /// Count defines the number of nodes in the Elasticsearch cluster.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub count: Option<i64>,
    /// NodeSets defines configuration specific to each Elasticsearch Node Set
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeSets")]
    pub node_sets: Option<Vec<LogStorageNodesNodeSets>>,
    /// ResourceRequirements defines the resource limits and requirements for the Elasticsearch cluster.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "resourceRequirements")]
    pub resource_requirements: Option<LogStorageNodesResourceRequirements>,
}

/// NodeSets defines configuration specific to each Elasticsearch Node Set
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogStorageNodesNodeSets {
    /// SelectionAttributes defines K8s node attributes a NodeSet should use when setting the Node Affinity selectors and Elasticsearch cluster awareness attributes for the Elasticsearch nodes. The list of SelectionAttributes are used to define Node Affinities and set the node awareness configuration in the running Elasticsearch instance.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "selectionAttributes")]
    pub selection_attributes: Option<Vec<LogStorageNodesNodeSetsSelectionAttributes>>,
}

/// NodeSetSelectionAttribute defines a K8s node "attribute" the Elasticsearch nodes should be aware of. The "Name" and "Value" are used together to set the "awareness" attributes in Elasticsearch, while the "NodeLabel" and "Value" are used together to define Node Affinity for the Pods created for the Elasticsearch nodes.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogStorageNodesNodeSetsSelectionAttributes {
    pub name: String,
    #[serde(rename = "nodeLabel")]
    pub node_label: String,
    pub value: String,
}

/// ResourceRequirements defines the resource limits and requirements for the Elasticsearch cluster.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogStorageNodesResourceRequirements {
    /// Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container. 
    ///  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate. 
    ///  This field is immutable. It can only be set for containers.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub claims: Option<Vec<LogStorageNodesResourceRequirementsClaims>>,
    /// Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub limits: Option<BTreeMap<String, IntOrString>>,
    /// Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub requests: Option<BTreeMap<String, IntOrString>>,
}

/// ResourceClaim references one entry in PodSpec.ResourceClaims.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogStorageNodesResourceRequirementsClaims {
    /// Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
    pub name: String,
}

/// Retention defines how long data is retained in the Elasticsearch cluster before it is cleared.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogStorageRetention {
    /// AuditReports configures the retention period for audit logs, in days.  Logs written on a day that started at least this long ago are removed.  To keep logs for at least x days, use a retention period of x+1. Default: 91
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "auditReports")]
    pub audit_reports: Option<i32>,
    /// BGPLogs configures the retention period for BGP logs, in days.  Logs written on a day that started at least this long ago are removed.  To keep logs for at least x days, use a retention period of x+1. Default: 8
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "bgpLogs")]
    pub bgp_logs: Option<i32>,
    /// ComplianceReports configures the retention period for compliance reports, in days. Reports are output from the analysis of the system state and audit events for compliance reporting. Consult the Compliance Reporting documentation for more details on reports. Logs written on a day that started at least this long ago are removed.  To keep logs for at least x days, use a retention period of x+1. Default: 91
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "complianceReports")]
    pub compliance_reports: Option<i32>,
    /// DNSLogs configures the retention period for DNS logs, in days.  Logs written on a day that started at least this long ago are removed.  To keep logs for at least x days, use a retention period of x+1. Default: 8
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dnsLogs")]
    pub dns_logs: Option<i32>,
    /// Flows configures the retention period for flow logs, in days.  Logs written on a day that started at least this long ago are removed.  To keep logs for at least x days, use a retention period of x+1. Default: 8
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub flows: Option<i32>,
    /// Snapshots configures the retention period for snapshots, in days. Snapshots are periodic captures of resources which along with audit events are used to generate reports. Consult the Compliance Reporting documentation for more details on snapshots. Logs written on a day that started at least this long ago are removed.  To keep logs for at least x days, use a retention period of x+1. Default: 91
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub snapshots: Option<i32>,
}

/// Most recently observed state for Tigera log storage.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogStorageStatus {
    /// Conditions represents the latest observed set of conditions for the component. A component may be one or more of Ready, Progressing, Degraded or other customer types.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub conditions: Option<Vec<LogStorageStatusConditions>>,
    /// ElasticsearchHash represents the current revision and configuration of the installed Elasticsearch cluster. This is an opaque string which can be monitored for changes to perform actions when Elasticsearch is modified.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "elasticsearchHash")]
    pub elasticsearch_hash: Option<String>,
    /// KibanaHash represents the current revision and configuration of the installed Kibana dashboard. This is an opaque string which can be monitored for changes to perform actions when Kibana is modified.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kibanaHash")]
    pub kibana_hash: Option<String>,
    /// State provides user-readable status.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub state: Option<String>,
}

/// Condition contains details for one aspect of the current state of this API Resource. --- This struct is intended for direct use as an array at the field path .status.conditions.  For example, 
///  type FooStatus struct{ // Represents the observations of a foo's current state. // Known .status.conditions.type are: "Available", "Progressing", and "Degraded" // +patchMergeKey=type // +patchStrategy=merge // +listType=map // +listMapKey=type Conditions []metav1.Condition `json:"conditions,omitempty" patchStrategy:"merge" patchMergeKey:"type" protobuf:"bytes,1,rep,name=conditions"` 
///  // other fields }
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogStorageStatusConditions {
    /// lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
    #[serde(rename = "lastTransitionTime")]
    pub last_transition_time: String,
    /// message is a human readable message indicating details about the transition. This may be an empty string.
    pub message: String,
    /// observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "observedGeneration")]
    pub observed_generation: Option<i64>,
    /// reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty.
    pub reason: String,
    /// status of the condition, one of True, False, Unknown.
    pub status: LogStorageStatusConditionsStatus,
    /// type of condition in CamelCase or in foo.example.com/CamelCase. --- Many .condition.type values are consistent across resources like Available, but because arbitrary conditions can be useful (see .node.status.conditions), the ability to deconflict is important. The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt)
    #[serde(rename = "type")]
    pub r#type: String,
}

/// Condition contains details for one aspect of the current state of this API Resource. --- This struct is intended for direct use as an array at the field path .status.conditions.  For example, 
///  type FooStatus struct{ // Represents the observations of a foo's current state. // Known .status.conditions.type are: "Available", "Progressing", and "Degraded" // +patchMergeKey=type // +patchStrategy=merge // +listType=map // +listMapKey=type Conditions []metav1.Condition `json:"conditions,omitempty" patchStrategy:"merge" patchMergeKey:"type" protobuf:"bytes,1,rep,name=conditions"` 
///  // other fields }
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum LogStorageStatusConditionsStatus {
    True,
    False,
    Unknown,
}

