// WARNING: generated by kopium - manual changes will be overwritten
// kopium command: kopium --docs --filename=./crd-catalog/tigera/operator/operator.tigera.io/v1/logcollectors.yaml --derive=PartialEq
// kopium version: 0.16.5

use kube::CustomResource;
use serde::{Serialize, Deserialize};

/// Specification of the desired state for Tigera log collection.
#[derive(CustomResource, Serialize, Deserialize, Clone, Debug, PartialEq)]
#[kube(group = "operator.tigera.io", version = "v1", kind = "LogCollector", plural = "logcollectors")]
#[kube(status = "LogCollectorStatus")]
#[kube(schema = "disabled")]
pub struct LogCollectorSpec {
    /// Configuration for importing audit logs from managed kubernetes cluster log sources.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "additionalSources")]
    pub additional_sources: Option<LogCollectorAdditionalSources>,
    /// Configuration for exporting flow, audit, and DNS logs to external storage.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "additionalStores")]
    pub additional_stores: Option<LogCollectorAdditionalStores>,
    /// Configuration for enabling/disabling process path collection in flowlogs. If Enabled, this feature sets hostPID to true in order to read process cmdline. Default: Enabled
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "collectProcessPath")]
    pub collect_process_path: Option<LogCollectorCollectProcessPath>,
    /// If running as a multi-tenant management cluster, the namespace in which the management cluster's tenant services are running.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "multiTenantManagementClusterNamespace")]
    pub multi_tenant_management_cluster_namespace: Option<String>,
}

/// Configuration for importing audit logs from managed kubernetes cluster log sources.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogCollectorAdditionalSources {
    /// If specified with EKS Provider in Installation, enables fetching EKS audit logs.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "eksCloudwatchLog")]
    pub eks_cloudwatch_log: Option<LogCollectorAdditionalSourcesEksCloudwatchLog>,
}

/// If specified with EKS Provider in Installation, enables fetching EKS audit logs.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogCollectorAdditionalSourcesEksCloudwatchLog {
    /// Cloudwatch audit logs fetching interval in seconds. Default: 60
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fetchInterval")]
    pub fetch_interval: Option<i32>,
    /// Cloudwatch log-group name containing EKS audit logs.
    #[serde(rename = "groupName")]
    pub group_name: String,
    /// AWS Region EKS cluster is hosted in.
    pub region: String,
    /// Prefix of Cloudwatch log stream containing EKS audit logs in the log-group. Default: kube-apiserver-audit-
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "streamPrefix")]
    pub stream_prefix: Option<String>,
}

/// Configuration for exporting flow, audit, and DNS logs to external storage.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogCollectorAdditionalStores {
    /// If specified, enables exporting of flow, audit, and DNS logs to Amazon S3 storage.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub s3: Option<LogCollectorAdditionalStoresS3>,
    /// If specified, enables exporting of flow, audit, and DNS logs to splunk.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub splunk: Option<LogCollectorAdditionalStoresSplunk>,
    /// If specified, enables exporting of flow, audit, and DNS logs to syslog.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub syslog: Option<LogCollectorAdditionalStoresSyslog>,
}

/// If specified, enables exporting of flow, audit, and DNS logs to Amazon S3 storage.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogCollectorAdditionalStoresS3 {
    /// Name of the S3 bucket to send logs
    #[serde(rename = "bucketName")]
    pub bucket_name: String,
    /// Path in the S3 bucket where to send logs
    #[serde(rename = "bucketPath")]
    pub bucket_path: String,
    /// AWS Region of the S3 bucket
    pub region: String,
}

/// If specified, enables exporting of flow, audit, and DNS logs to splunk.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogCollectorAdditionalStoresSplunk {
    /// Location for splunk's http event collector end point. example `https://1.2.3.4:8088`
    pub endpoint: String,
}

/// If specified, enables exporting of flow, audit, and DNS logs to syslog.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogCollectorAdditionalStoresSyslog {
    /// Encryption configures traffic encryption to the Syslog server. Default: None
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encryption: Option<LogCollectorAdditionalStoresSyslogEncryption>,
    /// Location of the syslog server. example: tcp://1.2.3.4:601
    pub endpoint: String,
    /// If no values are provided, the list will be updated to include log types Audit, DNS and Flows. Default: Audit, DNS, Flows
    #[serde(rename = "logTypes")]
    pub log_types: Vec<String>,
    /// PacketSize defines the maximum size of packets to send to syslog. In general this is only needed if you notice long logs being truncated. Default: 1024
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "packetSize")]
    pub packet_size: Option<i32>,
}

/// If specified, enables exporting of flow, audit, and DNS logs to syslog.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum LogCollectorAdditionalStoresSyslogEncryption {
    None,
    #[serde(rename = "TLS")]
    Tls,
}

/// Specification of the desired state for Tigera log collection.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum LogCollectorCollectProcessPath {
    Enabled,
    Disabled,
}

/// Most recently observed state for Tigera log collection.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogCollectorStatus {
    /// Conditions represents the latest observed set of conditions for the component. A component may be one or more of Ready, Progressing, Degraded or other customer types.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub conditions: Option<Vec<LogCollectorStatusConditions>>,
    /// State provides user-readable status.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub state: Option<String>,
}

/// Condition contains details for one aspect of the current state of this API Resource. --- This struct is intended for direct use as an array at the field path .status.conditions.  For example, 
///  type FooStatus struct{ // Represents the observations of a foo's current state. // Known .status.conditions.type are: "Available", "Progressing", and "Degraded" // +patchMergeKey=type // +patchStrategy=merge // +listType=map // +listMapKey=type Conditions []metav1.Condition `json:"conditions,omitempty" patchStrategy:"merge" patchMergeKey:"type" protobuf:"bytes,1,rep,name=conditions"` 
///  // other fields }
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct LogCollectorStatusConditions {
    /// lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
    #[serde(rename = "lastTransitionTime")]
    pub last_transition_time: String,
    /// message is a human readable message indicating details about the transition. This may be an empty string.
    pub message: String,
    /// observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "observedGeneration")]
    pub observed_generation: Option<i64>,
    /// reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty.
    pub reason: String,
    /// status of the condition, one of True, False, Unknown.
    pub status: LogCollectorStatusConditionsStatus,
    /// type of condition in CamelCase or in foo.example.com/CamelCase. --- Many .condition.type values are consistent across resources like Available, but because arbitrary conditions can be useful (see .node.status.conditions), the ability to deconflict is important. The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt)
    #[serde(rename = "type")]
    pub r#type: String,
}

/// Condition contains details for one aspect of the current state of this API Resource. --- This struct is intended for direct use as an array at the field path .status.conditions.  For example, 
///  type FooStatus struct{ // Represents the observations of a foo's current state. // Known .status.conditions.type are: "Available", "Progressing", and "Degraded" // +patchMergeKey=type // +patchStrategy=merge // +listType=map // +listMapKey=type Conditions []metav1.Condition `json:"conditions,omitempty" patchStrategy:"merge" patchMergeKey:"type" protobuf:"bytes,1,rep,name=conditions"` 
///  // other fields }
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum LogCollectorStatusConditionsStatus {
    True,
    False,
    Unknown,
}

