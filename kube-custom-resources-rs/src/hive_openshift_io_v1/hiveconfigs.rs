// WARNING: generated by kopium - manual changes will be overwritten
// kopium command: kopium --derive Default --derive PartialEq --docs --filename ./crd-catalog/openshift/hive/hive.openshift.io/v1/hiveconfigs.yaml
// kopium version: 0.16.1

use kube::CustomResource;
use serde::{Serialize, Deserialize};
use std::collections::BTreeMap;
use k8s_openapi::apimachinery::pkg::util::intstr::IntOrString;

/// HiveConfigSpec defines the desired state of Hive
#[derive(CustomResource, Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
#[kube(group = "hive.openshift.io", version = "v1", kind = "HiveConfig", plural = "hiveconfigs")]
#[kube(status = "HiveConfigStatus")]
#[kube(schema = "disabled")]
pub struct HiveConfigSpec {
    /// AdditionalCertificateAuthoritiesSecretRef is a list of references to secrets in the TargetNamespace that contain an additional Certificate Authority to use when communicating with target clusters. These certificate authorities will be used in addition to any self-signed CA generated by each cluster on installation. The cert data should be stored in the Secret key named 'ca.crt'.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "additionalCertificateAuthoritiesSecretRef")]
    pub additional_certificate_authorities_secret_ref: Option<Vec<HiveConfigAdditionalCertificateAuthoritiesSecretRef>>,
    /// ArgoCD specifies configuration for ArgoCD integration. If enabled, Hive will automatically add provisioned clusters to ArgoCD, and remove them when they are deprovisioned.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "argoCDConfig")]
    pub argo_cd_config: Option<HiveConfigArgoCdConfig>,
    /// AWSPrivateLink defines the configuration for the aws-private-link controller. It provides 3 major pieces of information required by the controller, 1. The Credentials that should be used to create AWS PrivateLink resources other than what exist in the customer's account. 2. A list of VPCs that can be used by the controller to choose one to create AWS VPC Endpoints for the AWS VPC Endpoint Services created for ClusterDeployments in their corresponding regions. 3. A list of VPCs that should be able to resolve the DNS addresses setup for Private Link.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "awsPrivateLink")]
    pub aws_private_link: Option<HiveConfigAwsPrivateLink>,
    /// Backup specifies configuration for backup integration. If absent, backup integration will be disabled.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub backup: Option<HiveConfigBackup>,
    /// ControllersConfig is used to configure different hive controllers
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "controllersConfig")]
    pub controllers_config: Option<HiveConfigControllersConfig>,
    /// DeleteProtection can be set to "enabled" to turn on automatic delete protection for ClusterDeployments. When enabled, Hive will add the "hive.openshift.io/protected-delete" annotation to new ClusterDeployments. Once a ClusterDeployment has been installed, a user must remove the annotation from a ClusterDeployment prior to deleting it.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "deleteProtection")]
    pub delete_protection: Option<HiveConfigDeleteProtection>,
    /// DeploymentConfig is used to configure (pods/containers of) the Deployments generated by hive-operator.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "deploymentConfig")]
    pub deployment_config: Option<Vec<HiveConfigDeploymentConfig>>,
    /// DeprovisionsDisabled can be set to true to block deprovision jobs from running.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "deprovisionsDisabled")]
    pub deprovisions_disabled: Option<bool>,
    /// DisabledControllers allows selectively disabling Hive controllers by name. The name of an individual controller matches the name of the controller as seen in the Hive logging output.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "disabledControllers")]
    pub disabled_controllers: Option<Vec<String>>,
    /// ExportMetrics has been disabled and has no effect. If upgrading from a version where it was active, please be aware of the following in your HiveConfig.Spec.TargetNamespace (default `hive` if unset): 1) ServiceMonitors named hive-controllers and hive-clustersync; 2) Role and RoleBinding named prometheus-k8s; 3) The `openshift.io/cluster-monitoring` metadata.label on the Namespace itself. You may wish to delete these resources. Or you may wish to continue using them to enable monitoring in your environment; but be aware that hive will no longer reconcile them.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "exportMetrics")]
    pub export_metrics: Option<bool>,
    /// FailedProvisionConfig is used to configure settings related to handling provision failures.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "failedProvisionConfig")]
    pub failed_provision_config: Option<HiveConfigFailedProvisionConfig>,
    /// FeatureGateSelection allows selecting feature gates for the controller.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "featureGates")]
    pub feature_gates: Option<HiveConfigFeatureGates>,
    /// GlobalPullSecretRef is used to specify a pull secret that will be used globally by all of the cluster deployments. For each cluster deployment, the contents of GlobalPullSecret will be merged with the specific pull secret for a cluster deployment(if specified), with precedence given to the contents of the pull secret for the cluster deployment. The global pull secret is assumed to be in the TargetNamespace.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "globalPullSecretRef")]
    pub global_pull_secret_ref: Option<HiveConfigGlobalPullSecretRef>,
    /// LogLevel is the level of logging to use for the Hive controllers. Acceptable levels, from coarsest to finest, are panic, fatal, error, warn, info, debug, and trace. The default level is info.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "logLevel")]
    pub log_level: Option<String>,
    /// MaintenanceMode can be set to true to disable the hive controllers in situations where we need to ensure nothing is running that will add or act upon finalizers on Hive types. This should rarely be needed. Sets replicas to 0 for the hive-controllers deployment to accomplish this.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maintenanceMode")]
    pub maintenance_mode: Option<bool>,
    /// ManagedDomains is the list of DNS domains that are managed by the Hive cluster When specifying 'manageDNS: true' in a ClusterDeployment, the ClusterDeployment's baseDomain should be a direct child of one of these domains, otherwise the ClusterDeployment creation will result in a validation error.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "managedDomains")]
    pub managed_domains: Option<Vec<HiveConfigManagedDomains>>,
    /// MetricsConfig encapsulates metrics specific configurations, like opting in for certain metrics.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "metricsConfig")]
    pub metrics_config: Option<HiveConfigMetricsConfig>,
    /// ReleaseImageVerificationConfigMapRef is a reference to the ConfigMap that will be used to verify release images. 
    ///  The config map structure is exactly the same as the config map used for verification of release images for OpenShift 4 during upgrades. Therefore you can usually set this to the config map shipped as part of OpenShift (openshift-config-managed/release-verification). 
    ///  See https://github.com/openshift/cluster-update-keys for more details. The keys within the config map in the data field define how verification is performed: 
    ///  verifier-public-key-*: One or more GPG public keys in ASCII form that must have signed the release image by digest. 
    ///  store-*: A URL (scheme file://, http://, or https://) location that contains signatures. These signatures are in the atomic container signature format. The URL will have the digest of the image appended to it as "<STORE>/<ALGO>=<DIGEST>/signature-<NUMBER>" as described in the container image signing format. The docker-image-manifest section of the signature must match the release image digest. Signatures are searched starting at NUMBER 1 and incrementing if the signature exists but is not valid. The signature is a GPG signed and encrypted JSON message. The file store is provided for testing only at the current time, although future versions of the CVO might allow host mounting of signatures. 
    ///  See https://github.com/containers/image/blob/ab49b0a48428c623a8f03b41b9083d48966b34a9/docs/signature-protocols.md for a description of the signature store 
    ///  The returned verifier will require that any new release image will only be considered verified if each provided public key has signed the release image digest. The signature may be in any store and the lookup order is internally defined. 
    ///  If not set, no verification will be performed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "releaseImageVerificationConfigMapRef")]
    pub release_image_verification_config_map_ref: Option<HiveConfigReleaseImageVerificationConfigMapRef>,
    /// ServiceProviderCredentialsConfig is used to configure credentials related to being a service provider on various cloud platforms.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "serviceProviderCredentialsConfig")]
    pub service_provider_credentials_config: Option<HiveConfigServiceProviderCredentialsConfig>,
    /// SyncSetReapplyInterval is a string duration indicating how much time must pass before SyncSet resources will be reapplied. The default reapply interval is two hours.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "syncSetReapplyInterval")]
    pub sync_set_reapply_interval: Option<String>,
    /// TargetNamespace is the namespace where the core Hive components should be run. Defaults to "hive". Will be created if it does not already exist. All resource references in HiveConfig can be assumed to be in the TargetNamespace. NOTE: Whereas it is possible to edit this value, causing hive to "move" its core components to the new namespace, the old namespace is not deleted, as it will still contain resources created by kubernetes and/or other OpenShift controllers.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "targetNamespace")]
    pub target_namespace: Option<String>,
}

/// LocalObjectReference contains enough information to let you locate the referenced object inside the same namespace.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigAdditionalCertificateAuthoritiesSecretRef {
    /// Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// ArgoCD specifies configuration for ArgoCD integration. If enabled, Hive will automatically add provisioned clusters to ArgoCD, and remove them when they are deprovisioned.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigArgoCdConfig {
    /// Enabled dictates if ArgoCD gitops integration is enabled. If not specified, the default is disabled.
    pub enabled: bool,
    /// Namespace specifies the namespace where ArgoCD is installed. Used for the location of cluster secrets. Defaults to "argocd"
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
}

/// AWSPrivateLink defines the configuration for the aws-private-link controller. It provides 3 major pieces of information required by the controller, 1. The Credentials that should be used to create AWS PrivateLink resources other than what exist in the customer's account. 2. A list of VPCs that can be used by the controller to choose one to create AWS VPC Endpoints for the AWS VPC Endpoint Services created for ClusterDeployments in their corresponding regions. 3. A list of VPCs that should be able to resolve the DNS addresses setup for Private Link.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigAwsPrivateLink {
    /// AssociatedVPCs is the list of VPCs that should be able to resolve the DNS addresses setup for Private Link. This allows clients in VPC to resolve the AWS PrivateLink address using AWS's default DNS resolver for Private Route53 Hosted Zones. 
    ///  This list should at minimum include the VPC where the current Hive controller is running.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "associatedVPCs")]
    pub associated_vp_cs: Option<Vec<HiveConfigAwsPrivateLinkAssociatedVpCs>>,
    /// CredentialsSecretRef references a secret in the TargetNamespace that will be used to authenticate with AWS for creating the resources for AWS PrivateLink.
    #[serde(rename = "credentialsSecretRef")]
    pub credentials_secret_ref: HiveConfigAwsPrivateLinkCredentialsSecretRef,
    /// DNSRecordType defines what type of DNS record should be created in Private Hosted Zone for the customer cluster's API endpoint (which is the VPC Endpoint's regional DNS name).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dnsRecordType")]
    pub dns_record_type: Option<HiveConfigAwsPrivateLinkDnsRecordType>,
    /// EndpointVPCInventory is a list of VPCs and the corresponding subnets in various AWS regions. The controller uses this list to choose a VPC for creating AWS VPC Endpoints. Since the VPC Endpoints must be in the same region as the ClusterDeployment, we must have VPCs in that region to be able to setup Private Link.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "endpointVPCInventory")]
    pub endpoint_vpc_inventory: Option<Vec<HiveConfigAwsPrivateLinkEndpointVpcInventory>>,
}

/// AWSAssociatedVPC defines a VPC that should be able to resolve the DNS addresses setup for Private Link.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigAwsPrivateLinkAssociatedVpCs {
    /// CredentialsSecretRef references a secret in the TargetNamespace that will be used to authenticate with AWS for associating the VPC with the Private HostedZone created for PrivateLink. When not provided, the common credentials for the controller should be used.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "credentialsSecretRef")]
    pub credentials_secret_ref: Option<HiveConfigAwsPrivateLinkAssociatedVpCsCredentialsSecretRef>,
    pub region: String,
    #[serde(rename = "vpcID")]
    pub vpc_id: String,
}

/// CredentialsSecretRef references a secret in the TargetNamespace that will be used to authenticate with AWS for associating the VPC with the Private HostedZone created for PrivateLink. When not provided, the common credentials for the controller should be used.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigAwsPrivateLinkAssociatedVpCsCredentialsSecretRef {
    /// Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// CredentialsSecretRef references a secret in the TargetNamespace that will be used to authenticate with AWS for creating the resources for AWS PrivateLink.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigAwsPrivateLinkCredentialsSecretRef {
    /// Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// AWSPrivateLink defines the configuration for the aws-private-link controller. It provides 3 major pieces of information required by the controller, 1. The Credentials that should be used to create AWS PrivateLink resources other than what exist in the customer's account. 2. A list of VPCs that can be used by the controller to choose one to create AWS VPC Endpoints for the AWS VPC Endpoint Services created for ClusterDeployments in their corresponding regions. 3. A list of VPCs that should be able to resolve the DNS addresses setup for Private Link.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum HiveConfigAwsPrivateLinkDnsRecordType {
    Alias,
    ARecord,
}

/// AWSPrivateLinkInventory is a VPC and its corresponding subnets in an AWS region. This VPC will be used to create an AWS VPC Endpoint whenever there is a VPC Endpoint Service created for a ClusterDeployment.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigAwsPrivateLinkEndpointVpcInventory {
    pub region: String,
    pub subnets: Vec<HiveConfigAwsPrivateLinkEndpointVpcInventorySubnets>,
    #[serde(rename = "vpcID")]
    pub vpc_id: String,
}

/// AWSPrivateLinkSubnet defines a subnet in the an AWS VPC.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigAwsPrivateLinkEndpointVpcInventorySubnets {
    #[serde(rename = "availabilityZone")]
    pub availability_zone: String,
    #[serde(rename = "subnetID")]
    pub subnet_id: String,
}

/// Backup specifies configuration for backup integration. If absent, backup integration will be disabled.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigBackup {
    /// MinBackupPeriodSeconds specifies that a minimum of MinBackupPeriodSeconds will occur in between each backup. This is used to rate limit backups. This potentially batches together multiple changes into 1 backup. No backups will be lost as changes that happen during this interval are queued up and will result in a backup happening once the interval has been completed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "minBackupPeriodSeconds")]
    pub min_backup_period_seconds: Option<i64>,
    /// Velero specifies configuration for the Velero backup integration.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub velero: Option<HiveConfigBackupVelero>,
}

/// Velero specifies configuration for the Velero backup integration.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigBackupVelero {
    /// Enabled dictates if Velero backup integration is enabled. If not specified, the default is disabled.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enabled: Option<bool>,
    /// Namespace specifies in which namespace velero backup objects should be created. If not specified, the default is a namespace named "velero".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
}

/// ControllersConfig is used to configure different hive controllers
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigControllersConfig {
    /// Controllers contains a list of configurations for different controllers
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub controllers: Option<Vec<HiveConfigControllersConfigControllers>>,
    /// Default specifies default configuration for all the controllers, can be used to override following coded defaults default for concurrent reconciles is 5 default for client qps is 5 default for client burst is 10 default for queue qps is 10 default for queue burst is 100
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub default: Option<HiveConfigControllersConfigDefault>,
}

/// SpecificControllerConfig contains the configuration for a specific controller
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigControllersConfigControllers {
    /// ControllerConfig contains the configuration for the controller specified by Name field
    pub config: HiveConfigControllersConfigControllersConfig,
    /// Name specifies the name of the controller
    pub name: HiveConfigControllersConfigControllersName,
}

/// ControllerConfig contains the configuration for the controller specified by Name field
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigControllersConfigControllersConfig {
    /// ClientBurst specifies client rate limiter burst for a controller
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clientBurst")]
    pub client_burst: Option<i32>,
    /// ClientQPS specifies client rate limiter QPS for a controller
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clientQPS")]
    pub client_qps: Option<i32>,
    /// ConcurrentReconciles specifies number of concurrent reconciles for a controller
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "concurrentReconciles")]
    pub concurrent_reconciles: Option<i32>,
    /// QueueBurst specifies workqueue rate limiter burst for a controller
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "queueBurst")]
    pub queue_burst: Option<i32>,
    /// QueueQPS specifies workqueue rate limiter QPS for a controller
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "queueQPS")]
    pub queue_qps: Option<i32>,
    /// Replicas specifies the number of replicas the specific controller pod should use. This is ONLY for controllers that have been split out into their own pods. This is ignored for all others.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub replicas: Option<i32>,
}

/// SpecificControllerConfig contains the configuration for a specific controller
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum HiveConfigControllersConfigControllersName {
    #[serde(rename = "clusterDeployment")]
    ClusterDeployment,
    #[serde(rename = "clusterrelocate")]
    Clusterrelocate,
    #[serde(rename = "clusterstate")]
    Clusterstate,
    #[serde(rename = "clusterversion")]
    Clusterversion,
    #[serde(rename = "controlPlaneCerts")]
    ControlPlaneCerts,
    #[serde(rename = "dnsendpoint")]
    Dnsendpoint,
    #[serde(rename = "dnszone")]
    Dnszone,
    #[serde(rename = "remoteingress")]
    Remoteingress,
    #[serde(rename = "remotemachineset")]
    Remotemachineset,
    #[serde(rename = "machinepool")]
    Machinepool,
    #[serde(rename = "syncidentityprovider")]
    Syncidentityprovider,
    #[serde(rename = "unreachable")]
    Unreachable,
    #[serde(rename = "velerobackup")]
    Velerobackup,
    #[serde(rename = "clusterprovision")]
    Clusterprovision,
    #[serde(rename = "clusterDeprovision")]
    ClusterDeprovision,
    #[serde(rename = "clusterpool")]
    Clusterpool,
    #[serde(rename = "clusterpoolnamespace")]
    Clusterpoolnamespace,
    #[serde(rename = "hibernation")]
    Hibernation,
    #[serde(rename = "clusterclaim")]
    Clusterclaim,
    #[serde(rename = "metrics")]
    Metrics,
    #[serde(rename = "clustersync")]
    Clustersync,
}

/// Default specifies default configuration for all the controllers, can be used to override following coded defaults default for concurrent reconciles is 5 default for client qps is 5 default for client burst is 10 default for queue qps is 10 default for queue burst is 100
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigControllersConfigDefault {
    /// ClientBurst specifies client rate limiter burst for a controller
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clientBurst")]
    pub client_burst: Option<i32>,
    /// ClientQPS specifies client rate limiter QPS for a controller
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clientQPS")]
    pub client_qps: Option<i32>,
    /// ConcurrentReconciles specifies number of concurrent reconciles for a controller
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "concurrentReconciles")]
    pub concurrent_reconciles: Option<i32>,
    /// QueueBurst specifies workqueue rate limiter burst for a controller
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "queueBurst")]
    pub queue_burst: Option<i32>,
    /// QueueQPS specifies workqueue rate limiter QPS for a controller
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "queueQPS")]
    pub queue_qps: Option<i32>,
    /// Replicas specifies the number of replicas the specific controller pod should use. This is ONLY for controllers that have been split out into their own pods. This is ignored for all others.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub replicas: Option<i32>,
}

/// HiveConfigSpec defines the desired state of Hive
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum HiveConfigDeleteProtection {
    #[serde(rename = "enabled")]
    Enabled,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigDeploymentConfig {
    /// DeploymentName is the name of one of the Deployments/StatefulSets managed by hive-operator. NOTE: At this time each deployment has only one container. In the future, we may provide a way to specify which container this DeploymentConfig will be applied to.
    #[serde(rename = "deploymentName")]
    pub deployment_name: HiveConfigDeploymentConfigDeploymentName,
    /// Resources allows customization of the resource (memory, CPU, etc.) limits and requests used by containers in the Deployment/StatefulSet named by DeploymentName.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resources: Option<HiveConfigDeploymentConfigResources>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum HiveConfigDeploymentConfigDeploymentName {
    #[serde(rename = "hive-controllers")]
    HiveControllers,
    #[serde(rename = "hive-clustersync")]
    HiveClustersync,
    #[serde(rename = "hiveadmission")]
    Hiveadmission,
}

/// Resources allows customization of the resource (memory, CPU, etc.) limits and requests used by containers in the Deployment/StatefulSet named by DeploymentName.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigDeploymentConfigResources {
    /// Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container. 
    ///  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate. 
    ///  This field is immutable. It can only be set for containers.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub claims: Option<Vec<HiveConfigDeploymentConfigResourcesClaims>>,
    /// Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub limits: Option<BTreeMap<String, IntOrString>>,
    /// Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub requests: Option<BTreeMap<String, IntOrString>>,
}

/// ResourceClaim references one entry in PodSpec.ResourceClaims.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigDeploymentConfigResourcesClaims {
    /// Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.
    pub name: String,
}

/// FailedProvisionConfig is used to configure settings related to handling provision failures.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigFailedProvisionConfig {
    /// FailedProvisionAWSConfig contains AWS-specific info to upload log files.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub aws: Option<HiveConfigFailedProvisionConfigAws>,
    /// RetryReasons is a list of installFailingReason strings from the [additional-]install-log-regexes ConfigMaps. If specified, Hive will only retry a failed installation if it results in one of the listed reasons. If omitted (not the same thing as empty!), Hive will retry regardless of the failure reason. (The total number of install attempts is still constrained by ClusterDeployment.Spec.InstallAttemptsLimit.)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "retryReasons")]
    pub retry_reasons: Option<Vec<String>>,
    /// DEPRECATED: This flag is no longer respected and will be removed in the future.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "skipGatherLogs")]
    pub skip_gather_logs: Option<bool>,
}

/// FailedProvisionAWSConfig contains AWS-specific info to upload log files.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigFailedProvisionConfigAws {
    /// Bucket is the S3 bucket to store the logs in.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub bucket: Option<String>,
    /// CredentialsSecretRef references a secret in the TargetNamespace that will be used to authenticate with AWS S3. It will need permission to upload logs to S3. Secret should have keys named aws_access_key_id and aws_secret_access_key that contain the AWS credentials. Example Secret: data: aws_access_key_id: minio aws_secret_access_key: minio123
    #[serde(rename = "credentialsSecretRef")]
    pub credentials_secret_ref: HiveConfigFailedProvisionConfigAwsCredentialsSecretRef,
    /// Region is the AWS region to use for S3 operations. This defaults to us-east-1. For AWS China, use cn-northwest-1.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub region: Option<String>,
    /// ServiceEndpoint is the url to connect to an S3 compatible provider.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "serviceEndpoint")]
    pub service_endpoint: Option<String>,
}

/// CredentialsSecretRef references a secret in the TargetNamespace that will be used to authenticate with AWS S3. It will need permission to upload logs to S3. Secret should have keys named aws_access_key_id and aws_secret_access_key that contain the AWS credentials. Example Secret: data: aws_access_key_id: minio aws_secret_access_key: minio123
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigFailedProvisionConfigAwsCredentialsSecretRef {
    /// Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// FeatureGateSelection allows selecting feature gates for the controller.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigFeatureGates {
    /// custom allows the enabling or disabling of any feature. Because of its nature, this setting cannot be validated.  If you have any typos or accidentally apply invalid combinations might cause unknown behavior. featureSet must equal "Custom" must be set to use this field.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub custom: Option<HiveConfigFeatureGatesCustom>,
    /// featureSet changes the list of features in the cluster.  The default is empty.  Be very careful adjusting this setting.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "featureSet")]
    pub feature_set: Option<HiveConfigFeatureGatesFeatureSet>,
}

/// custom allows the enabling or disabling of any feature. Because of its nature, this setting cannot be validated.  If you have any typos or accidentally apply invalid combinations might cause unknown behavior. featureSet must equal "Custom" must be set to use this field.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigFeatureGatesCustom {
    /// enabled is a list of all feature gates that you want to force on
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enabled: Option<Vec<String>>,
}

/// FeatureGateSelection allows selecting feature gates for the controller.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum HiveConfigFeatureGatesFeatureSet {
    #[serde(rename = "")]
    KopiumEmpty,
    Custom,
}

/// GlobalPullSecretRef is used to specify a pull secret that will be used globally by all of the cluster deployments. For each cluster deployment, the contents of GlobalPullSecret will be merged with the specific pull secret for a cluster deployment(if specified), with precedence given to the contents of the pull secret for the cluster deployment. The global pull secret is assumed to be in the TargetNamespace.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigGlobalPullSecretRef {
    /// Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// ManageDNSConfig contains the domain being managed, and the cloud-specific details for accessing/managing the domain.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigManagedDomains {
    /// AWS contains AWS-specific settings for external DNS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub aws: Option<HiveConfigManagedDomainsAws>,
    /// Azure contains Azure-specific settings for external DNS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub azure: Option<HiveConfigManagedDomainsAzure>,
    /// Domains is the list of domains that hive will be managing entries for with the provided credentials.
    pub domains: Vec<String>,
    /// GCP contains GCP-specific settings for external DNS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub gcp: Option<HiveConfigManagedDomainsGcp>,
}

/// AWS contains AWS-specific settings for external DNS
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigManagedDomainsAws {
    /// CredentialsSecretRef references a secret in the TargetNamespace that will be used to authenticate with AWS Route53. It will need permission to manage entries for the domain listed in the parent ManageDNSConfig object. Secret should have AWS keys named 'aws_access_key_id' and 'aws_secret_access_key'.
    #[serde(rename = "credentialsSecretRef")]
    pub credentials_secret_ref: HiveConfigManagedDomainsAwsCredentialsSecretRef,
    /// Region is the AWS region to use for route53 operations. This defaults to us-east-1. For AWS China, use cn-northwest-1.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub region: Option<String>,
}

/// CredentialsSecretRef references a secret in the TargetNamespace that will be used to authenticate with AWS Route53. It will need permission to manage entries for the domain listed in the parent ManageDNSConfig object. Secret should have AWS keys named 'aws_access_key_id' and 'aws_secret_access_key'.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigManagedDomainsAwsCredentialsSecretRef {
    /// Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// Azure contains Azure-specific settings for external DNS
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigManagedDomainsAzure {
    /// CloudName is the name of the Azure cloud environment which can be used to configure the Azure SDK with the appropriate Azure API endpoints. If empty, the value is equal to "AzurePublicCloud".
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "cloudName")]
    pub cloud_name: Option<HiveConfigManagedDomainsAzureCloudName>,
    /// CredentialsSecretRef references a secret in the TargetNamespace that will be used to authenticate with Azure DNS. It wil need permission to manage entries in each of the managed domains listed in the parent ManageDNSConfig object. Secret should have a key named 'osServicePrincipal.json'
    #[serde(rename = "credentialsSecretRef")]
    pub credentials_secret_ref: HiveConfigManagedDomainsAzureCredentialsSecretRef,
    /// ResourceGroupName specifies the Azure resource group containing the DNS zones for the domains being managed.
    #[serde(rename = "resourceGroupName")]
    pub resource_group_name: String,
}

/// Azure contains Azure-specific settings for external DNS
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum HiveConfigManagedDomainsAzureCloudName {
    #[serde(rename = "")]
    KopiumEmpty,
    AzurePublicCloud,
    #[serde(rename = "AzureUSGovernmentCloud")]
    AzureUsGovernmentCloud,
    AzureChinaCloud,
    AzureGermanCloud,
}

/// CredentialsSecretRef references a secret in the TargetNamespace that will be used to authenticate with Azure DNS. It wil need permission to manage entries in each of the managed domains listed in the parent ManageDNSConfig object. Secret should have a key named 'osServicePrincipal.json'
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigManagedDomainsAzureCredentialsSecretRef {
    /// Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// GCP contains GCP-specific settings for external DNS
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigManagedDomainsGcp {
    /// CredentialsSecretRef references a secret in the TargetNamespace that will be used to authenticate with GCP DNS. It will need permission to manage entries in each of the managed domains for this cluster. listed in the parent ManageDNSConfig object. Secret should have a key named 'osServiceAccount.json'. The credentials must specify the project to use.
    #[serde(rename = "credentialsSecretRef")]
    pub credentials_secret_ref: HiveConfigManagedDomainsGcpCredentialsSecretRef,
}

/// CredentialsSecretRef references a secret in the TargetNamespace that will be used to authenticate with GCP DNS. It will need permission to manage entries in each of the managed domains for this cluster. listed in the parent ManageDNSConfig object. Secret should have a key named 'osServiceAccount.json'. The credentials must specify the project to use.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigManagedDomainsGcpCredentialsSecretRef {
    /// Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// MetricsConfig encapsulates metrics specific configurations, like opting in for certain metrics.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigMetricsConfig {
    /// AdditionalClusterDeploymentLabels allows configuration of additional labels to be applied to certain metrics. The keys can be any string value suitable for a metric label (see https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels). The values can be any ClusterDeployment label key (from metadata.labels). When observing an affected metric, hive will label it with the specified metric key, and copy the value from the specified ClusterDeployment label. For example, including {"ocp_major_version": "hive.openshift.io/version-major"} will cause affected metrics to include a label key ocp_major_version with the value from the hive.openshift.io/version-major ClusterDeployment label -- e.g. "4". NOTE: Avoid ClusterDeployment labels whose values are unbounded, such as those representing cluster names or IDs, as these will cause your prometheus database to grow indefinitely. Affected metrics are those whose type implements the metricsWithDynamicLabels interface found in pkg/controller/metrics/metrics_with_dynamic_labels.go
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "additionalClusterDeploymentLabels")]
    pub additional_cluster_deployment_labels: Option<BTreeMap<String, String>>,
    /// Optional metrics and their configurations
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "metricsWithDuration")]
    pub metrics_with_duration: Option<Vec<HiveConfigMetricsConfigMetricsWithDuration>>,
}

/// MetricsWithDuration represents metrics that report time as values,like transition seconds. The purpose of these metrics should be to track outliers - ensure their duration is not set too low.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigMetricsConfigMetricsWithDuration {
    /// Duration is the minimum time taken - the relevant metric will be logged only if the value reported by that metric is more than the time mentioned here. For example, if a user opts-in for current clusters stopping and mentions 1 hour here, only the clusters stopping for more than an hour will be reported. This is a Duration value; see https://pkg.go.dev/time#ParseDuration for accepted formats.
    pub duration: String,
    /// Name of the metric. It will correspond to an optional relevant metric in hive
    pub name: HiveConfigMetricsConfigMetricsWithDurationName,
}

/// MetricsWithDuration represents metrics that report time as values,like transition seconds. The purpose of these metrics should be to track outliers - ensure their duration is not set too low.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum HiveConfigMetricsConfigMetricsWithDurationName {
    #[serde(rename = "currentStopping")]
    CurrentStopping,
    #[serde(rename = "currentResuming")]
    CurrentResuming,
    #[serde(rename = "currentWaitingForCO")]
    CurrentWaitingForCo,
    #[serde(rename = "currentClusterSyncFailing")]
    CurrentClusterSyncFailing,
    #[serde(rename = "cumulativeHibernated")]
    CumulativeHibernated,
    #[serde(rename = "cumulativeResumed")]
    CumulativeResumed,
}

/// ReleaseImageVerificationConfigMapRef is a reference to the ConfigMap that will be used to verify release images. 
///  The config map structure is exactly the same as the config map used for verification of release images for OpenShift 4 during upgrades. Therefore you can usually set this to the config map shipped as part of OpenShift (openshift-config-managed/release-verification). 
///  See https://github.com/openshift/cluster-update-keys for more details. The keys within the config map in the data field define how verification is performed: 
///  verifier-public-key-*: One or more GPG public keys in ASCII form that must have signed the release image by digest. 
///  store-*: A URL (scheme file://, http://, or https://) location that contains signatures. These signatures are in the atomic container signature format. The URL will have the digest of the image appended to it as "<STORE>/<ALGO>=<DIGEST>/signature-<NUMBER>" as described in the container image signing format. The docker-image-manifest section of the signature must match the release image digest. Signatures are searched starting at NUMBER 1 and incrementing if the signature exists but is not valid. The signature is a GPG signed and encrypted JSON message. The file store is provided for testing only at the current time, although future versions of the CVO might allow host mounting of signatures. 
///  See https://github.com/containers/image/blob/ab49b0a48428c623a8f03b41b9083d48966b34a9/docs/signature-protocols.md for a description of the signature store 
///  The returned verifier will require that any new release image will only be considered verified if each provided public key has signed the release image digest. The signature may be in any store and the lookup order is internally defined. 
///  If not set, no verification will be performed.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigReleaseImageVerificationConfigMapRef {
    /// Name of the ConfigMap
    pub name: String,
    /// Namespace of the ConfigMap
    pub namespace: String,
}

/// ServiceProviderCredentialsConfig is used to configure credentials related to being a service provider on various cloud platforms.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigServiceProviderCredentialsConfig {
    /// AWS is used to configure credentials related to being a service provider on AWS.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub aws: Option<HiveConfigServiceProviderCredentialsConfigAws>,
}

/// AWS is used to configure credentials related to being a service provider on AWS.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigServiceProviderCredentialsConfigAws {
    /// CredentialsSecretRef references a secret in the TargetNamespace that will be used to authenticate with AWS to become the Service Provider. Being a Service Provider allows the controllers to assume the role in customer AWS accounts to manager clusters.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "credentialsSecretRef")]
    pub credentials_secret_ref: Option<HiveConfigServiceProviderCredentialsConfigAwsCredentialsSecretRef>,
}

/// CredentialsSecretRef references a secret in the TargetNamespace that will be used to authenticate with AWS to become the Service Provider. Being a Service Provider allows the controllers to assume the role in customer AWS accounts to manager clusters.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigServiceProviderCredentialsConfigAwsCredentialsSecretRef {
    /// Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// HiveConfigStatus defines the observed state of Hive
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigStatus {
    /// AggregatorClientCAHash keeps an md5 hash of the aggregator client CA configmap data from the openshift-config-managed namespace. When the configmap changes, admission is redeployed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "aggregatorClientCAHash")]
    pub aggregator_client_ca_hash: Option<String>,
    /// Conditions includes more detailed status for the HiveConfig
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub conditions: Option<Vec<HiveConfigStatusConditions>>,
    /// ConfigApplied will be set by the hive operator to indicate whether or not the LastGenerationObserved was successfully reconciled.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configApplied")]
    pub config_applied: Option<bool>,
    /// ObservedGeneration will record the most recently processed HiveConfig object's generation.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "observedGeneration")]
    pub observed_generation: Option<i64>,
}

/// HiveConfigCondition contains details for the current condition of a HiveConfig
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveConfigStatusConditions {
    /// LastProbeTime is the last time we probed the condition.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "lastProbeTime")]
    pub last_probe_time: Option<String>,
    /// LastTransitionTime is the last time the condition transitioned from one status to another.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "lastTransitionTime")]
    pub last_transition_time: Option<String>,
    /// Message is a human-readable message indicating details about last transition.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub message: Option<String>,
    /// Reason is a unique, one-word, CamelCase reason for the condition's last transition.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub reason: Option<String>,
    /// Status is the status of the condition.
    pub status: String,
    /// Type is the type of the condition.
    #[serde(rename = "type")]
    pub r#type: String,
}

