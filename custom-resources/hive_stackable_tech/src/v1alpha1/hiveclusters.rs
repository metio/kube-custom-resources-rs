// WARNING: generated by kopium - manual changes will be overwritten
// kopium command: kopium --docs --derive=Default --derive=PartialEq --smart-derive-elision --filename crd-catalog/stackabletech/hive-operator/hive.stackable.tech/v1alpha1/hiveclusters.yaml
// kopium version: 0.22.5

#[allow(unused_imports)]
mod prelude {
    pub use kube::CustomResource;
    pub use serde::{Serialize, Deserialize};
    pub use std::collections::BTreeMap;
    pub use k8s_openapi::apimachinery::pkg::apis::meta::v1::Condition;
}
use self::prelude::*;

/// A Hive cluster stacklet. This resource is managed by the Stackable operator for Apache Hive.
/// Find more information on how to use it and the resources that the operator generates in the
/// [operator documentation](<https://docs.stackable.tech/home/nightly/hive/).>
#[derive(CustomResource, Serialize, Deserialize, Clone, Debug, PartialEq)]
#[kube(group = "hive.stackable.tech", version = "v1alpha1", kind = "HiveCluster", plural = "hiveclusters")]
#[kube(namespaced)]
#[kube(status = "HiveClusterStatus")]
#[kube(schema = "disabled")]
#[kube(derive="PartialEq")]
pub struct HiveClusterSpec {
    /// Hive metastore settings that affect all roles and role groups.
    /// The settings in the `clusterConfig` are cluster wide settings that do not need to be configurable at role or role group level.
    #[serde(rename = "clusterConfig")]
    pub cluster_config: HiveClusterClusterConfig,
    /// [Cluster operations](<https://docs.stackable.tech/home/nightly/concepts/operations/cluster_operations)>
    /// properties, allow stopping the product instance as well as pausing reconciliation.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clusterOperation")]
    pub cluster_operation: Option<HiveClusterClusterOperation>,
    /// Specify which image to use, the easiest way is to only configure the `productVersion`.
    /// You can also configure a custom image registry to pull from, as well as completely custom
    /// images.
    /// 
    /// Consult the [Product image selection documentation](<https://docs.stackable.tech/home/nightly/concepts/product_image_selection)>
    /// for details.
    pub image: HiveClusterImage,
    /// This struct represents a role - e.g. HDFS datanodes or Trino workers. It has a key-value-map containing
    /// all the roleGroups that are part of this role. Additionally, there is a `config`, which is configurable
    /// at the role *and* roleGroup level. Everything at roleGroup level is merged on top of what is configured
    /// on role level. There is also a second form of config, which can only be configured
    /// at role level, the `roleConfig`.
    /// You can learn more about this in the
    /// [Roles and role group concept documentation](<https://docs.stackable.tech/home/nightly/concepts/roles-and-role-groups).>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metastore: Option<HiveClusterMetastore>,
    /// A list of generic Kubernetes objects, which are merged into the objects that the operator
    /// creates.
    /// 
    /// List entries are arbitrary YAML objects, which need to be valid Kubernetes objects.
    /// 
    /// Read the [Object overrides documentation](<https://docs.stackable.tech/home/nightly/concepts/overrides#object-overrides)>
    /// for more information.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "objectOverrides")]
    pub object_overrides: Option<Vec<BTreeMap<String, serde_json::Value>>>,
}

/// Hive metastore settings that affect all roles and role groups.
/// The settings in the `clusterConfig` are cluster wide settings that do not need to be configurable at role or role group level.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct HiveClusterClusterConfig {
    /// Settings related to user [authentication](<https://docs.stackable.tech/home/nightly/hive/usage-guide/security).>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub authentication: Option<HiveClusterClusterConfigAuthentication>,
    /// Authorization options for Hive.
    /// Learn more in the [Hive authorization usage guide](<https://docs.stackable.tech/home/nightly/hive/usage-guide/security#authorization).>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub authorization: Option<HiveClusterClusterConfigAuthorization>,
    /// Database connection specification for the metadata database.
    pub database: HiveClusterClusterConfigDatabase,
    /// HDFS connection specification.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub hdfs: Option<HiveClusterClusterConfigHdfs>,
    /// S3 connection specification. This can be either `inline` or a `reference` to an
    /// S3Connection object. Read the [S3 concept documentation](<https://docs.stackable.tech/home/nightly/concepts/s3)> to learn more.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub s3: Option<HiveClusterClusterConfigS3>,
    /// Name of the Vector aggregator [discovery ConfigMap](<https://docs.stackable.tech/home/nightly/concepts/service_discovery).>
    /// It must contain the key `ADDRESS` with the address of the Vector aggregator.
    /// Follow the [logging tutorial](<https://docs.stackable.tech/home/nightly/tutorials/logging-vector-aggregator)>
    /// to learn how to configure log aggregation with Vector.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "vectorAggregatorConfigMapName")]
    pub vector_aggregator_config_map_name: Option<String>,
}

/// Settings related to user [authentication](<https://docs.stackable.tech/home/nightly/hive/usage-guide/security).>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterClusterConfigAuthentication {
    /// Kerberos configuration.
    pub kerberos: HiveClusterClusterConfigAuthenticationKerberos,
}

/// Kerberos configuration.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterClusterConfigAuthenticationKerberos {
    /// Name of the SecretClass providing the keytab for the HBase services.
    #[serde(rename = "secretClass")]
    pub secret_class: String,
}

/// Authorization options for Hive.
/// Learn more in the [Hive authorization usage guide](<https://docs.stackable.tech/home/nightly/hive/usage-guide/security#authorization).>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterClusterConfigAuthorization {
    /// Configure the OPA stacklet [discovery ConfigMap](<https://docs.stackable.tech/home/nightly/concepts/service_discovery)>
    /// and the name of the Rego package containing your authorization rules.
    /// Consult the [OPA authorization documentation](<https://docs.stackable.tech/home/nightly/concepts/opa)>
    /// to learn how to deploy Rego authorization rules with OPA.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub opa: Option<HiveClusterClusterConfigAuthorizationOpa>,
}

/// Configure the OPA stacklet [discovery ConfigMap](<https://docs.stackable.tech/home/nightly/concepts/service_discovery)>
/// and the name of the Rego package containing your authorization rules.
/// Consult the [OPA authorization documentation](<https://docs.stackable.tech/home/nightly/concepts/opa)>
/// to learn how to deploy Rego authorization rules with OPA.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterClusterConfigAuthorizationOpa {
    /// The [discovery ConfigMap](<https://docs.stackable.tech/home/nightly/concepts/service_discovery)>
    /// for the OPA stacklet that should be used for authorization requests.
    #[serde(rename = "configMapName")]
    pub config_map_name: String,
    /// The name of the Rego package containing the Rego rules for the product.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub package: Option<String>,
}

/// Database connection specification for the metadata database.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct HiveClusterClusterConfigDatabase {
    /// A connection string for the database. For example:
    /// `jdbc:postgresql://hivehdfs-postgresql:5432/hivehdfs`
    #[serde(rename = "connString")]
    pub conn_string: String,
    /// A reference to a Secret containing the database credentials.
    /// The Secret needs to contain the keys `username` and `password`.
    #[serde(rename = "credentialsSecret")]
    pub credentials_secret: String,
    /// The type of database to connect to. Supported are:
    /// `postgres`, `mysql`, `oracle`, `mssql` and `derby`.
    /// This value is used to configure the jdbc driver class.
    #[serde(rename = "dbType")]
    pub db_type: HiveClusterClusterConfigDatabaseDbType,
}

/// Database connection specification for the metadata database.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum HiveClusterClusterConfigDatabaseDbType {
    #[serde(rename = "derby")]
    Derby,
    #[serde(rename = "mysql")]
    Mysql,
    #[serde(rename = "postgres")]
    Postgres,
    #[serde(rename = "oracle")]
    Oracle,
    #[serde(rename = "mssql")]
    Mssql,
}

/// HDFS connection specification.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterClusterConfigHdfs {
    /// Name of the [discovery ConfigMap](<https://docs.stackable.tech/home/nightly/concepts/service_discovery)>
    /// providing information about the HDFS cluster.
    /// See also the [Stackable Operator for HDFS](<https://docs.stackable.tech/home/nightly/hdfs/)> to learn
    /// more about setting up an HDFS cluster.
    #[serde(rename = "configMap")]
    pub config_map: String,
}

/// S3 connection specification. This can be either `inline` or a `reference` to an
/// S3Connection object. Read the [S3 concept documentation](<https://docs.stackable.tech/home/nightly/concepts/s3)> to learn more.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterClusterConfigS3 {
    /// S3 connection definition as a resource.
    /// Learn more on the [S3 concept documentation](<https://docs.stackable.tech/home/nightly/concepts/s3).>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub inline: Option<HiveClusterClusterConfigS3Inline>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub reference: Option<String>,
}

/// S3 connection definition as a resource.
/// Learn more on the [S3 concept documentation](<https://docs.stackable.tech/home/nightly/concepts/s3).>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterClusterConfigS3Inline {
    /// Which access style to use.
    /// Defaults to virtual hosted-style as most of the data products out there.
    /// Have a look at the [AWS documentation](<https://docs.aws.amazon.com/AmazonS3/latest/userguide/VirtualHosting.html).>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "accessStyle")]
    pub access_style: Option<HiveClusterClusterConfigS3InlineAccessStyle>,
    /// If the S3 uses authentication you have to specify you S3 credentials.
    /// In the most cases a [SecretClass](<https://docs.stackable.tech/home/nightly/secret-operator/secretclass)>
    /// providing `accessKey` and `secretKey` is sufficient.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub credentials: Option<HiveClusterClusterConfigS3InlineCredentials>,
    /// Host of the S3 server without any protocol or port. For example: `west1.my-cloud.com`.
    pub host: String,
    /// Port the S3 server listens on.
    /// If not specified the product will determine the port to use.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub port: Option<u16>,
    /// Bucket region used for signing headers (sigv4).
    /// 
    /// This defaults to `us-east-1` which is compatible with other implementations such as Minio.
    /// 
    /// WARNING: Some products use the Hadoop S3 implementation which falls back to us-east-2.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub region: Option<HiveClusterClusterConfigS3InlineRegion>,
    /// Use a TLS connection. If not specified no TLS will be used.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<HiveClusterClusterConfigS3InlineTls>,
}

/// S3 connection definition as a resource.
/// Learn more on the [S3 concept documentation](<https://docs.stackable.tech/home/nightly/concepts/s3).>
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum HiveClusterClusterConfigS3InlineAccessStyle {
    Path,
    VirtualHosted,
}

/// If the S3 uses authentication you have to specify you S3 credentials.
/// In the most cases a [SecretClass](<https://docs.stackable.tech/home/nightly/secret-operator/secretclass)>
/// providing `accessKey` and `secretKey` is sufficient.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterClusterConfigS3InlineCredentials {
    /// [Scope](<https://docs.stackable.tech/home/nightly/secret-operator/scope)> of the
    /// [SecretClass](<https://docs.stackable.tech/home/nightly/secret-operator/secretclass).>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub scope: Option<HiveClusterClusterConfigS3InlineCredentialsScope>,
    /// [SecretClass](<https://docs.stackable.tech/home/nightly/secret-operator/secretclass)> containing the LDAP bind credentials.
    #[serde(rename = "secretClass")]
    pub secret_class: String,
}

/// [Scope](<https://docs.stackable.tech/home/nightly/secret-operator/scope)> of the
/// [SecretClass](<https://docs.stackable.tech/home/nightly/secret-operator/secretclass).>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterClusterConfigS3InlineCredentialsScope {
    /// The listener volume scope allows Node and Service scopes to be inferred from the applicable listeners.
    /// This must correspond to Volume names in the Pod that mount Listeners.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "listenerVolumes")]
    pub listener_volumes: Option<Vec<String>>,
    /// The node scope is resolved to the name of the Kubernetes Node object that the Pod is running on.
    /// This will typically be the DNS name of the node.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub node: Option<bool>,
    /// The pod scope is resolved to the name of the Kubernetes Pod.
    /// This allows the secret to differentiate between StatefulSet replicas.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub pod: Option<bool>,
    /// The service scope allows Pod objects to specify custom scopes.
    /// This should typically correspond to Service objects that the Pod participates in.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub services: Option<Vec<String>>,
}

/// Bucket region used for signing headers (sigv4).
/// 
/// This defaults to `us-east-1` which is compatible with other implementations such as Minio.
/// 
/// WARNING: Some products use the Hadoop S3 implementation which falls back to us-east-2.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterClusterConfigS3InlineRegion {
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// Use a TLS connection. If not specified no TLS will be used.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterClusterConfigS3InlineTls {
    /// The verification method used to verify the certificates of the server and/or the client.
    pub verification: HiveClusterClusterConfigS3InlineTlsVerification,
}

/// The verification method used to verify the certificates of the server and/or the client.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterClusterConfigS3InlineTlsVerification {
    /// Use TLS but don't verify certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub none: Option<HiveClusterClusterConfigS3InlineTlsVerificationNone>,
    /// Use TLS and a CA certificate to verify the server.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub server: Option<HiveClusterClusterConfigS3InlineTlsVerificationServer>,
}

/// Use TLS but don't verify certificates.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterClusterConfigS3InlineTlsVerificationNone {
}

/// Use TLS and a CA certificate to verify the server.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterClusterConfigS3InlineTlsVerificationServer {
    /// CA cert to verify the server.
    #[serde(rename = "caCert")]
    pub ca_cert: HiveClusterClusterConfigS3InlineTlsVerificationServerCaCert,
}

/// CA cert to verify the server.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterClusterConfigS3InlineTlsVerificationServerCaCert {
    /// Name of the [SecretClass](<https://docs.stackable.tech/home/nightly/secret-operator/secretclass)> which will provide the CA certificate.
    /// Note that a SecretClass does not need to have a key but can also work with just a CA certificate,
    /// so if you got provided with a CA cert but don't have access to the key you can still use this method.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "secretClass")]
    pub secret_class: Option<String>,
    /// Use TLS and the CA certificates trusted by the common web browsers to verify the server.
    /// This can be useful when you e.g. use public AWS S3 or other public available services.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "webPki")]
    pub web_pki: Option<HiveClusterClusterConfigS3InlineTlsVerificationServerCaCertWebPki>,
}

/// Use TLS and the CA certificates trusted by the common web browsers to verify the server.
/// This can be useful when you e.g. use public AWS S3 or other public available services.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterClusterConfigS3InlineTlsVerificationServerCaCertWebPki {
}

/// [Cluster operations](<https://docs.stackable.tech/home/nightly/concepts/operations/cluster_operations)>
/// properties, allow stopping the product instance as well as pausing reconciliation.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterClusterOperation {
    /// Flag to stop cluster reconciliation by the operator. This means that all changes in the
    /// custom resource spec are ignored until this flag is set to false or removed. The operator
    /// will however still watch the deployed resources at the time and update the custom resource
    /// status field.
    /// If applied at the same time with `stopped`, `reconciliationPaused` will take precedence over
    /// `stopped` and stop the reconciliation immediately.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "reconciliationPaused")]
    pub reconciliation_paused: Option<bool>,
    /// Flag to stop the cluster. This means all deployed resources (e.g. Services, StatefulSets,
    /// ConfigMaps) are kept but all deployed Pods (e.g. replicas from a StatefulSet) are scaled to 0
    /// and therefore stopped and removed.
    /// If applied at the same time with `reconciliationPaused`, the latter will pause reconciliation
    /// and `stopped` will take no effect until `reconciliationPaused` is set to false or removed.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub stopped: Option<bool>,
}

/// Specify which image to use, the easiest way is to only configure the `productVersion`.
/// You can also configure a custom image registry to pull from, as well as completely custom
/// images.
/// 
/// Consult the [Product image selection documentation](<https://docs.stackable.tech/home/nightly/concepts/product_image_selection)>
/// for details.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterImage {
    /// Overwrite the docker image.
    /// Specify the full docker image name, e.g. `oci.stackable.tech/sdp/superset:1.4.1-stackable2.1.0`
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub custom: Option<String>,
    /// Version of the product, e.g. `1.4.1`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "productVersion")]
    pub product_version: Option<String>,
    /// [Pull policy](<https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy)> used when pulling the image.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "pullPolicy")]
    pub pull_policy: Option<HiveClusterImagePullPolicy>,
    /// [Image pull secrets](<https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod)> to pull images from a private registry.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "pullSecrets")]
    pub pull_secrets: Option<Vec<HiveClusterImagePullSecrets>>,
    /// Name of the docker repo, e.g. `oci.stackable.tech/sdp`
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub repo: Option<String>,
    /// Stackable version of the product, e.g. `23.4`, `23.4.1` or `0.0.0-dev`.
    /// If not specified, the operator will use its own version, e.g. `23.4.1`.
    /// When using a nightly operator or a pr version, it will use the nightly `0.0.0-dev` image.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "stackableVersion")]
    pub stackable_version: Option<String>,
}

/// Specify which image to use, the easiest way is to only configure the `productVersion`.
/// You can also configure a custom image registry to pull from, as well as completely custom
/// images.
/// 
/// Consult the [Product image selection documentation](<https://docs.stackable.tech/home/nightly/concepts/product_image_selection)>
/// for details.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum HiveClusterImagePullPolicy {
    IfNotPresent,
    Always,
    Never,
}

/// LocalObjectReference contains enough information to let you locate the referenced object inside the same namespace.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterImagePullSecrets {
    /// Name of the referent. This field is effectively required, but due to backwards compatibility is allowed to be empty. Instances of this type with an empty value here are almost certainly wrong. More info: <https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names>
    pub name: String,
}

/// This struct represents a role - e.g. HDFS datanodes or Trino workers. It has a key-value-map containing
/// all the roleGroups that are part of this role. Additionally, there is a `config`, which is configurable
/// at the role *and* roleGroup level. Everything at roleGroup level is merged on top of what is configured
/// on role level. There is also a second form of config, which can only be configured
/// at role level, the `roleConfig`.
/// You can learn more about this in the
/// [Roles and role group concept documentation](<https://docs.stackable.tech/home/nightly/concepts/roles-and-role-groups).>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastore {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "cliOverrides")]
    pub cli_overrides: Option<BTreeMap<String, String>>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub config: Option<HiveClusterMetastoreConfig>,
    /// The `configOverrides` can be used to configure properties in product config files
    /// that are not exposed in the CRD. Read the
    /// [config overrides documentation](<https://docs.stackable.tech/home/nightly/concepts/overrides#config-overrides)>
    /// and consult the operator specific usage guide documentation for details on the
    /// available config files and settings for the specific product.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configOverrides")]
    pub config_overrides: Option<BTreeMap<String, BTreeMap<String, String>>>,
    /// `envOverrides` configure environment variables to be set in the Pods.
    /// It is a map from strings to strings - environment variables and the value to set.
    /// Read the
    /// [environment variable overrides documentation](<https://docs.stackable.tech/home/nightly/concepts/overrides#env-overrides)>
    /// for more information and consult the operator specific usage guide to find out about
    /// the product specific environment variables that are available.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "envOverrides")]
    pub env_overrides: Option<BTreeMap<String, String>>,
    /// Allows overriding JVM arguments.
    /// Please read on the [JVM argument overrides documentation](<https://docs.stackable.tech/home/nightly/concepts/overrides#jvm-argument-overrides)>
    /// for details on the usage.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jvmArgumentOverrides")]
    pub jvm_argument_overrides: Option<HiveClusterMetastoreJvmArgumentOverrides>,
    /// In the `podOverrides` property you can define a
    /// [PodTemplateSpec](<https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#podtemplatespec-v1-core)>
    /// to override any property that can be set on a Kubernetes Pod.
    /// Read the
    /// [Pod overrides documentation](<https://docs.stackable.tech/home/nightly/concepts/overrides#pod-overrides)>
    /// for more information.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podOverrides")]
    pub pod_overrides: Option<BTreeMap<String, serde_json::Value>>,
    /// This is a product-agnostic RoleConfig, which is sufficient for most of the products.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "roleConfig")]
    pub role_config: Option<HiveClusterMetastoreRoleConfig>,
    #[serde(rename = "roleGroups")]
    pub role_groups: BTreeMap<String, HiveClusterMetastoreRoleGroups>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreConfig {
    /// These configuration settings control
    /// [Pod placement](<https://docs.stackable.tech/home/nightly/concepts/operations/pod_placement).>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub affinity: Option<HiveClusterMetastoreConfigAffinity>,
    /// Time period Pods have to gracefully shut down, e.g. `30m`, `1h` or `2d`. Consult the operator documentation for details.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "gracefulShutdownTimeout")]
    pub graceful_shutdown_timeout: Option<String>,
    /// Logging configuration, learn more in the [logging concept documentation](<https://docs.stackable.tech/home/nightly/concepts/logging).>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub logging: Option<HiveClusterMetastoreConfigLogging>,
    /// Resource usage is configured here, this includes CPU usage, memory usage and disk storage
    /// usage, if this role needs any.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resources: Option<HiveClusterMetastoreConfigResources>,
    /// The location of default database for the Hive warehouse.
    /// Maps to the `hive.metastore.warehouse.dir` setting.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "warehouseDir")]
    pub warehouse_dir: Option<String>,
}

/// These configuration settings control
/// [Pod placement](<https://docs.stackable.tech/home/nightly/concepts/operations/pod_placement).>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreConfigAffinity {
    /// Same as the `spec.affinity.nodeAffinity` field on the Pod, see the [Kubernetes docs](<https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node)>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeAffinity")]
    pub node_affinity: Option<BTreeMap<String, serde_json::Value>>,
    /// Simple key-value pairs forming a nodeSelector, see the [Kubernetes docs](<https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node)>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeSelector")]
    pub node_selector: Option<BTreeMap<String, String>>,
    /// Same as the `spec.affinity.podAffinity` field on the Pod, see the [Kubernetes docs](<https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node)>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podAffinity")]
    pub pod_affinity: Option<BTreeMap<String, serde_json::Value>>,
    /// Same as the `spec.affinity.podAntiAffinity` field on the Pod, see the [Kubernetes docs](<https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node)>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podAntiAffinity")]
    pub pod_anti_affinity: Option<BTreeMap<String, serde_json::Value>>,
}

/// Logging configuration, learn more in the [logging concept documentation](<https://docs.stackable.tech/home/nightly/concepts/logging).>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreConfigLogging {
    /// Log configuration per container.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub containers: Option<BTreeMap<String, HiveClusterMetastoreConfigLoggingContainers>>,
    /// Wether or not to deploy a container with the Vector log agent.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableVectorAgent")]
    pub enable_vector_agent: Option<bool>,
}

/// Log configuration per container.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreConfigLoggingContainers {
    /// Configuration for the console appender
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub console: Option<HiveClusterMetastoreConfigLoggingContainersConsole>,
    /// Log configuration provided in a ConfigMap
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub custom: Option<HiveClusterMetastoreConfigLoggingContainersCustom>,
    /// Configuration for the file appender
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub file: Option<HiveClusterMetastoreConfigLoggingContainersFile>,
    /// Configuration per logger
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub loggers: Option<BTreeMap<String, HiveClusterMetastoreConfigLoggingContainersLoggers>>,
}

/// Configuration for the console appender
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreConfigLoggingContainersConsole {
    /// The log level threshold.
    /// Log events with a lower log level are discarded.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub level: Option<HiveClusterMetastoreConfigLoggingContainersConsoleLevel>,
}

/// Configuration for the console appender
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum HiveClusterMetastoreConfigLoggingContainersConsoleLevel {
    #[serde(rename = "TRACE")]
    Trace,
    #[serde(rename = "DEBUG")]
    Debug,
    #[serde(rename = "INFO")]
    Info,
    #[serde(rename = "WARN")]
    Warn,
    #[serde(rename = "ERROR")]
    Error,
    #[serde(rename = "FATAL")]
    Fatal,
    #[serde(rename = "NONE")]
    None,
}

/// Log configuration provided in a ConfigMap
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreConfigLoggingContainersCustom {
    /// ConfigMap containing the log configuration files
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configMap")]
    pub config_map: Option<String>,
}

/// Configuration for the file appender
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreConfigLoggingContainersFile {
    /// The log level threshold.
    /// Log events with a lower log level are discarded.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub level: Option<HiveClusterMetastoreConfigLoggingContainersFileLevel>,
}

/// Configuration for the file appender
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum HiveClusterMetastoreConfigLoggingContainersFileLevel {
    #[serde(rename = "TRACE")]
    Trace,
    #[serde(rename = "DEBUG")]
    Debug,
    #[serde(rename = "INFO")]
    Info,
    #[serde(rename = "WARN")]
    Warn,
    #[serde(rename = "ERROR")]
    Error,
    #[serde(rename = "FATAL")]
    Fatal,
    #[serde(rename = "NONE")]
    None,
}

/// Configuration per logger
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreConfigLoggingContainersLoggers {
    /// The log level threshold.
    /// Log events with a lower log level are discarded.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub level: Option<HiveClusterMetastoreConfigLoggingContainersLoggersLevel>,
}

/// Configuration per logger
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum HiveClusterMetastoreConfigLoggingContainersLoggersLevel {
    #[serde(rename = "TRACE")]
    Trace,
    #[serde(rename = "DEBUG")]
    Debug,
    #[serde(rename = "INFO")]
    Info,
    #[serde(rename = "WARN")]
    Warn,
    #[serde(rename = "ERROR")]
    Error,
    #[serde(rename = "FATAL")]
    Fatal,
    #[serde(rename = "NONE")]
    None,
}

/// Resource usage is configured here, this includes CPU usage, memory usage and disk storage
/// usage, if this role needs any.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreConfigResources {
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub cpu: Option<HiveClusterMetastoreConfigResourcesCpu>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub memory: Option<HiveClusterMetastoreConfigResourcesMemory>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub storage: Option<HiveClusterMetastoreConfigResourcesStorage>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreConfigResourcesCpu {
    /// The maximum amount of CPU cores that can be requested by Pods.
    /// Equivalent to the `limit` for Pod resource configuration.
    /// Cores are specified either as a decimal point number or as milli units.
    /// For example:`1.5` will be 1.5 cores, also written as `1500m`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub max: Option<String>,
    /// The minimal amount of CPU cores that Pods need to run.
    /// Equivalent to the `request` for Pod resource configuration.
    /// Cores are specified either as a decimal point number or as milli units.
    /// For example:`1.5` will be 1.5 cores, also written as `1500m`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub min: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreConfigResourcesMemory {
    /// The maximum amount of memory that should be available to the Pod.
    /// Specified as a byte [Quantity](<https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/quantity/),>
    /// which means these suffixes are supported: E, P, T, G, M, k.
    /// You can also use the power-of-two equivalents: Ei, Pi, Ti, Gi, Mi, Ki.
    /// For example, the following represent roughly the same value:
    /// `128974848, 129e6, 129M,  128974848000m, 123Mi`
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub limit: Option<String>,
    /// Additional options that can be specified.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "runtimeLimits")]
    pub runtime_limits: Option<HiveClusterMetastoreConfigResourcesMemoryRuntimeLimits>,
}

/// Additional options that can be specified.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreConfigResourcesMemoryRuntimeLimits {
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreConfigResourcesStorage {
    /// This field is deprecated. It was never used by Hive and will be removed in a future
    /// CRD version. The controller will warn if it's set to a non zero value.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub data: Option<HiveClusterMetastoreConfigResourcesStorageData>,
}

/// This field is deprecated. It was never used by Hive and will be removed in a future
/// CRD version. The controller will warn if it's set to a non zero value.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreConfigResourcesStorageData {
    /// Quantity is a fixed-point representation of a number. It provides convenient marshaling/unmarshaling in JSON and YAML, in addition to String() and AsInt64() accessors.
    /// 
    /// The serialization format is:
    /// 
    /// ``` <quantity>        ::= <signedNumber><suffix>
    /// 
    /// 	(Note that <suffix> may be empty, from the "" case in <decimalSI>.)
    /// 
    /// <digit>           ::= 0 | 1 | ... | 9 <digits>          ::= <digit> | <digit><digits> <number>          ::= <digits> | <digits>.<digits> | <digits>. | .<digits> <sign>            ::= "+" | "-" <signedNumber>    ::= <number> | <sign><number> <suffix>          ::= <binarySI> | <decimalExponent> | <decimalSI> <binarySI>        ::= Ki | Mi | Gi | Ti | Pi | Ei
    /// 
    /// 	(International System of units; See: <http://physics.nist.gov/cuu/Units/binary.html)>
    /// 
    /// <decimalSI>       ::= m | "" | k | M | G | T | P | E
    /// 
    /// 	(Note that 1024 = 1Ki but 1000 = 1k; I didn't choose the capitalization.)
    /// 
    /// <decimalExponent> ::= "e" <signedNumber> | "E" <signedNumber> ```
    /// 
    /// No matter which of the three exponent forms is used, no quantity may represent a number greater than 2^63-1 in magnitude, nor may it have more than 3 decimal places. Numbers larger or more precise will be capped or rounded up. (E.g.: 0.1m will rounded up to 1m.) This may be extended in the future if we require larger or smaller quantities.
    /// 
    /// When a Quantity is parsed from a string, it will remember the type of suffix it had, and will use the same type again when it is serialized.
    /// 
    /// Before serializing, Quantity will be put in "canonical form". This means that Exponent/suffix will be adjusted up or down (with a corresponding increase or decrease in Mantissa) such that:
    /// 
    /// - No precision is lost - No fractional digits will be emitted - The exponent (or suffix) is as large as possible.
    /// 
    /// The sign will be omitted unless the number is negative.
    /// 
    /// Examples:
    /// 
    /// - 1.5 will be serialized as "1500m" - 1.5Gi will be serialized as "1536Mi"
    /// 
    /// Note that the quantity will NEVER be internally represented by a floating point number. That is the whole point of this exercise.
    /// 
    /// Non-canonical values will still parse as long as they are well formed, but will be re-emitted in their canonical form. (So always use canonical form, or don't diff.)
    /// 
    /// This format is intended to make it difficult to use these numbers without writing some sort of special handling code in the hopes that that will cause implementors to also use a fixed point implementation.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub capacity: Option<String>,
    /// A label selector is a label query over a set of resources. The result of matchLabels and matchExpressions are ANDed. An empty label selector matches all objects. A null label selector matches no objects.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selectors: Option<HiveClusterMetastoreConfigResourcesStorageDataSelectors>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "storageClass")]
    pub storage_class: Option<String>,
}

/// A label selector is a label query over a set of resources. The result of matchLabels and matchExpressions are ANDed. An empty label selector matches all objects. A null label selector matches no objects.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreConfigResourcesStorageDataSelectors {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<HiveClusterMetastoreConfigResourcesStorageDataSelectorsMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreConfigResourcesStorageDataSelectorsMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Allows overriding JVM arguments.
/// Please read on the [JVM argument overrides documentation](<https://docs.stackable.tech/home/nightly/concepts/overrides#jvm-argument-overrides)>
/// for details on the usage.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreJvmArgumentOverrides {
    /// JVM arguments to be added
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub add: Option<Vec<String>>,
    /// JVM arguments to be removed by exact match
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub remove: Option<Vec<String>>,
    /// JVM arguments matching any of this regexes will be removed
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "removeRegex")]
    pub remove_regex: Option<Vec<String>>,
}

/// This is a product-agnostic RoleConfig, which is sufficient for most of the products.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleConfig {
    /// This field controls which [ListenerClass](<https://docs.stackable.tech/home/nightly/listener-operator/listenerclass.html)> is used to expose the coordinator.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "listenerClass")]
    pub listener_class: Option<String>,
    /// This struct is used to configure:
    /// 
    /// 1. If PodDisruptionBudgets are created by the operator
    /// 2. The allowed number of Pods to be unavailable (`maxUnavailable`)
    /// 
    /// Learn more in the
    /// [allowed Pod disruptions documentation](<https://docs.stackable.tech/home/nightly/concepts/operations/pod_disruptions).>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podDisruptionBudget")]
    pub pod_disruption_budget: Option<HiveClusterMetastoreRoleConfigPodDisruptionBudget>,
}

/// This struct is used to configure:
/// 
/// 1. If PodDisruptionBudgets are created by the operator
/// 2. The allowed number of Pods to be unavailable (`maxUnavailable`)
/// 
/// Learn more in the
/// [allowed Pod disruptions documentation](<https://docs.stackable.tech/home/nightly/concepts/operations/pod_disruptions).>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleConfigPodDisruptionBudget {
    /// Whether a PodDisruptionBudget should be written out for this role.
    /// Disabling this enables you to specify your own - custom - one.
    /// Defaults to true.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enabled: Option<bool>,
    /// The number of Pods that are allowed to be down because of voluntary disruptions.
    /// If you don't explicitly set this, the operator will use a sane default based
    /// upon knowledge about the individual product.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxUnavailable")]
    pub max_unavailable: Option<u16>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroups {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "cliOverrides")]
    pub cli_overrides: Option<BTreeMap<String, String>>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub config: Option<HiveClusterMetastoreRoleGroupsConfig>,
    /// The `configOverrides` can be used to configure properties in product config files
    /// that are not exposed in the CRD. Read the
    /// [config overrides documentation](<https://docs.stackable.tech/home/nightly/concepts/overrides#config-overrides)>
    /// and consult the operator specific usage guide documentation for details on the
    /// available config files and settings for the specific product.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configOverrides")]
    pub config_overrides: Option<BTreeMap<String, BTreeMap<String, String>>>,
    /// `envOverrides` configure environment variables to be set in the Pods.
    /// It is a map from strings to strings - environment variables and the value to set.
    /// Read the
    /// [environment variable overrides documentation](<https://docs.stackable.tech/home/nightly/concepts/overrides#env-overrides)>
    /// for more information and consult the operator specific usage guide to find out about
    /// the product specific environment variables that are available.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "envOverrides")]
    pub env_overrides: Option<BTreeMap<String, String>>,
    /// Allows overriding JVM arguments.
    /// Please read on the [JVM argument overrides documentation](<https://docs.stackable.tech/home/nightly/concepts/overrides#jvm-argument-overrides)>
    /// for details on the usage.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jvmArgumentOverrides")]
    pub jvm_argument_overrides: Option<HiveClusterMetastoreRoleGroupsJvmArgumentOverrides>,
    /// In the `podOverrides` property you can define a
    /// [PodTemplateSpec](<https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#podtemplatespec-v1-core)>
    /// to override any property that can be set on a Kubernetes Pod.
    /// Read the
    /// [Pod overrides documentation](<https://docs.stackable.tech/home/nightly/concepts/overrides#pod-overrides)>
    /// for more information.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podOverrides")]
    pub pod_overrides: Option<BTreeMap<String, serde_json::Value>>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub replicas: Option<u16>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroupsConfig {
    /// These configuration settings control
    /// [Pod placement](<https://docs.stackable.tech/home/nightly/concepts/operations/pod_placement).>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub affinity: Option<HiveClusterMetastoreRoleGroupsConfigAffinity>,
    /// Time period Pods have to gracefully shut down, e.g. `30m`, `1h` or `2d`. Consult the operator documentation for details.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "gracefulShutdownTimeout")]
    pub graceful_shutdown_timeout: Option<String>,
    /// Logging configuration, learn more in the [logging concept documentation](<https://docs.stackable.tech/home/nightly/concepts/logging).>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub logging: Option<HiveClusterMetastoreRoleGroupsConfigLogging>,
    /// Resource usage is configured here, this includes CPU usage, memory usage and disk storage
    /// usage, if this role needs any.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resources: Option<HiveClusterMetastoreRoleGroupsConfigResources>,
    /// The location of default database for the Hive warehouse.
    /// Maps to the `hive.metastore.warehouse.dir` setting.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "warehouseDir")]
    pub warehouse_dir: Option<String>,
}

/// These configuration settings control
/// [Pod placement](<https://docs.stackable.tech/home/nightly/concepts/operations/pod_placement).>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroupsConfigAffinity {
    /// Same as the `spec.affinity.nodeAffinity` field on the Pod, see the [Kubernetes docs](<https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node)>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeAffinity")]
    pub node_affinity: Option<BTreeMap<String, serde_json::Value>>,
    /// Simple key-value pairs forming a nodeSelector, see the [Kubernetes docs](<https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node)>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeSelector")]
    pub node_selector: Option<BTreeMap<String, String>>,
    /// Same as the `spec.affinity.podAffinity` field on the Pod, see the [Kubernetes docs](<https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node)>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podAffinity")]
    pub pod_affinity: Option<BTreeMap<String, serde_json::Value>>,
    /// Same as the `spec.affinity.podAntiAffinity` field on the Pod, see the [Kubernetes docs](<https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node)>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podAntiAffinity")]
    pub pod_anti_affinity: Option<BTreeMap<String, serde_json::Value>>,
}

/// Logging configuration, learn more in the [logging concept documentation](<https://docs.stackable.tech/home/nightly/concepts/logging).>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroupsConfigLogging {
    /// Log configuration per container.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub containers: Option<BTreeMap<String, HiveClusterMetastoreRoleGroupsConfigLoggingContainers>>,
    /// Wether or not to deploy a container with the Vector log agent.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableVectorAgent")]
    pub enable_vector_agent: Option<bool>,
}

/// Log configuration per container.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroupsConfigLoggingContainers {
    /// Configuration for the console appender
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub console: Option<HiveClusterMetastoreRoleGroupsConfigLoggingContainersConsole>,
    /// Log configuration provided in a ConfigMap
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub custom: Option<HiveClusterMetastoreRoleGroupsConfigLoggingContainersCustom>,
    /// Configuration for the file appender
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub file: Option<HiveClusterMetastoreRoleGroupsConfigLoggingContainersFile>,
    /// Configuration per logger
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub loggers: Option<BTreeMap<String, HiveClusterMetastoreRoleGroupsConfigLoggingContainersLoggers>>,
}

/// Configuration for the console appender
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroupsConfigLoggingContainersConsole {
    /// The log level threshold.
    /// Log events with a lower log level are discarded.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub level: Option<HiveClusterMetastoreRoleGroupsConfigLoggingContainersConsoleLevel>,
}

/// Configuration for the console appender
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum HiveClusterMetastoreRoleGroupsConfigLoggingContainersConsoleLevel {
    #[serde(rename = "TRACE")]
    Trace,
    #[serde(rename = "DEBUG")]
    Debug,
    #[serde(rename = "INFO")]
    Info,
    #[serde(rename = "WARN")]
    Warn,
    #[serde(rename = "ERROR")]
    Error,
    #[serde(rename = "FATAL")]
    Fatal,
    #[serde(rename = "NONE")]
    None,
}

/// Log configuration provided in a ConfigMap
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroupsConfigLoggingContainersCustom {
    /// ConfigMap containing the log configuration files
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configMap")]
    pub config_map: Option<String>,
}

/// Configuration for the file appender
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroupsConfigLoggingContainersFile {
    /// The log level threshold.
    /// Log events with a lower log level are discarded.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub level: Option<HiveClusterMetastoreRoleGroupsConfigLoggingContainersFileLevel>,
}

/// Configuration for the file appender
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum HiveClusterMetastoreRoleGroupsConfigLoggingContainersFileLevel {
    #[serde(rename = "TRACE")]
    Trace,
    #[serde(rename = "DEBUG")]
    Debug,
    #[serde(rename = "INFO")]
    Info,
    #[serde(rename = "WARN")]
    Warn,
    #[serde(rename = "ERROR")]
    Error,
    #[serde(rename = "FATAL")]
    Fatal,
    #[serde(rename = "NONE")]
    None,
}

/// Configuration per logger
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroupsConfigLoggingContainersLoggers {
    /// The log level threshold.
    /// Log events with a lower log level are discarded.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub level: Option<HiveClusterMetastoreRoleGroupsConfigLoggingContainersLoggersLevel>,
}

/// Configuration per logger
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum HiveClusterMetastoreRoleGroupsConfigLoggingContainersLoggersLevel {
    #[serde(rename = "TRACE")]
    Trace,
    #[serde(rename = "DEBUG")]
    Debug,
    #[serde(rename = "INFO")]
    Info,
    #[serde(rename = "WARN")]
    Warn,
    #[serde(rename = "ERROR")]
    Error,
    #[serde(rename = "FATAL")]
    Fatal,
    #[serde(rename = "NONE")]
    None,
}

/// Resource usage is configured here, this includes CPU usage, memory usage and disk storage
/// usage, if this role needs any.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroupsConfigResources {
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub cpu: Option<HiveClusterMetastoreRoleGroupsConfigResourcesCpu>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub memory: Option<HiveClusterMetastoreRoleGroupsConfigResourcesMemory>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub storage: Option<HiveClusterMetastoreRoleGroupsConfigResourcesStorage>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroupsConfigResourcesCpu {
    /// The maximum amount of CPU cores that can be requested by Pods.
    /// Equivalent to the `limit` for Pod resource configuration.
    /// Cores are specified either as a decimal point number or as milli units.
    /// For example:`1.5` will be 1.5 cores, also written as `1500m`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub max: Option<String>,
    /// The minimal amount of CPU cores that Pods need to run.
    /// Equivalent to the `request` for Pod resource configuration.
    /// Cores are specified either as a decimal point number or as milli units.
    /// For example:`1.5` will be 1.5 cores, also written as `1500m`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub min: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroupsConfigResourcesMemory {
    /// The maximum amount of memory that should be available to the Pod.
    /// Specified as a byte [Quantity](<https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/quantity/),>
    /// which means these suffixes are supported: E, P, T, G, M, k.
    /// You can also use the power-of-two equivalents: Ei, Pi, Ti, Gi, Mi, Ki.
    /// For example, the following represent roughly the same value:
    /// `128974848, 129e6, 129M,  128974848000m, 123Mi`
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub limit: Option<String>,
    /// Additional options that can be specified.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "runtimeLimits")]
    pub runtime_limits: Option<HiveClusterMetastoreRoleGroupsConfigResourcesMemoryRuntimeLimits>,
}

/// Additional options that can be specified.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroupsConfigResourcesMemoryRuntimeLimits {
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroupsConfigResourcesStorage {
    /// This field is deprecated. It was never used by Hive and will be removed in a future
    /// CRD version. The controller will warn if it's set to a non zero value.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub data: Option<HiveClusterMetastoreRoleGroupsConfigResourcesStorageData>,
}

/// This field is deprecated. It was never used by Hive and will be removed in a future
/// CRD version. The controller will warn if it's set to a non zero value.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroupsConfigResourcesStorageData {
    /// Quantity is a fixed-point representation of a number. It provides convenient marshaling/unmarshaling in JSON and YAML, in addition to String() and AsInt64() accessors.
    /// 
    /// The serialization format is:
    /// 
    /// ``` <quantity>        ::= <signedNumber><suffix>
    /// 
    /// 	(Note that <suffix> may be empty, from the "" case in <decimalSI>.)
    /// 
    /// <digit>           ::= 0 | 1 | ... | 9 <digits>          ::= <digit> | <digit><digits> <number>          ::= <digits> | <digits>.<digits> | <digits>. | .<digits> <sign>            ::= "+" | "-" <signedNumber>    ::= <number> | <sign><number> <suffix>          ::= <binarySI> | <decimalExponent> | <decimalSI> <binarySI>        ::= Ki | Mi | Gi | Ti | Pi | Ei
    /// 
    /// 	(International System of units; See: <http://physics.nist.gov/cuu/Units/binary.html)>
    /// 
    /// <decimalSI>       ::= m | "" | k | M | G | T | P | E
    /// 
    /// 	(Note that 1024 = 1Ki but 1000 = 1k; I didn't choose the capitalization.)
    /// 
    /// <decimalExponent> ::= "e" <signedNumber> | "E" <signedNumber> ```
    /// 
    /// No matter which of the three exponent forms is used, no quantity may represent a number greater than 2^63-1 in magnitude, nor may it have more than 3 decimal places. Numbers larger or more precise will be capped or rounded up. (E.g.: 0.1m will rounded up to 1m.) This may be extended in the future if we require larger or smaller quantities.
    /// 
    /// When a Quantity is parsed from a string, it will remember the type of suffix it had, and will use the same type again when it is serialized.
    /// 
    /// Before serializing, Quantity will be put in "canonical form". This means that Exponent/suffix will be adjusted up or down (with a corresponding increase or decrease in Mantissa) such that:
    /// 
    /// - No precision is lost - No fractional digits will be emitted - The exponent (or suffix) is as large as possible.
    /// 
    /// The sign will be omitted unless the number is negative.
    /// 
    /// Examples:
    /// 
    /// - 1.5 will be serialized as "1500m" - 1.5Gi will be serialized as "1536Mi"
    /// 
    /// Note that the quantity will NEVER be internally represented by a floating point number. That is the whole point of this exercise.
    /// 
    /// Non-canonical values will still parse as long as they are well formed, but will be re-emitted in their canonical form. (So always use canonical form, or don't diff.)
    /// 
    /// This format is intended to make it difficult to use these numbers without writing some sort of special handling code in the hopes that that will cause implementors to also use a fixed point implementation.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub capacity: Option<String>,
    /// A label selector is a label query over a set of resources. The result of matchLabels and matchExpressions are ANDed. An empty label selector matches all objects. A null label selector matches no objects.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selectors: Option<HiveClusterMetastoreRoleGroupsConfigResourcesStorageDataSelectors>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "storageClass")]
    pub storage_class: Option<String>,
}

/// A label selector is a label query over a set of resources. The result of matchLabels and matchExpressions are ANDed. An empty label selector matches all objects. A null label selector matches no objects.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroupsConfigResourcesStorageDataSelectors {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<HiveClusterMetastoreRoleGroupsConfigResourcesStorageDataSelectorsMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroupsConfigResourcesStorageDataSelectorsMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Allows overriding JVM arguments.
/// Please read on the [JVM argument overrides documentation](<https://docs.stackable.tech/home/nightly/concepts/overrides#jvm-argument-overrides)>
/// for details on the usage.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterMetastoreRoleGroupsJvmArgumentOverrides {
    /// JVM arguments to be added
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub add: Option<Vec<String>>,
    /// JVM arguments to be removed by exact match
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub remove: Option<Vec<String>>,
    /// JVM arguments matching any of this regexes will be removed
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "removeRegex")]
    pub remove_regex: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct HiveClusterStatus {
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub conditions: Option<Vec<Condition>>,
    /// An opaque value that changes every time a discovery detail does
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "discoveryHash")]
    pub discovery_hash: Option<String>,
}

