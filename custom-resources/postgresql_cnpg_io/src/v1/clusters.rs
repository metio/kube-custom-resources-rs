// WARNING: generated by kopium - manual changes will be overwritten
// kopium command: kopium --docs --derive=Default --derive=PartialEq --smart-derive-elision --filename crd-catalog/cloudnative-pg/cloudnative-pg/postgresql.cnpg.io/v1/clusters.yaml
// kopium version: 0.22.4

#[allow(unused_imports)]
mod prelude {
    pub use kube::CustomResource;
    pub use serde::{Serialize, Deserialize};
    pub use std::collections::BTreeMap;
    pub use k8s_openapi::apimachinery::pkg::util::intstr::IntOrString;
    pub use k8s_openapi::apimachinery::pkg::apis::meta::v1::Condition;
}
use self::prelude::*;

/// Specification of the desired behavior of the cluster.
/// More info: <https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>
#[derive(CustomResource, Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
#[kube(group = "postgresql.cnpg.io", version = "v1", kind = "Cluster", plural = "clusters")]
#[kube(namespaced)]
#[kube(status = "ClusterStatus")]
#[kube(schema = "disabled")]
#[kube(derive="Default")]
#[kube(derive="PartialEq")]
pub struct ClusterSpec {
    /// Affinity/Anti-affinity rules for Pods
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub affinity: Option<ClusterAffinity>,
    /// The configuration to be used for backups
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub backup: Option<ClusterBackup>,
    /// Instructions to bootstrap this cluster
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub bootstrap: Option<ClusterBootstrap>,
    /// The configuration for the CA and related certificates
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub certificates: Option<ClusterCertificates>,
    /// Description of this PostgreSQL cluster
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub description: Option<String>,
    /// Manage the `PodDisruptionBudget` resources within the cluster. When
    /// configured as `true` (default setting), the pod disruption budgets
    /// will safeguard the primary node from being terminated. Conversely,
    /// setting it to `false` will result in the absence of any
    /// `PodDisruptionBudget` resource, permitting the shutdown of all nodes
    /// hosting the PostgreSQL cluster. This latter configuration is
    /// advisable for any PostgreSQL cluster employed for
    /// development/staging purposes.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enablePDB")]
    pub enable_pdb: Option<bool>,
    /// When this option is enabled, the operator will use the `SuperuserSecret`
    /// to update the `postgres` user password (if the secret is
    /// not present, the operator will automatically create one). When this
    /// option is disabled, the operator will ignore the `SuperuserSecret` content, delete
    /// it when automatically created, and then blank the password of the `postgres`
    /// user by setting it to `NULL`. Disabled by default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableSuperuserAccess")]
    pub enable_superuser_access: Option<bool>,
    /// Env follows the Env format to pass environment variables
    /// to the pods created in the cluster
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub env: Option<Vec<ClusterEnv>>,
    /// EnvFrom follows the EnvFrom format to pass environment variables
    /// sources to the pods to be used by Env
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "envFrom")]
    pub env_from: Option<Vec<ClusterEnvFrom>>,
    /// EphemeralVolumeSource allows the user to configure the source of ephemeral volumes.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ephemeralVolumeSource")]
    pub ephemeral_volume_source: Option<ClusterEphemeralVolumeSource>,
    /// EphemeralVolumesSizeLimit allows the user to set the limits for the ephemeral
    /// volumes
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ephemeralVolumesSizeLimit")]
    pub ephemeral_volumes_size_limit: Option<ClusterEphemeralVolumesSizeLimit>,
    /// The list of external clusters which are used in the configuration
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "externalClusters")]
    pub external_clusters: Option<Vec<ClusterExternalClusters>>,
    /// The amount of time (in seconds) to wait before triggering a failover
    /// after the primary PostgreSQL instance in the cluster was detected
    /// to be unhealthy
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "failoverDelay")]
    pub failover_delay: Option<i32>,
    /// Defines the major PostgreSQL version we want to use within an ImageCatalog
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "imageCatalogRef")]
    pub image_catalog_ref: Option<ClusterImageCatalogRef>,
    /// Name of the container image, supporting both tags (`<image>:<tag>`)
    /// and digests for deterministic and repeatable deployments
    /// (`<image>:<tag>@sha256:<digestValue>`)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "imageName")]
    pub image_name: Option<String>,
    /// Image pull policy.
    /// One of `Always`, `Never` or `IfNotPresent`.
    /// If not defined, it defaults to `IfNotPresent`.
    /// Cannot be updated.
    /// More info: <https://kubernetes.io/docs/concepts/containers/images#updating-images>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "imagePullPolicy")]
    pub image_pull_policy: Option<String>,
    /// The list of pull secrets to be used to pull the images
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "imagePullSecrets")]
    pub image_pull_secrets: Option<Vec<ClusterImagePullSecrets>>,
    /// Metadata that will be inherited by all objects related to the Cluster
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inheritedMetadata")]
    pub inherited_metadata: Option<ClusterInheritedMetadata>,
    /// Number of instances required in the cluster
    pub instances: i64,
    /// LivenessProbeTimeout is the time (in seconds) that is allowed for a PostgreSQL instance
    /// to successfully respond to the liveness probe (default 30).
    /// The Liveness probe failure threshold is derived from this value using the formula:
    /// ceiling(livenessProbe / 10).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "livenessProbeTimeout")]
    pub liveness_probe_timeout: Option<i32>,
    /// The instances' log level, one of the following values: error, warning, info (default), debug, trace
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "logLevel")]
    pub log_level: Option<ClusterLogLevel>,
    /// The configuration that is used by the portions of PostgreSQL that are managed by the instance manager
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub managed: Option<ClusterManaged>,
    /// The target value for the synchronous replication quorum, that can be
    /// decreased if the number of ready standbys is lower than this.
    /// Undefined or 0 disable synchronous replication.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxSyncReplicas")]
    pub max_sync_replicas: Option<i64>,
    /// Minimum number of instances required in synchronous replication with the
    /// primary. Undefined or 0 allow writes to complete when no standby is
    /// available.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "minSyncReplicas")]
    pub min_sync_replicas: Option<i64>,
    /// The configuration of the monitoring infrastructure of this cluster
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub monitoring: Option<ClusterMonitoring>,
    /// Define a maintenance window for the Kubernetes nodes
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeMaintenanceWindow")]
    pub node_maintenance_window: Option<ClusterNodeMaintenanceWindow>,
    /// The plugins configuration, containing
    /// any plugin to be loaded with the corresponding configuration
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub plugins: Option<Vec<ClusterPlugins>>,
    /// The GID of the `postgres` user inside the image, defaults to `26`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "postgresGID")]
    pub postgres_gid: Option<i64>,
    /// The UID of the `postgres` user inside the image, defaults to `26`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "postgresUID")]
    pub postgres_uid: Option<i64>,
    /// Configuration of the PostgreSQL server
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub postgresql: Option<ClusterPostgresql>,
    /// Method to follow to upgrade the primary server during a rolling
    /// update procedure, after all replicas have been successfully updated:
    /// it can be with a switchover (`switchover`) or in-place (`restart` - default)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "primaryUpdateMethod")]
    pub primary_update_method: Option<ClusterPrimaryUpdateMethod>,
    /// Deployment strategy to follow to upgrade the primary server during a rolling
    /// update procedure, after all replicas have been successfully updated:
    /// it can be automated (`unsupervised` - default) or manual (`supervised`)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "primaryUpdateStrategy")]
    pub primary_update_strategy: Option<ClusterPrimaryUpdateStrategy>,
    /// Name of the priority class which will be used in every generated Pod, if the PriorityClass
    /// specified does not exist, the pod will not be able to schedule.  Please refer to
    /// <https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#priorityclass>
    /// for more information
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "priorityClassName")]
    pub priority_class_name: Option<String>,
    /// The configuration of the probes to be injected
    /// in the PostgreSQL Pods.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub probes: Option<ClusterProbes>,
    /// Template to be used to define projected volumes, projected volumes will be mounted
    /// under `/projected` base folder
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectedVolumeTemplate")]
    pub projected_volume_template: Option<ClusterProjectedVolumeTemplate>,
    /// Replica cluster configuration
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub replica: Option<ClusterReplica>,
    /// Replication slots management configuration
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "replicationSlots")]
    pub replication_slots: Option<ClusterReplicationSlots>,
    /// Resources requirements of every generated Pod. Please refer to
    /// <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    /// for more information.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resources: Option<ClusterResources>,
    /// If specified, the pod will be dispatched by specified Kubernetes
    /// scheduler. If not specified, the pod will be dispatched by the default
    /// scheduler. More info:
    /// <https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "schedulerName")]
    pub scheduler_name: Option<String>,
    /// The SeccompProfile applied to every Pod and Container.
    /// Defaults to: `RuntimeDefault`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "seccompProfile")]
    pub seccomp_profile: Option<ClusterSeccompProfile>,
    /// Configure the generation of the service account
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "serviceAccountTemplate")]
    pub service_account_template: Option<ClusterServiceAccountTemplate>,
    /// The time in seconds that controls the window of time reserved for the smart shutdown of Postgres to complete.
    /// Make sure you reserve enough time for the operator to request a fast shutdown of Postgres
    /// (that is: `stopDelay` - `smartShutdownTimeout`).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "smartShutdownTimeout")]
    pub smart_shutdown_timeout: Option<i32>,
    /// The time in seconds that is allowed for a PostgreSQL instance to
    /// successfully start up (default 3600).
    /// The startup probe failure threshold is derived from this value using the formula:
    /// ceiling(startDelay / 10).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "startDelay")]
    pub start_delay: Option<i32>,
    /// The time in seconds that is allowed for a PostgreSQL instance to
    /// gracefully shutdown (default 1800)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "stopDelay")]
    pub stop_delay: Option<i32>,
    /// Configuration of the storage of the instances
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub storage: Option<ClusterStorage>,
    /// The secret containing the superuser password. If not defined a new
    /// secret will be created with a randomly generated password
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "superuserSecret")]
    pub superuser_secret: Option<ClusterSuperuserSecret>,
    /// The time in seconds that is allowed for a primary PostgreSQL instance
    /// to gracefully shutdown during a switchover.
    /// Default value is 3600 seconds (1 hour).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "switchoverDelay")]
    pub switchover_delay: Option<i32>,
    /// The tablespaces configuration
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tablespaces: Option<Vec<ClusterTablespaces>>,
    /// TopologySpreadConstraints specifies how to spread matching pods among the given topology.
    /// More info:
    /// <https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "topologySpreadConstraints")]
    pub topology_spread_constraints: Option<Vec<ClusterTopologySpreadConstraints>>,
    /// Configuration of the storage for PostgreSQL WAL (Write-Ahead Log)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "walStorage")]
    pub wal_storage: Option<ClusterWalStorage>,
}

/// Affinity/Anti-affinity rules for Pods
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinity {
    /// AdditionalPodAffinity allows to specify pod affinity terms to be passed to all the cluster's pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "additionalPodAffinity")]
    pub additional_pod_affinity: Option<ClusterAffinityAdditionalPodAffinity>,
    /// AdditionalPodAntiAffinity allows to specify pod anti-affinity terms to be added to the ones generated
    /// by the operator if EnablePodAntiAffinity is set to true (default) or to be used exclusively if set to false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "additionalPodAntiAffinity")]
    pub additional_pod_anti_affinity: Option<ClusterAffinityAdditionalPodAntiAffinity>,
    /// Activates anti-affinity for the pods. The operator will define pods
    /// anti-affinity unless this field is explicitly set to false
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enablePodAntiAffinity")]
    pub enable_pod_anti_affinity: Option<bool>,
    /// NodeAffinity describes node affinity scheduling rules for the pod.
    /// More info: <https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeAffinity")]
    pub node_affinity: Option<ClusterAffinityNodeAffinity>,
    /// NodeSelector is map of key-value pairs used to define the nodes on which
    /// the pods can run.
    /// More info: <https://kubernetes.io/docs/concepts/configuration/assign-pod-node/>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeSelector")]
    pub node_selector: Option<BTreeMap<String, String>>,
    /// PodAntiAffinityType allows the user to decide whether pod anti-affinity between cluster instance has to be
    /// considered a strong requirement during scheduling or not. Allowed values are: "preferred" (default if empty) or
    /// "required". Setting it to "required", could lead to instances remaining pending until new kubernetes nodes are
    /// added if all the existing nodes don't match the required pod anti-affinity rule.
    /// More info:
    /// <https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podAntiAffinityType")]
    pub pod_anti_affinity_type: Option<String>,
    /// Tolerations is a list of Tolerations that should be set for all the pods, in order to allow them to run
    /// on tainted nodes.
    /// More info: <https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tolerations: Option<Vec<ClusterAffinityTolerations>>,
    /// TopologyKey to use for anti-affinity configuration. See k8s documentation
    /// for more info on that
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "topologyKey")]
    pub topology_key: Option<String>,
}

/// AdditionalPodAffinity allows to specify pod affinity terms to be passed to all the cluster's pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAffinity {
    /// The scheduler will prefer to schedule pods to nodes that satisfy
    /// the affinity expressions specified by this field, but it may choose
    /// a node that violates one or more of the expressions. The node that is
    /// most preferred is the one with the greatest sum of weights, i.e.
    /// for each node that meets all of the scheduling requirements (resource
    /// request, requiredDuringScheduling affinity expressions, etc.),
    /// compute a sum by iterating through the elements of this field and adding
    /// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
    /// node(s) with the highest sum are the most preferred.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<ClusterAffinityAdditionalPodAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    /// If the affinity requirements specified by this field are not met at
    /// scheduling time, the pod will not be scheduled onto the node.
    /// If the affinity requirements specified by this field cease to be met
    /// at some point during pod execution (e.g. due to a pod label update), the
    /// system may or may not try to eventually evict the pod from its node.
    /// When there are multiple elements, the lists of nodes corresponding to each
    /// podAffinityTerm are intersected, i.e. all terms must be satisfied.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<Vec<ClusterAffinityAdditionalPodAffinityRequiredDuringSchedulingIgnoredDuringExecution>>,
}

/// The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    /// Required. A pod affinity term, associated with the corresponding weight.
    #[serde(rename = "podAffinityTerm")]
    pub pod_affinity_term: ClusterAffinityAdditionalPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm,
    /// weight associated with matching the corresponding podAffinityTerm,
    /// in the range 1-100.
    pub weight: i32,
}

/// Required. A pod affinity term, associated with the corresponding weight.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
    /// A label query over a set of resources, in this case pods.
    /// If it's null, this PodAffinityTerm matches with no Pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<ClusterAffinityAdditionalPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector>,
    /// MatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
    /// Also, matchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    /// MismatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
    /// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    /// A label query over the set of namespaces that the term applies to.
    /// The term is applied to the union of the namespaces selected by this field
    /// and the ones listed in the namespaces field.
    /// null selector and null or empty namespaces list means "this pod's namespace".
    /// An empty selector ({}) matches all namespaces.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<ClusterAffinityAdditionalPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector>,
    /// namespaces specifies a static list of namespace names that the term applies to.
    /// The term is applied to the union of the namespaces listed in this field
    /// and the ones selected by namespaceSelector.
    /// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    /// This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
    /// the labelSelector in the specified namespaces, where co-located is defined as running on a node
    /// whose value of the label with key topologyKey matches that of any node on which any of the
    /// selected pods is running.
    /// Empty topologyKey is not allowed.
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

/// A label query over a set of resources, in this case pods.
/// If it's null, this PodAffinityTerm matches with no Pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterAffinityAdditionalPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A label query over the set of namespaces that the term applies to.
/// The term is applied to the union of the namespaces selected by this field
/// and the ones listed in the namespaces field.
/// null selector and null or empty namespaces list means "this pod's namespace".
/// An empty selector ({}) matches all namespaces.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterAffinityAdditionalPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Defines a set of pods (namely those matching the labelSelector
/// relative to the given namespace(s)) that this pod should be
/// co-located (affinity) or not co-located (anti-affinity) with,
/// where co-located is defined as running on a node whose value of
/// the label with key <topologyKey> matches that of any node on which
/// a pod of the set of pods is running
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    /// A label query over a set of resources, in this case pods.
    /// If it's null, this PodAffinityTerm matches with no Pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<ClusterAffinityAdditionalPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector>,
    /// MatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
    /// Also, matchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    /// MismatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
    /// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    /// A label query over the set of namespaces that the term applies to.
    /// The term is applied to the union of the namespaces selected by this field
    /// and the ones listed in the namespaces field.
    /// null selector and null or empty namespaces list means "this pod's namespace".
    /// An empty selector ({}) matches all namespaces.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<ClusterAffinityAdditionalPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector>,
    /// namespaces specifies a static list of namespace names that the term applies to.
    /// The term is applied to the union of the namespaces listed in this field
    /// and the ones selected by namespaceSelector.
    /// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    /// This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
    /// the labelSelector in the specified namespaces, where co-located is defined as running on a node
    /// whose value of the label with key topologyKey matches that of any node on which any of the
    /// selected pods is running.
    /// Empty topologyKey is not allowed.
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

/// A label query over a set of resources, in this case pods.
/// If it's null, this PodAffinityTerm matches with no Pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterAffinityAdditionalPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A label query over the set of namespaces that the term applies to.
/// The term is applied to the union of the namespaces selected by this field
/// and the ones listed in the namespaces field.
/// null selector and null or empty namespaces list means "this pod's namespace".
/// An empty selector ({}) matches all namespaces.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterAffinityAdditionalPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// AdditionalPodAntiAffinity allows to specify pod anti-affinity terms to be added to the ones generated
/// by the operator if EnablePodAntiAffinity is set to true (default) or to be used exclusively if set to false.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAntiAffinity {
    /// The scheduler will prefer to schedule pods to nodes that satisfy
    /// the anti-affinity expressions specified by this field, but it may choose
    /// a node that violates one or more of the expressions. The node that is
    /// most preferred is the one with the greatest sum of weights, i.e.
    /// for each node that meets all of the scheduling requirements (resource
    /// request, requiredDuringScheduling anti-affinity expressions, etc.),
    /// compute a sum by iterating through the elements of this field and subtracting
    /// "weight" from the sum if the node has pods which matches the corresponding podAffinityTerm; the
    /// node(s) with the highest sum are the most preferred.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<ClusterAffinityAdditionalPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    /// If the anti-affinity requirements specified by this field are not met at
    /// scheduling time, the pod will not be scheduled onto the node.
    /// If the anti-affinity requirements specified by this field cease to be met
    /// at some point during pod execution (e.g. due to a pod label update), the
    /// system may or may not try to eventually evict the pod from its node.
    /// When there are multiple elements, the lists of nodes corresponding to each
    /// podAffinityTerm are intersected, i.e. all terms must be satisfied.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<Vec<ClusterAffinityAdditionalPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution>>,
}

/// The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    /// Required. A pod affinity term, associated with the corresponding weight.
    #[serde(rename = "podAffinityTerm")]
    pub pod_affinity_term: ClusterAffinityAdditionalPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm,
    /// weight associated with matching the corresponding podAffinityTerm,
    /// in the range 1-100.
    pub weight: i32,
}

/// Required. A pod affinity term, associated with the corresponding weight.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
    /// A label query over a set of resources, in this case pods.
    /// If it's null, this PodAffinityTerm matches with no Pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<ClusterAffinityAdditionalPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector>,
    /// MatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
    /// Also, matchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    /// MismatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
    /// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    /// A label query over the set of namespaces that the term applies to.
    /// The term is applied to the union of the namespaces selected by this field
    /// and the ones listed in the namespaces field.
    /// null selector and null or empty namespaces list means "this pod's namespace".
    /// An empty selector ({}) matches all namespaces.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<ClusterAffinityAdditionalPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector>,
    /// namespaces specifies a static list of namespace names that the term applies to.
    /// The term is applied to the union of the namespaces listed in this field
    /// and the ones selected by namespaceSelector.
    /// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    /// This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
    /// the labelSelector in the specified namespaces, where co-located is defined as running on a node
    /// whose value of the label with key topologyKey matches that of any node on which any of the
    /// selected pods is running.
    /// Empty topologyKey is not allowed.
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

/// A label query over a set of resources, in this case pods.
/// If it's null, this PodAffinityTerm matches with no Pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterAffinityAdditionalPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A label query over the set of namespaces that the term applies to.
/// The term is applied to the union of the namespaces selected by this field
/// and the ones listed in the namespaces field.
/// null selector and null or empty namespaces list means "this pod's namespace".
/// An empty selector ({}) matches all namespaces.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterAffinityAdditionalPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Defines a set of pods (namely those matching the labelSelector
/// relative to the given namespace(s)) that this pod should be
/// co-located (affinity) or not co-located (anti-affinity) with,
/// where co-located is defined as running on a node whose value of
/// the label with key <topologyKey> matches that of any node on which
/// a pod of the set of pods is running
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    /// A label query over a set of resources, in this case pods.
    /// If it's null, this PodAffinityTerm matches with no Pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<ClusterAffinityAdditionalPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector>,
    /// MatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
    /// Also, matchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    /// MismatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
    /// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    /// A label query over the set of namespaces that the term applies to.
    /// The term is applied to the union of the namespaces selected by this field
    /// and the ones listed in the namespaces field.
    /// null selector and null or empty namespaces list means "this pod's namespace".
    /// An empty selector ({}) matches all namespaces.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<ClusterAffinityAdditionalPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector>,
    /// namespaces specifies a static list of namespace names that the term applies to.
    /// The term is applied to the union of the namespaces listed in this field
    /// and the ones selected by namespaceSelector.
    /// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    /// This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
    /// the labelSelector in the specified namespaces, where co-located is defined as running on a node
    /// whose value of the label with key topologyKey matches that of any node on which any of the
    /// selected pods is running.
    /// Empty topologyKey is not allowed.
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

/// A label query over a set of resources, in this case pods.
/// If it's null, this PodAffinityTerm matches with no Pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterAffinityAdditionalPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A label query over the set of namespaces that the term applies to.
/// The term is applied to the union of the namespaces selected by this field
/// and the ones listed in the namespaces field.
/// null selector and null or empty namespaces list means "this pod's namespace".
/// An empty selector ({}) matches all namespaces.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterAffinityAdditionalPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityAdditionalPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// NodeAffinity describes node affinity scheduling rules for the pod.
/// More info: <https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityNodeAffinity {
    /// The scheduler will prefer to schedule pods to nodes that satisfy
    /// the affinity expressions specified by this field, but it may choose
    /// a node that violates one or more of the expressions. The node that is
    /// most preferred is the one with the greatest sum of weights, i.e.
    /// for each node that meets all of the scheduling requirements (resource
    /// request, requiredDuringScheduling affinity expressions, etc.),
    /// compute a sum by iterating through the elements of this field and adding
    /// "weight" to the sum if the node matches the corresponding matchExpressions; the
    /// node(s) with the highest sum are the most preferred.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<ClusterAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    /// If the affinity requirements specified by this field are not met at
    /// scheduling time, the pod will not be scheduled onto the node.
    /// If the affinity requirements specified by this field cease to be met
    /// at some point during pod execution (e.g. due to an update), the system
    /// may or may not try to eventually evict the pod from its node.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<ClusterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution>,
}

/// An empty preferred scheduling term matches all objects with implicit weight 0
/// (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    /// A node selector term, associated with the corresponding weight.
    pub preference: ClusterAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference,
    /// Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
    pub weight: i32,
}

/// A node selector term, associated with the corresponding weight.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
    /// A list of node selector requirements by node's labels.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions>>,
    /// A list of node selector requirements by node's fields.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchFields")]
    pub match_fields: Option<Vec<ClusterAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// If the affinity requirements specified by this field are not met at
/// scheduling time, the pod will not be scheduled onto the node.
/// If the affinity requirements specified by this field cease to be met
/// at some point during pod execution (e.g. due to an update), the system
/// may or may not try to eventually evict the pod from its node.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    /// Required. A list of node selector terms. The terms are ORed.
    #[serde(rename = "nodeSelectorTerms")]
    pub node_selector_terms: Vec<ClusterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms>,
}

/// A null or empty node selector term matches no objects. The requirements of
/// them are ANDed.
/// The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
    /// A list of node selector requirements by node's labels.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions>>,
    /// A list of node selector requirements by node's fields.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchFields")]
    pub match_fields: Option<Vec<ClusterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// The pod this Toleration is attached to tolerates any taint that matches
/// the triple <key,value,effect> using the matching operator <operator>.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterAffinityTolerations {
    /// Effect indicates the taint effect to match. Empty means match all taint effects.
    /// When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub effect: Option<String>,
    /// Key is the taint key that the toleration applies to. Empty means match all taint keys.
    /// If the key is empty, operator must be Exists; this combination means to match all values and all keys.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub key: Option<String>,
    /// Operator represents a key's relationship to the value.
    /// Valid operators are Exists and Equal. Defaults to Equal.
    /// Exists is equivalent to wildcard for value, so that a pod can
    /// tolerate all taints of a particular category.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub operator: Option<String>,
    /// TolerationSeconds represents the period of time the toleration (which must be
    /// of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,
    /// it is not set, which means tolerate the taint forever (do not evict). Zero and
    /// negative values will be treated as 0 (evict immediately) by the system.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tolerationSeconds")]
    pub toleration_seconds: Option<i64>,
    /// Value is the taint value the toleration matches to.
    /// If the operator is Exists, the value should be empty, otherwise just a regular string.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<String>,
}

/// The configuration to be used for backups
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackup {
    /// The configuration for the barman-cloud tool suite
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "barmanObjectStore")]
    pub barman_object_store: Option<ClusterBackupBarmanObjectStore>,
    /// RetentionPolicy is the retention policy to be used for backups
    /// and WALs (i.e. '60d'). The retention policy is expressed in the form
    /// of `XXu` where `XX` is a positive integer and `u` is in `[dwm]` -
    /// days, weeks, months.
    /// It's currently only applicable when using the BarmanObjectStore method.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "retentionPolicy")]
    pub retention_policy: Option<String>,
    /// The policy to decide which instance should perform backups. Available
    /// options are empty string, which will default to `prefer-standby` policy,
    /// `primary` to have backups run always on primary instances, `prefer-standby`
    /// to have backups run preferably on the most updated standby, if available.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub target: Option<ClusterBackupTarget>,
    /// VolumeSnapshot provides the configuration for the execution of volume snapshot backups.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeSnapshot")]
    pub volume_snapshot: Option<ClusterBackupVolumeSnapshot>,
}

/// The configuration for the barman-cloud tool suite
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupBarmanObjectStore {
    /// The credentials to use to upload data to Azure Blob Storage
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "azureCredentials")]
    pub azure_credentials: Option<ClusterBackupBarmanObjectStoreAzureCredentials>,
    /// The configuration to be used to backup the data files
    /// When not defined, base backups files will be stored uncompressed and may
    /// be unencrypted in the object store, according to the bucket default
    /// policy.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub data: Option<ClusterBackupBarmanObjectStoreData>,
    /// The path where to store the backup (i.e. s3://bucket/path/to/folder)
    /// this path, with different destination folders, will be used for WALs
    /// and for data
    #[serde(rename = "destinationPath")]
    pub destination_path: String,
    /// EndpointCA store the CA bundle of the barman endpoint.
    /// Useful when using self-signed certificates to avoid
    /// errors with certificate issuer and barman-cloud-wal-archive
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "endpointCA")]
    pub endpoint_ca: Option<ClusterBackupBarmanObjectStoreEndpointCa>,
    /// Endpoint to be used to upload data to the cloud,
    /// overriding the automatic endpoint discovery
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "endpointURL")]
    pub endpoint_url: Option<String>,
    /// The credentials to use to upload data to Google Cloud Storage
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "googleCredentials")]
    pub google_credentials: Option<ClusterBackupBarmanObjectStoreGoogleCredentials>,
    /// HistoryTags is a list of key value pairs that will be passed to the
    /// Barman --history-tags option.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "historyTags")]
    pub history_tags: Option<BTreeMap<String, String>>,
    /// The credentials to use to upload data to S3
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3Credentials")]
    pub s3_credentials: Option<ClusterBackupBarmanObjectStoreS3Credentials>,
    /// The server name on S3, the cluster name is used if this
    /// parameter is omitted
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "serverName")]
    pub server_name: Option<String>,
    /// Tags is a list of key value pairs that will be passed to the
    /// Barman --tags option.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tags: Option<BTreeMap<String, String>>,
    /// The configuration for the backup of the WAL stream.
    /// When not defined, WAL files will be stored uncompressed and may be
    /// unencrypted in the object store, according to the bucket default policy.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub wal: Option<ClusterBackupBarmanObjectStoreWal>,
}

/// The credentials to use to upload data to Azure Blob Storage
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupBarmanObjectStoreAzureCredentials {
    /// The connection string to be used
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "connectionString")]
    pub connection_string: Option<ClusterBackupBarmanObjectStoreAzureCredentialsConnectionString>,
    /// Use the Azure AD based authentication without providing explicitly the keys.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inheritFromAzureAD")]
    pub inherit_from_azure_ad: Option<bool>,
    /// The storage account where to upload data
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "storageAccount")]
    pub storage_account: Option<ClusterBackupBarmanObjectStoreAzureCredentialsStorageAccount>,
    /// The storage account key to be used in conjunction
    /// with the storage account name
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "storageKey")]
    pub storage_key: Option<ClusterBackupBarmanObjectStoreAzureCredentialsStorageKey>,
    /// A shared-access-signature to be used in conjunction with
    /// the storage account name
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "storageSasToken")]
    pub storage_sas_token: Option<ClusterBackupBarmanObjectStoreAzureCredentialsStorageSasToken>,
}

/// The connection string to be used
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupBarmanObjectStoreAzureCredentialsConnectionString {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The storage account where to upload data
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupBarmanObjectStoreAzureCredentialsStorageAccount {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The storage account key to be used in conjunction
/// with the storage account name
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupBarmanObjectStoreAzureCredentialsStorageKey {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// A shared-access-signature to be used in conjunction with
/// the storage account name
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupBarmanObjectStoreAzureCredentialsStorageSasToken {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The configuration to be used to backup the data files
/// When not defined, base backups files will be stored uncompressed and may
/// be unencrypted in the object store, according to the bucket default
/// policy.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupBarmanObjectStoreData {
    /// AdditionalCommandArgs represents additional arguments that can be appended
    /// to the 'barman-cloud-backup' command-line invocation. These arguments
    /// provide flexibility to customize the backup process further according to
    /// specific requirements or configurations.
    /// 
    /// Example:
    /// In a scenario where specialized backup options are required, such as setting
    /// a specific timeout or defining custom behavior, users can use this field
    /// to specify additional command arguments.
    /// 
    /// Note:
    /// It's essential to ensure that the provided arguments are valid and supported
    /// by the 'barman-cloud-backup' command, to avoid potential errors or unintended
    /// behavior during execution.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "additionalCommandArgs")]
    pub additional_command_args: Option<Vec<String>>,
    /// Compress a backup file (a tar file per tablespace) while streaming it
    /// to the object store. Available options are empty string (no
    /// compression, default), `gzip`, `bzip2`, and `snappy`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub compression: Option<ClusterBackupBarmanObjectStoreDataCompression>,
    /// Whenever to force the encryption of files (if the bucket is
    /// not already configured for that).
    /// Allowed options are empty string (use the bucket policy, default),
    /// `AES256` and `aws:kms`
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encryption: Option<ClusterBackupBarmanObjectStoreDataEncryption>,
    /// Control whether the I/O workload for the backup initial checkpoint will
    /// be limited, according to the `checkpoint_completion_target` setting on
    /// the PostgreSQL server. If set to true, an immediate checkpoint will be
    /// used, meaning PostgreSQL will complete the checkpoint as soon as
    /// possible. `false` by default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "immediateCheckpoint")]
    pub immediate_checkpoint: Option<bool>,
    /// The number of parallel jobs to be used to upload the backup, defaults
    /// to 2
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub jobs: Option<i32>,
}

/// The configuration to be used to backup the data files
/// When not defined, base backups files will be stored uncompressed and may
/// be unencrypted in the object store, according to the bucket default
/// policy.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterBackupBarmanObjectStoreDataCompression {
    #[serde(rename = "bzip2")]
    Bzip2,
    #[serde(rename = "gzip")]
    Gzip,
    #[serde(rename = "snappy")]
    Snappy,
}

/// The configuration to be used to backup the data files
/// When not defined, base backups files will be stored uncompressed and may
/// be unencrypted in the object store, according to the bucket default
/// policy.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterBackupBarmanObjectStoreDataEncryption {
    #[serde(rename = "AES256")]
    Aes256,
    #[serde(rename = "aws:kms")]
    AwsKms,
}

/// EndpointCA store the CA bundle of the barman endpoint.
/// Useful when using self-signed certificates to avoid
/// errors with certificate issuer and barman-cloud-wal-archive
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupBarmanObjectStoreEndpointCa {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The credentials to use to upload data to Google Cloud Storage
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupBarmanObjectStoreGoogleCredentials {
    /// The secret containing the Google Cloud Storage JSON file with the credentials
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "applicationCredentials")]
    pub application_credentials: Option<ClusterBackupBarmanObjectStoreGoogleCredentialsApplicationCredentials>,
    /// If set to true, will presume that it's running inside a GKE environment,
    /// default to false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "gkeEnvironment")]
    pub gke_environment: Option<bool>,
}

/// The secret containing the Google Cloud Storage JSON file with the credentials
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupBarmanObjectStoreGoogleCredentialsApplicationCredentials {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The credentials to use to upload data to S3
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupBarmanObjectStoreS3Credentials {
    /// The reference to the access key id
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "accessKeyId")]
    pub access_key_id: Option<ClusterBackupBarmanObjectStoreS3CredentialsAccessKeyId>,
    /// Use the role based authentication without providing explicitly the keys.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inheritFromIAMRole")]
    pub inherit_from_iam_role: Option<bool>,
    /// The reference to the secret containing the region name
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub region: Option<ClusterBackupBarmanObjectStoreS3CredentialsRegion>,
    /// The reference to the secret access key
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "secretAccessKey")]
    pub secret_access_key: Option<ClusterBackupBarmanObjectStoreS3CredentialsSecretAccessKey>,
    /// The references to the session key
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sessionToken")]
    pub session_token: Option<ClusterBackupBarmanObjectStoreS3CredentialsSessionToken>,
}

/// The reference to the access key id
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupBarmanObjectStoreS3CredentialsAccessKeyId {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The reference to the secret containing the region name
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupBarmanObjectStoreS3CredentialsRegion {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The reference to the secret access key
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupBarmanObjectStoreS3CredentialsSecretAccessKey {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The references to the session key
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupBarmanObjectStoreS3CredentialsSessionToken {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The configuration for the backup of the WAL stream.
/// When not defined, WAL files will be stored uncompressed and may be
/// unencrypted in the object store, according to the bucket default policy.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupBarmanObjectStoreWal {
    /// Additional arguments that can be appended to the 'barman-cloud-wal-archive'
    /// command-line invocation. These arguments provide flexibility to customize
    /// the WAL archive process further, according to specific requirements or configurations.
    /// 
    /// Example:
    /// In a scenario where specialized backup options are required, such as setting
    /// a specific timeout or defining custom behavior, users can use this field
    /// to specify additional command arguments.
    /// 
    /// Note:
    /// It's essential to ensure that the provided arguments are valid and supported
    /// by the 'barman-cloud-wal-archive' command, to avoid potential errors or unintended
    /// behavior during execution.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "archiveAdditionalCommandArgs")]
    pub archive_additional_command_args: Option<Vec<String>>,
    /// Compress a WAL file before sending it to the object store. Available
    /// options are empty string (no compression, default), `gzip`, `bzip2`,
    /// `lz4`, `snappy`, `xz`, and `zstd`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub compression: Option<ClusterBackupBarmanObjectStoreWalCompression>,
    /// Whenever to force the encryption of files (if the bucket is
    /// not already configured for that).
    /// Allowed options are empty string (use the bucket policy, default),
    /// `AES256` and `aws:kms`
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encryption: Option<ClusterBackupBarmanObjectStoreWalEncryption>,
    /// Number of WAL files to be either archived in parallel (when the
    /// PostgreSQL instance is archiving to a backup object store) or
    /// restored in parallel (when a PostgreSQL standby is fetching WAL
    /// files from a recovery object store). If not specified, WAL files
    /// will be processed one at a time. It accepts a positive integer as a
    /// value - with 1 being the minimum accepted value.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxParallel")]
    pub max_parallel: Option<i64>,
    /// Additional arguments that can be appended to the 'barman-cloud-wal-restore'
    /// command-line invocation. These arguments provide flexibility to customize
    /// the WAL restore process further, according to specific requirements or configurations.
    /// 
    /// Example:
    /// In a scenario where specialized backup options are required, such as setting
    /// a specific timeout or defining custom behavior, users can use this field
    /// to specify additional command arguments.
    /// 
    /// Note:
    /// It's essential to ensure that the provided arguments are valid and supported
    /// by the 'barman-cloud-wal-restore' command, to avoid potential errors or unintended
    /// behavior during execution.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "restoreAdditionalCommandArgs")]
    pub restore_additional_command_args: Option<Vec<String>>,
}

/// The configuration for the backup of the WAL stream.
/// When not defined, WAL files will be stored uncompressed and may be
/// unencrypted in the object store, according to the bucket default policy.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterBackupBarmanObjectStoreWalCompression {
    #[serde(rename = "bzip2")]
    Bzip2,
    #[serde(rename = "gzip")]
    Gzip,
    #[serde(rename = "lz4")]
    Lz4,
    #[serde(rename = "snappy")]
    Snappy,
    #[serde(rename = "xz")]
    Xz,
    #[serde(rename = "zstd")]
    Zstd,
}

/// The configuration for the backup of the WAL stream.
/// When not defined, WAL files will be stored uncompressed and may be
/// unencrypted in the object store, according to the bucket default policy.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterBackupBarmanObjectStoreWalEncryption {
    #[serde(rename = "AES256")]
    Aes256,
    #[serde(rename = "aws:kms")]
    AwsKms,
}

/// The configuration to be used for backups
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterBackupTarget {
    #[serde(rename = "primary")]
    Primary,
    #[serde(rename = "prefer-standby")]
    PreferStandby,
}

/// VolumeSnapshot provides the configuration for the execution of volume snapshot backups.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupVolumeSnapshot {
    /// Annotations key-value pairs that will be added to .metadata.annotations snapshot resources.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub annotations: Option<BTreeMap<String, String>>,
    /// ClassName specifies the Snapshot Class to be used for PG_DATA PersistentVolumeClaim.
    /// It is the default class for the other types if no specific class is present
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "className")]
    pub class_name: Option<String>,
    /// Labels are key-value pairs that will be added to .metadata.labels snapshot resources.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub labels: Option<BTreeMap<String, String>>,
    /// Whether the default type of backup with volume snapshots is
    /// online/hot (`true`, default) or offline/cold (`false`)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub online: Option<bool>,
    /// Configuration parameters to control the online/hot backup with volume snapshots
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "onlineConfiguration")]
    pub online_configuration: Option<ClusterBackupVolumeSnapshotOnlineConfiguration>,
    /// SnapshotOwnerReference indicates the type of owner reference the snapshot should have
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "snapshotOwnerReference")]
    pub snapshot_owner_reference: Option<ClusterBackupVolumeSnapshotSnapshotOwnerReference>,
    /// TablespaceClassName specifies the Snapshot Class to be used for the tablespaces.
    /// defaults to the PGDATA Snapshot Class, if set
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tablespaceClassName")]
    pub tablespace_class_name: Option<BTreeMap<String, String>>,
    /// WalClassName specifies the Snapshot Class to be used for the PG_WAL PersistentVolumeClaim.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "walClassName")]
    pub wal_class_name: Option<String>,
}

/// Configuration parameters to control the online/hot backup with volume snapshots
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBackupVolumeSnapshotOnlineConfiguration {
    /// Control whether the I/O workload for the backup initial checkpoint will
    /// be limited, according to the `checkpoint_completion_target` setting on
    /// the PostgreSQL server. If set to true, an immediate checkpoint will be
    /// used, meaning PostgreSQL will complete the checkpoint as soon as
    /// possible. `false` by default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "immediateCheckpoint")]
    pub immediate_checkpoint: Option<bool>,
    /// If false, the function will return immediately after the backup is completed,
    /// without waiting for WAL to be archived.
    /// This behavior is only useful with backup software that independently monitors WAL archiving.
    /// Otherwise, WAL required to make the backup consistent might be missing and make the backup useless.
    /// By default, or when this parameter is true, pg_backup_stop will wait for WAL to be archived when archiving is
    /// enabled.
    /// On a standby, this means that it will wait only when archive_mode = always.
    /// If write activity on the primary is low, it may be useful to run pg_switch_wal on the primary in order to trigger
    /// an immediate segment switch.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "waitForArchive")]
    pub wait_for_archive: Option<bool>,
}

/// VolumeSnapshot provides the configuration for the execution of volume snapshot backups.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterBackupVolumeSnapshotSnapshotOwnerReference {
    #[serde(rename = "none")]
    None,
    #[serde(rename = "cluster")]
    Cluster,
    #[serde(rename = "backup")]
    Backup,
}

/// Instructions to bootstrap this cluster
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrap {
    /// Bootstrap the cluster via initdb
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub initdb: Option<ClusterBootstrapInitdb>,
    /// Bootstrap the cluster taking a physical backup of another compatible
    /// PostgreSQL instance
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub pg_basebackup: Option<ClusterBootstrapPgBasebackup>,
    /// Bootstrap the cluster from a backup
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub recovery: Option<ClusterBootstrapRecovery>,
}

/// Bootstrap the cluster via initdb
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapInitdb {
    /// Specifies the locale name when the builtin provider is used.
    /// This option requires `localeProvider` to be set to `builtin`.
    /// Available from PostgreSQL 17.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "builtinLocale")]
    pub builtin_locale: Option<String>,
    /// Whether the `-k` option should be passed to initdb,
    /// enabling checksums on data pages (default: `false`)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataChecksums")]
    pub data_checksums: Option<bool>,
    /// Name of the database used by the application. Default: `app`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub database: Option<String>,
    /// The value to be passed as option `--encoding` for initdb (default:`UTF8`)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encoding: Option<String>,
    /// Specifies the ICU locale when the ICU provider is used.
    /// This option requires `localeProvider` to be set to `icu`.
    /// Available from PostgreSQL 15.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "icuLocale")]
    pub icu_locale: Option<String>,
    /// Specifies additional collation rules to customize the behavior of the default collation.
    /// This option requires `localeProvider` to be set to `icu`.
    /// Available from PostgreSQL 16.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "icuRules")]
    pub icu_rules: Option<String>,
    /// Bootstraps the new cluster by importing data from an existing PostgreSQL
    /// instance using logical backup (`pg_dump` and `pg_restore`)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub import: Option<ClusterBootstrapInitdbImport>,
    /// Sets the default collation order and character classification in the new database.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub locale: Option<String>,
    /// The value to be passed as option `--lc-ctype` for initdb (default:`C`)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "localeCType")]
    pub locale_c_type: Option<String>,
    /// The value to be passed as option `--lc-collate` for initdb (default:`C`)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "localeCollate")]
    pub locale_collate: Option<String>,
    /// This option sets the locale provider for databases created in the new cluster.
    /// Available from PostgreSQL 16.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "localeProvider")]
    pub locale_provider: Option<String>,
    /// The list of options that must be passed to initdb when creating the cluster.
    /// Deprecated: This could lead to inconsistent configurations,
    /// please use the explicit provided parameters instead.
    /// If defined, explicit values will be ignored.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub options: Option<Vec<String>>,
    /// Name of the owner of the database in the instance to be used
    /// by applications. Defaults to the value of the `database` key.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub owner: Option<String>,
    /// List of SQL queries to be executed as a superuser in the application
    /// database right after the cluster has been created - to be used with extreme care
    /// (by default empty)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "postInitApplicationSQL")]
    pub post_init_application_sql: Option<Vec<String>>,
    /// List of references to ConfigMaps or Secrets containing SQL files
    /// to be executed as a superuser in the application database right after
    /// the cluster has been created. The references are processed in a specific order:
    /// first, all Secrets are processed, followed by all ConfigMaps.
    /// Within each group, the processing order follows the sequence specified
    /// in their respective arrays.
    /// (by default empty)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "postInitApplicationSQLRefs")]
    pub post_init_application_sql_refs: Option<ClusterBootstrapInitdbPostInitApplicationSqlRefs>,
    /// List of SQL queries to be executed as a superuser in the `postgres`
    /// database right after the cluster has been created - to be used with extreme care
    /// (by default empty)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "postInitSQL")]
    pub post_init_sql: Option<Vec<String>>,
    /// List of references to ConfigMaps or Secrets containing SQL files
    /// to be executed as a superuser in the `postgres` database right after
    /// the cluster has been created. The references are processed in a specific order:
    /// first, all Secrets are processed, followed by all ConfigMaps.
    /// Within each group, the processing order follows the sequence specified
    /// in their respective arrays.
    /// (by default empty)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "postInitSQLRefs")]
    pub post_init_sql_refs: Option<ClusterBootstrapInitdbPostInitSqlRefs>,
    /// List of SQL queries to be executed as a superuser in the `template1`
    /// database right after the cluster has been created - to be used with extreme care
    /// (by default empty)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "postInitTemplateSQL")]
    pub post_init_template_sql: Option<Vec<String>>,
    /// List of references to ConfigMaps or Secrets containing SQL files
    /// to be executed as a superuser in the `template1` database right after
    /// the cluster has been created. The references are processed in a specific order:
    /// first, all Secrets are processed, followed by all ConfigMaps.
    /// Within each group, the processing order follows the sequence specified
    /// in their respective arrays.
    /// (by default empty)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "postInitTemplateSQLRefs")]
    pub post_init_template_sql_refs: Option<ClusterBootstrapInitdbPostInitTemplateSqlRefs>,
    /// Name of the secret containing the initial credentials for the
    /// owner of the user database. If empty a new secret will be
    /// created from scratch
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub secret: Option<ClusterBootstrapInitdbSecret>,
    /// The value in megabytes (1 to 1024) to be passed to the `--wal-segsize`
    /// option for initdb (default: empty, resulting in PostgreSQL default: 16MB)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "walSegmentSize")]
    pub wal_segment_size: Option<i64>,
}

/// Bootstraps the new cluster by importing data from an existing PostgreSQL
/// instance using logical backup (`pg_dump` and `pg_restore`)
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct ClusterBootstrapInitdbImport {
    /// The databases to import
    pub databases: Vec<String>,
    /// List of custom options to pass to the `pg_dump` command. IMPORTANT:
    /// Use these options with caution and at your own risk, as the operator
    /// does not validate their content. Be aware that certain options may
    /// conflict with the operator's intended functionality or design.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "pgDumpExtraOptions")]
    pub pg_dump_extra_options: Option<Vec<String>>,
    /// List of custom options to pass to the `pg_restore` command. IMPORTANT:
    /// Use these options with caution and at your own risk, as the operator
    /// does not validate their content. Be aware that certain options may
    /// conflict with the operator's intended functionality or design.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "pgRestoreExtraOptions")]
    pub pg_restore_extra_options: Option<Vec<String>>,
    /// List of SQL queries to be executed as a superuser in the application
    /// database right after is imported - to be used with extreme care
    /// (by default empty). Only available in microservice type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "postImportApplicationSQL")]
    pub post_import_application_sql: Option<Vec<String>>,
    /// The roles to import
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub roles: Option<Vec<String>>,
    /// When set to true, only the `pre-data` and `post-data` sections of
    /// `pg_restore` are invoked, avoiding data import. Default: `false`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "schemaOnly")]
    pub schema_only: Option<bool>,
    /// The source of the import
    pub source: ClusterBootstrapInitdbImportSource,
    /// The import type. Can be `microservice` or `monolith`.
    #[serde(rename = "type")]
    pub r#type: ClusterBootstrapInitdbImportType,
}

/// The source of the import
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapInitdbImportSource {
    /// The name of the externalCluster used for import
    #[serde(rename = "externalCluster")]
    pub external_cluster: String,
}

/// Bootstraps the new cluster by importing data from an existing PostgreSQL
/// instance using logical backup (`pg_dump` and `pg_restore`)
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterBootstrapInitdbImportType {
    #[serde(rename = "microservice")]
    Microservice,
    #[serde(rename = "monolith")]
    Monolith,
}

/// List of references to ConfigMaps or Secrets containing SQL files
/// to be executed as a superuser in the application database right after
/// the cluster has been created. The references are processed in a specific order:
/// first, all Secrets are processed, followed by all ConfigMaps.
/// Within each group, the processing order follows the sequence specified
/// in their respective arrays.
/// (by default empty)
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapInitdbPostInitApplicationSqlRefs {
    /// ConfigMapRefs holds a list of references to ConfigMaps
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configMapRefs")]
    pub config_map_refs: Option<Vec<ClusterBootstrapInitdbPostInitApplicationSqlRefsConfigMapRefs>>,
    /// SecretRefs holds a list of references to Secrets
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "secretRefs")]
    pub secret_refs: Option<Vec<ClusterBootstrapInitdbPostInitApplicationSqlRefsSecretRefs>>,
}

/// ConfigMapKeySelector contains enough information to let you locate
/// the key of a ConfigMap
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapInitdbPostInitApplicationSqlRefsConfigMapRefs {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// SecretKeySelector contains enough information to let you locate
/// the key of a Secret
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapInitdbPostInitApplicationSqlRefsSecretRefs {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// List of references to ConfigMaps or Secrets containing SQL files
/// to be executed as a superuser in the `postgres` database right after
/// the cluster has been created. The references are processed in a specific order:
/// first, all Secrets are processed, followed by all ConfigMaps.
/// Within each group, the processing order follows the sequence specified
/// in their respective arrays.
/// (by default empty)
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapInitdbPostInitSqlRefs {
    /// ConfigMapRefs holds a list of references to ConfigMaps
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configMapRefs")]
    pub config_map_refs: Option<Vec<ClusterBootstrapInitdbPostInitSqlRefsConfigMapRefs>>,
    /// SecretRefs holds a list of references to Secrets
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "secretRefs")]
    pub secret_refs: Option<Vec<ClusterBootstrapInitdbPostInitSqlRefsSecretRefs>>,
}

/// ConfigMapKeySelector contains enough information to let you locate
/// the key of a ConfigMap
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapInitdbPostInitSqlRefsConfigMapRefs {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// SecretKeySelector contains enough information to let you locate
/// the key of a Secret
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapInitdbPostInitSqlRefsSecretRefs {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// List of references to ConfigMaps or Secrets containing SQL files
/// to be executed as a superuser in the `template1` database right after
/// the cluster has been created. The references are processed in a specific order:
/// first, all Secrets are processed, followed by all ConfigMaps.
/// Within each group, the processing order follows the sequence specified
/// in their respective arrays.
/// (by default empty)
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapInitdbPostInitTemplateSqlRefs {
    /// ConfigMapRefs holds a list of references to ConfigMaps
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configMapRefs")]
    pub config_map_refs: Option<Vec<ClusterBootstrapInitdbPostInitTemplateSqlRefsConfigMapRefs>>,
    /// SecretRefs holds a list of references to Secrets
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "secretRefs")]
    pub secret_refs: Option<Vec<ClusterBootstrapInitdbPostInitTemplateSqlRefsSecretRefs>>,
}

/// ConfigMapKeySelector contains enough information to let you locate
/// the key of a ConfigMap
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapInitdbPostInitTemplateSqlRefsConfigMapRefs {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// SecretKeySelector contains enough information to let you locate
/// the key of a Secret
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapInitdbPostInitTemplateSqlRefsSecretRefs {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// Name of the secret containing the initial credentials for the
/// owner of the user database. If empty a new secret will be
/// created from scratch
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapInitdbSecret {
    /// Name of the referent.
    pub name: String,
}

/// Bootstrap the cluster taking a physical backup of another compatible
/// PostgreSQL instance
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapPgBasebackup {
    /// Name of the database used by the application. Default: `app`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub database: Option<String>,
    /// Name of the owner of the database in the instance to be used
    /// by applications. Defaults to the value of the `database` key.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub owner: Option<String>,
    /// Name of the secret containing the initial credentials for the
    /// owner of the user database. If empty a new secret will be
    /// created from scratch
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub secret: Option<ClusterBootstrapPgBasebackupSecret>,
    /// The name of the server of which we need to take a physical backup
    pub source: String,
}

/// Name of the secret containing the initial credentials for the
/// owner of the user database. If empty a new secret will be
/// created from scratch
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapPgBasebackupSecret {
    /// Name of the referent.
    pub name: String,
}

/// Bootstrap the cluster from a backup
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapRecovery {
    /// The backup object containing the physical base backup from which to
    /// initiate the recovery procedure.
    /// Mutually exclusive with `source` and `volumeSnapshots`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub backup: Option<ClusterBootstrapRecoveryBackup>,
    /// Name of the database used by the application. Default: `app`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub database: Option<String>,
    /// Name of the owner of the database in the instance to be used
    /// by applications. Defaults to the value of the `database` key.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub owner: Option<String>,
    /// By default, the recovery process applies all the available
    /// WAL files in the archive (full recovery). However, you can also
    /// end the recovery as soon as a consistent state is reached or
    /// recover to a point-in-time (PITR) by specifying a `RecoveryTarget` object,
    /// as expected by PostgreSQL (i.e., timestamp, transaction Id, LSN, ...).
    /// More info: <https://www.postgresql.org/docs/current/runtime-config-wal.html#RUNTIME-CONFIG-WAL-RECOVERY-TARGET>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "recoveryTarget")]
    pub recovery_target: Option<ClusterBootstrapRecoveryRecoveryTarget>,
    /// Name of the secret containing the initial credentials for the
    /// owner of the user database. If empty a new secret will be
    /// created from scratch
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub secret: Option<ClusterBootstrapRecoverySecret>,
    /// The external cluster whose backup we will restore. This is also
    /// used as the name of the folder under which the backup is stored,
    /// so it must be set to the name of the source cluster
    /// Mutually exclusive with `backup`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub source: Option<String>,
    /// The static PVC data source(s) from which to initiate the
    /// recovery procedure. Currently supporting `VolumeSnapshot`
    /// and `PersistentVolumeClaim` resources that map an existing
    /// PVC group, compatible with CloudNativePG, and taken with
    /// a cold backup copy on a fenced Postgres instance (limitation
    /// which will be removed in the future when online backup
    /// will be implemented).
    /// Mutually exclusive with `backup`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeSnapshots")]
    pub volume_snapshots: Option<ClusterBootstrapRecoveryVolumeSnapshots>,
}

/// The backup object containing the physical base backup from which to
/// initiate the recovery procedure.
/// Mutually exclusive with `source` and `volumeSnapshots`.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapRecoveryBackup {
    /// EndpointCA store the CA bundle of the barman endpoint.
    /// Useful when using self-signed certificates to avoid
    /// errors with certificate issuer and barman-cloud-wal-archive.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "endpointCA")]
    pub endpoint_ca: Option<ClusterBootstrapRecoveryBackupEndpointCa>,
    /// Name of the referent.
    pub name: String,
}

/// EndpointCA store the CA bundle of the barman endpoint.
/// Useful when using self-signed certificates to avoid
/// errors with certificate issuer and barman-cloud-wal-archive.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapRecoveryBackupEndpointCa {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// By default, the recovery process applies all the available
/// WAL files in the archive (full recovery). However, you can also
/// end the recovery as soon as a consistent state is reached or
/// recover to a point-in-time (PITR) by specifying a `RecoveryTarget` object,
/// as expected by PostgreSQL (i.e., timestamp, transaction Id, LSN, ...).
/// More info: <https://www.postgresql.org/docs/current/runtime-config-wal.html#RUNTIME-CONFIG-WAL-RECOVERY-TARGET>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapRecoveryRecoveryTarget {
    /// The ID of the backup from which to start the recovery process.
    /// If empty (default) the operator will automatically detect the backup
    /// based on targetTime or targetLSN if specified. Otherwise use the
    /// latest available backup in chronological order.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "backupID")]
    pub backup_id: Option<String>,
    /// Set the target to be exclusive. If omitted, defaults to false, so that
    /// in Postgres, `recovery_target_inclusive` will be true
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub exclusive: Option<bool>,
    /// End recovery as soon as a consistent state is reached
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "targetImmediate")]
    pub target_immediate: Option<bool>,
    /// The target LSN (Log Sequence Number)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "targetLSN")]
    pub target_lsn: Option<String>,
    /// The target name (to be previously created
    /// with `pg_create_restore_point`)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "targetName")]
    pub target_name: Option<String>,
    /// The target timeline ("latest" or a positive integer)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "targetTLI")]
    pub target_tli: Option<String>,
    /// The target time as a timestamp in the RFC3339 standard
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "targetTime")]
    pub target_time: Option<String>,
    /// The target transaction ID
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "targetXID")]
    pub target_xid: Option<String>,
}

/// Name of the secret containing the initial credentials for the
/// owner of the user database. If empty a new secret will be
/// created from scratch
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapRecoverySecret {
    /// Name of the referent.
    pub name: String,
}

/// The static PVC data source(s) from which to initiate the
/// recovery procedure. Currently supporting `VolumeSnapshot`
/// and `PersistentVolumeClaim` resources that map an existing
/// PVC group, compatible with CloudNativePG, and taken with
/// a cold backup copy on a fenced Postgres instance (limitation
/// which will be removed in the future when online backup
/// will be implemented).
/// Mutually exclusive with `backup`.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapRecoveryVolumeSnapshots {
    /// Configuration of the storage of the instances
    pub storage: ClusterBootstrapRecoveryVolumeSnapshotsStorage,
    /// Configuration of the storage for PostgreSQL tablespaces
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tablespaceStorage")]
    pub tablespace_storage: Option<BTreeMap<String, ClusterBootstrapRecoveryVolumeSnapshotsTablespaceStorage>>,
    /// Configuration of the storage for PostgreSQL WAL (Write-Ahead Log)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "walStorage")]
    pub wal_storage: Option<ClusterBootstrapRecoveryVolumeSnapshotsWalStorage>,
}

/// Configuration of the storage of the instances
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapRecoveryVolumeSnapshotsStorage {
    /// APIGroup is the group for the resource being referenced.
    /// If APIGroup is not specified, the specified Kind must be in the core API group.
    /// For any other third-party types, APIGroup is required.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiGroup")]
    pub api_group: Option<String>,
    /// Kind is the type of resource being referenced
    pub kind: String,
    /// Name is the name of resource being referenced
    pub name: String,
}

/// Configuration of the storage for PostgreSQL tablespaces
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapRecoveryVolumeSnapshotsTablespaceStorage {
    /// APIGroup is the group for the resource being referenced.
    /// If APIGroup is not specified, the specified Kind must be in the core API group.
    /// For any other third-party types, APIGroup is required.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiGroup")]
    pub api_group: Option<String>,
    /// Kind is the type of resource being referenced
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub kind: Option<String>,
    /// Name is the name of resource being referenced
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// Configuration of the storage for PostgreSQL WAL (Write-Ahead Log)
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterBootstrapRecoveryVolumeSnapshotsWalStorage {
    /// APIGroup is the group for the resource being referenced.
    /// If APIGroup is not specified, the specified Kind must be in the core API group.
    /// For any other third-party types, APIGroup is required.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiGroup")]
    pub api_group: Option<String>,
    /// Kind is the type of resource being referenced
    pub kind: String,
    /// Name is the name of resource being referenced
    pub name: String,
}

/// The configuration for the CA and related certificates
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterCertificates {
    /// The secret containing the Client CA certificate. If not defined, a new secret will be created
    /// with a self-signed CA and will be used to generate all the client certificates.<br />
    /// <br />
    /// Contains:<br />
    /// <br />
    /// - `ca.crt`: CA that should be used to validate the client certificates,
    /// used as `ssl_ca_file` of all the instances.<br />
    /// - `ca.key`: key used to generate client certificates, if ReplicationTLSSecret is provided,
    /// this can be omitted.<br />
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clientCASecret")]
    pub client_ca_secret: Option<String>,
    /// The secret of type kubernetes.io/tls containing the client certificate to authenticate as
    /// the `streaming_replica` user.
    /// If not defined, ClientCASecret must provide also `ca.key`, and a new secret will be
    /// created using the provided CA.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "replicationTLSSecret")]
    pub replication_tls_secret: Option<String>,
    /// The list of the server alternative DNS names to be added to the generated server TLS certificates, when required.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "serverAltDNSNames")]
    pub server_alt_dns_names: Option<Vec<String>>,
    /// The secret containing the Server CA certificate. If not defined, a new secret will be created
    /// with a self-signed CA and will be used to generate the TLS certificate ServerTLSSecret.<br />
    /// <br />
    /// Contains:<br />
    /// <br />
    /// - `ca.crt`: CA that should be used to validate the server certificate,
    /// used as `sslrootcert` in client connection strings.<br />
    /// - `ca.key`: key used to generate Server SSL certs, if ServerTLSSecret is provided,
    /// this can be omitted.<br />
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "serverCASecret")]
    pub server_ca_secret: Option<String>,
    /// The secret of type kubernetes.io/tls containing the server TLS certificate and key that will be set as
    /// `ssl_cert_file` and `ssl_key_file` so that clients can connect to postgres securely.
    /// If not defined, ServerCASecret must provide also `ca.key` and a new secret will be
    /// created using the provided CA.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "serverTLSSecret")]
    pub server_tls_secret: Option<String>,
}

/// EnvVar represents an environment variable present in a Container.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEnv {
    /// Name of the environment variable.
    /// May consist of any printable ASCII characters except '='.
    pub name: String,
    /// Variable references $(VAR_NAME) are expanded
    /// using the previously defined environment variables in the container and
    /// any service environment variables. If a variable cannot be resolved,
    /// the reference in the input string will be unchanged. Double $$ are reduced
    /// to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e.
    /// "$$(VAR_NAME)" will produce the string literal "$(VAR_NAME)".
    /// Escaped references will never be expanded, regardless of whether the variable
    /// exists or not.
    /// Defaults to "".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<String>,
    /// Source for the environment variable's value. Cannot be used if value is not empty.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "valueFrom")]
    pub value_from: Option<ClusterEnvValueFrom>,
}

/// Source for the environment variable's value. Cannot be used if value is not empty.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEnvValueFrom {
    /// Selects a key of a ConfigMap.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configMapKeyRef")]
    pub config_map_key_ref: Option<ClusterEnvValueFromConfigMapKeyRef>,
    /// Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['<KEY>']`, `metadata.annotations['<KEY>']`,
    /// spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldRef")]
    pub field_ref: Option<ClusterEnvValueFromFieldRef>,
    /// FileKeyRef selects a key of the env file.
    /// Requires the EnvFiles feature gate to be enabled.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fileKeyRef")]
    pub file_key_ref: Option<ClusterEnvValueFromFileKeyRef>,
    /// Selects a resource of the container: only resources limits and requests
    /// (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "resourceFieldRef")]
    pub resource_field_ref: Option<ClusterEnvValueFromResourceFieldRef>,
    /// Selects a key of a secret in the pod's namespace
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "secretKeyRef")]
    pub secret_key_ref: Option<ClusterEnvValueFromSecretKeyRef>,
}

/// Selects a key of a ConfigMap.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEnvValueFromConfigMapKeyRef {
    /// The key to select.
    pub key: String,
    /// Name of the referent.
    /// This field is effectively required, but due to backwards compatibility is
    /// allowed to be empty. Instances of this type with an empty value here are
    /// almost certainly wrong.
    /// More info: <https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Specify whether the ConfigMap or its key must be defined
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub optional: Option<bool>,
}

/// Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['<KEY>']`, `metadata.annotations['<KEY>']`,
/// spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEnvValueFromFieldRef {
    /// Version of the schema the FieldPath is written in terms of, defaults to "v1".
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiVersion")]
    pub api_version: Option<String>,
    /// Path of the field to select in the specified API version.
    #[serde(rename = "fieldPath")]
    pub field_path: String,
}

/// FileKeyRef selects a key of the env file.
/// Requires the EnvFiles feature gate to be enabled.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEnvValueFromFileKeyRef {
    /// The key within the env file. An invalid key will prevent the pod from starting.
    /// The keys defined within a source may consist of any printable ASCII characters except '='.
    /// During Alpha stage of the EnvFiles feature gate, the key size is limited to 128 characters.
    pub key: String,
    /// Specify whether the file or its key must be defined. If the file or key
    /// does not exist, then the env var is not published.
    /// If optional is set to true and the specified key does not exist,
    /// the environment variable will not be set in the Pod's containers.
    /// 
    /// If optional is set to false and the specified key does not exist,
    /// an error will be returned during Pod creation.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub optional: Option<bool>,
    /// The path within the volume from which to select the file.
    /// Must be relative and may not contain the '..' path or start with '..'.
    pub path: String,
    /// The name of the volume mount containing the env file.
    #[serde(rename = "volumeName")]
    pub volume_name: String,
}

/// Selects a resource of the container: only resources limits and requests
/// (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEnvValueFromResourceFieldRef {
    /// Container name: required for volumes, optional for env vars
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "containerName")]
    pub container_name: Option<String>,
    /// Specifies the output format of the exposed resources, defaults to "1"
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub divisor: Option<IntOrString>,
    /// Required: resource to select
    pub resource: String,
}

/// Selects a key of a secret in the pod's namespace
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEnvValueFromSecretKeyRef {
    /// The key of the secret to select from.  Must be a valid secret key.
    pub key: String,
    /// Name of the referent.
    /// This field is effectively required, but due to backwards compatibility is
    /// allowed to be empty. Instances of this type with an empty value here are
    /// almost certainly wrong.
    /// More info: <https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Specify whether the Secret or its key must be defined
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub optional: Option<bool>,
}

/// EnvFromSource represents the source of a set of ConfigMaps or Secrets
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEnvFrom {
    /// The ConfigMap to select from
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configMapRef")]
    pub config_map_ref: Option<ClusterEnvFromConfigMapRef>,
    /// Optional text to prepend to the name of each environment variable.
    /// May consist of any printable ASCII characters except '='.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub prefix: Option<String>,
    /// The Secret to select from
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "secretRef")]
    pub secret_ref: Option<ClusterEnvFromSecretRef>,
}

/// The ConfigMap to select from
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEnvFromConfigMapRef {
    /// Name of the referent.
    /// This field is effectively required, but due to backwards compatibility is
    /// allowed to be empty. Instances of this type with an empty value here are
    /// almost certainly wrong.
    /// More info: <https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Specify whether the ConfigMap must be defined
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub optional: Option<bool>,
}

/// The Secret to select from
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEnvFromSecretRef {
    /// Name of the referent.
    /// This field is effectively required, but due to backwards compatibility is
    /// allowed to be empty. Instances of this type with an empty value here are
    /// almost certainly wrong.
    /// More info: <https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Specify whether the Secret must be defined
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub optional: Option<bool>,
}

/// EphemeralVolumeSource allows the user to configure the source of ephemeral volumes.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEphemeralVolumeSource {
    /// Will be used to create a stand-alone PVC to provision the volume.
    /// The pod in which this EphemeralVolumeSource is embedded will be the
    /// owner of the PVC, i.e. the PVC will be deleted together with the
    /// pod.  The name of the PVC will be `<pod name>-<volume name>` where
    /// `<volume name>` is the name from the `PodSpec.Volumes` array
    /// entry. Pod validation will reject the pod if the concatenated name
    /// is not valid for a PVC (for example, too long).
    /// 
    /// An existing PVC with that name that is not owned by the pod
    /// will *not* be used for the pod to avoid using an unrelated
    /// volume by mistake. Starting the pod is then blocked until
    /// the unrelated PVC is removed. If such a pre-created PVC is
    /// meant to be used by the pod, the PVC has to updated with an
    /// owner reference to the pod once the pod exists. Normally
    /// this should not be necessary, but it may be useful when
    /// manually reconstructing a broken cluster.
    /// 
    /// This field is read-only and no changes will be made by Kubernetes
    /// to the PVC after it has been created.
    /// 
    /// Required, must not be nil.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeClaimTemplate")]
    pub volume_claim_template: Option<ClusterEphemeralVolumeSourceVolumeClaimTemplate>,
}

/// Will be used to create a stand-alone PVC to provision the volume.
/// The pod in which this EphemeralVolumeSource is embedded will be the
/// owner of the PVC, i.e. the PVC will be deleted together with the
/// pod.  The name of the PVC will be `<pod name>-<volume name>` where
/// `<volume name>` is the name from the `PodSpec.Volumes` array
/// entry. Pod validation will reject the pod if the concatenated name
/// is not valid for a PVC (for example, too long).
/// 
/// An existing PVC with that name that is not owned by the pod
/// will *not* be used for the pod to avoid using an unrelated
/// volume by mistake. Starting the pod is then blocked until
/// the unrelated PVC is removed. If such a pre-created PVC is
/// meant to be used by the pod, the PVC has to updated with an
/// owner reference to the pod once the pod exists. Normally
/// this should not be necessary, but it may be useful when
/// manually reconstructing a broken cluster.
/// 
/// This field is read-only and no changes will be made by Kubernetes
/// to the PVC after it has been created.
/// 
/// Required, must not be nil.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEphemeralVolumeSourceVolumeClaimTemplate {
    /// May contain labels and annotations that will be copied into the PVC
    /// when creating it. No other fields are allowed and will be rejected during
    /// validation.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metadata: Option<ClusterEphemeralVolumeSourceVolumeClaimTemplateMetadata>,
    /// The specification for the PersistentVolumeClaim. The entire content is
    /// copied unchanged into the PVC that gets created from this
    /// template. The same fields as in a PersistentVolumeClaim
    /// are also valid here.
    pub spec: ClusterEphemeralVolumeSourceVolumeClaimTemplateSpec,
}

/// May contain labels and annotations that will be copied into the PVC
/// when creating it. No other fields are allowed and will be rejected during
/// validation.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEphemeralVolumeSourceVolumeClaimTemplateMetadata {
}

/// The specification for the PersistentVolumeClaim. The entire content is
/// copied unchanged into the PVC that gets created from this
/// template. The same fields as in a PersistentVolumeClaim
/// are also valid here.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEphemeralVolumeSourceVolumeClaimTemplateSpec {
    /// accessModes contains the desired access modes the volume should have.
    /// More info: <https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "accessModes")]
    pub access_modes: Option<Vec<String>>,
    /// dataSource field can be used to specify either:
    /// * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)
    /// * An existing PVC (PersistentVolumeClaim)
    /// If the provisioner or an external controller can support the specified data source,
    /// it will create a new volume based on the contents of the specified data source.
    /// When the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,
    /// and dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.
    /// If the namespace is specified, then dataSourceRef will not be copied to dataSource.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataSource")]
    pub data_source: Option<ClusterEphemeralVolumeSourceVolumeClaimTemplateSpecDataSource>,
    /// dataSourceRef specifies the object from which to populate the volume with data, if a non-empty
    /// volume is desired. This may be any object from a non-empty API group (non
    /// core object) or a PersistentVolumeClaim object.
    /// When this field is specified, volume binding will only succeed if the type of
    /// the specified object matches some installed volume populator or dynamic
    /// provisioner.
    /// This field will replace the functionality of the dataSource field and as such
    /// if both fields are non-empty, they must have the same value. For backwards
    /// compatibility, when namespace isn't specified in dataSourceRef,
    /// both fields (dataSource and dataSourceRef) will be set to the same
    /// value automatically if one of them is empty and the other is non-empty.
    /// When namespace is specified in dataSourceRef,
    /// dataSource isn't set to the same value and must be empty.
    /// There are three important differences between dataSource and dataSourceRef:
    /// * While dataSource only allows two specific types of objects, dataSourceRef
    ///   allows any non-core object, as well as PersistentVolumeClaim objects.
    /// * While dataSource ignores disallowed values (dropping them), dataSourceRef
    ///   preserves all values, and generates an error if a disallowed value is
    ///   specified.
    /// * While dataSource only allows local objects, dataSourceRef allows objects
    ///   in any namespaces.
    /// (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
    /// (Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataSourceRef")]
    pub data_source_ref: Option<ClusterEphemeralVolumeSourceVolumeClaimTemplateSpecDataSourceRef>,
    /// resources represents the minimum resources the volume should have.
    /// If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements
    /// that are lower than previous value but must still be higher than capacity recorded in the
    /// status field of the claim.
    /// More info: <https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resources: Option<ClusterEphemeralVolumeSourceVolumeClaimTemplateSpecResources>,
    /// selector is a label query over volumes to consider for binding.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selector: Option<ClusterEphemeralVolumeSourceVolumeClaimTemplateSpecSelector>,
    /// storageClassName is the name of the StorageClass required by the claim.
    /// More info: <https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "storageClassName")]
    pub storage_class_name: Option<String>,
    /// volumeAttributesClassName may be used to set the VolumeAttributesClass used by this claim.
    /// If specified, the CSI driver will create or update the volume with the attributes defined
    /// in the corresponding VolumeAttributesClass. This has a different purpose than storageClassName,
    /// it can be changed after the claim is created. An empty string or nil value indicates that no
    /// VolumeAttributesClass will be applied to the claim. If the claim enters an Infeasible error state,
    /// this field can be reset to its previous value (including nil) to cancel the modification.
    /// If the resource referred to by volumeAttributesClass does not exist, this PersistentVolumeClaim will be
    /// set to a Pending state, as reflected by the modifyVolumeStatus field, until such as a resource
    /// exists.
    /// More info: <https://kubernetes.io/docs/concepts/storage/volume-attributes-classes/>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeAttributesClassName")]
    pub volume_attributes_class_name: Option<String>,
    /// volumeMode defines what type of volume is required by the claim.
    /// Value of Filesystem is implied when not included in claim spec.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeMode")]
    pub volume_mode: Option<String>,
    /// volumeName is the binding reference to the PersistentVolume backing this claim.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeName")]
    pub volume_name: Option<String>,
}

/// dataSource field can be used to specify either:
/// * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)
/// * An existing PVC (PersistentVolumeClaim)
/// If the provisioner or an external controller can support the specified data source,
/// it will create a new volume based on the contents of the specified data source.
/// When the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,
/// and dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.
/// If the namespace is specified, then dataSourceRef will not be copied to dataSource.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEphemeralVolumeSourceVolumeClaimTemplateSpecDataSource {
    /// APIGroup is the group for the resource being referenced.
    /// If APIGroup is not specified, the specified Kind must be in the core API group.
    /// For any other third-party types, APIGroup is required.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiGroup")]
    pub api_group: Option<String>,
    /// Kind is the type of resource being referenced
    pub kind: String,
    /// Name is the name of resource being referenced
    pub name: String,
}

/// dataSourceRef specifies the object from which to populate the volume with data, if a non-empty
/// volume is desired. This may be any object from a non-empty API group (non
/// core object) or a PersistentVolumeClaim object.
/// When this field is specified, volume binding will only succeed if the type of
/// the specified object matches some installed volume populator or dynamic
/// provisioner.
/// This field will replace the functionality of the dataSource field and as such
/// if both fields are non-empty, they must have the same value. For backwards
/// compatibility, when namespace isn't specified in dataSourceRef,
/// both fields (dataSource and dataSourceRef) will be set to the same
/// value automatically if one of them is empty and the other is non-empty.
/// When namespace is specified in dataSourceRef,
/// dataSource isn't set to the same value and must be empty.
/// There are three important differences between dataSource and dataSourceRef:
/// * While dataSource only allows two specific types of objects, dataSourceRef
///   allows any non-core object, as well as PersistentVolumeClaim objects.
/// * While dataSource ignores disallowed values (dropping them), dataSourceRef
///   preserves all values, and generates an error if a disallowed value is
///   specified.
/// * While dataSource only allows local objects, dataSourceRef allows objects
///   in any namespaces.
/// (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
/// (Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEphemeralVolumeSourceVolumeClaimTemplateSpecDataSourceRef {
    /// APIGroup is the group for the resource being referenced.
    /// If APIGroup is not specified, the specified Kind must be in the core API group.
    /// For any other third-party types, APIGroup is required.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiGroup")]
    pub api_group: Option<String>,
    /// Kind is the type of resource being referenced
    pub kind: String,
    /// Name is the name of resource being referenced
    pub name: String,
    /// Namespace is the namespace of resource being referenced
    /// Note that when a namespace is specified, a gateway.networking.k8s.io/ReferenceGrant object is required in the referent namespace to allow that namespace's owner to accept the reference. See the ReferenceGrant documentation for details.
    /// (Alpha) This field requires the CrossNamespaceVolumeDataSource feature gate to be enabled.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
}

/// resources represents the minimum resources the volume should have.
/// If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements
/// that are lower than previous value but must still be higher than capacity recorded in the
/// status field of the claim.
/// More info: <https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEphemeralVolumeSourceVolumeClaimTemplateSpecResources {
    /// Limits describes the maximum amount of compute resources allowed.
    /// More info: <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub limits: Option<BTreeMap<String, IntOrString>>,
    /// Requests describes the minimum amount of compute resources required.
    /// If Requests is omitted for a container, it defaults to Limits if that is explicitly specified,
    /// otherwise to an implementation-defined value. Requests cannot exceed Limits.
    /// More info: <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub requests: Option<BTreeMap<String, IntOrString>>,
}

/// selector is a label query over volumes to consider for binding.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEphemeralVolumeSourceVolumeClaimTemplateSpecSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterEphemeralVolumeSourceVolumeClaimTemplateSpecSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEphemeralVolumeSourceVolumeClaimTemplateSpecSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// EphemeralVolumesSizeLimit allows the user to set the limits for the ephemeral
/// volumes
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterEphemeralVolumesSizeLimit {
    /// Shm is the size limit of the shared memory volume
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub shm: Option<IntOrString>,
    /// TemporaryData is the size limit of the temporary data volume
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "temporaryData")]
    pub temporary_data: Option<IntOrString>,
}

/// ExternalCluster represents the connection parameters to an
/// external cluster which is used in the other sections of the configuration
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClusters {
    /// The configuration for the barman-cloud tool suite
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "barmanObjectStore")]
    pub barman_object_store: Option<ClusterExternalClustersBarmanObjectStore>,
    /// The list of connection parameters, such as dbname, host, username, etc
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "connectionParameters")]
    pub connection_parameters: Option<BTreeMap<String, String>>,
    /// The server name, required
    pub name: String,
    /// The reference to the password to be used to connect to the server.
    /// If a password is provided, CloudNativePG creates a PostgreSQL
    /// passfile at `/controller/external/NAME/pass` (where "NAME" is the
    /// cluster's name). This passfile is automatically referenced in the
    /// connection string when establishing a connection to the remote
    /// PostgreSQL server from the current PostgreSQL `Cluster`. This ensures
    /// secure and efficient password management for external clusters.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub password: Option<ClusterExternalClustersPassword>,
    /// The configuration of the plugin that is taking care
    /// of WAL archiving and backups for this external cluster
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub plugin: Option<ClusterExternalClustersPlugin>,
    /// The reference to an SSL certificate to be used to connect to this
    /// instance
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sslCert")]
    pub ssl_cert: Option<ClusterExternalClustersSslCert>,
    /// The reference to an SSL private key to be used to connect to this
    /// instance
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sslKey")]
    pub ssl_key: Option<ClusterExternalClustersSslKey>,
    /// The reference to an SSL CA public key to be used to connect to this
    /// instance
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sslRootCert")]
    pub ssl_root_cert: Option<ClusterExternalClustersSslRootCert>,
}

/// The configuration for the barman-cloud tool suite
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersBarmanObjectStore {
    /// The credentials to use to upload data to Azure Blob Storage
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "azureCredentials")]
    pub azure_credentials: Option<ClusterExternalClustersBarmanObjectStoreAzureCredentials>,
    /// The configuration to be used to backup the data files
    /// When not defined, base backups files will be stored uncompressed and may
    /// be unencrypted in the object store, according to the bucket default
    /// policy.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub data: Option<ClusterExternalClustersBarmanObjectStoreData>,
    /// The path where to store the backup (i.e. s3://bucket/path/to/folder)
    /// this path, with different destination folders, will be used for WALs
    /// and for data
    #[serde(rename = "destinationPath")]
    pub destination_path: String,
    /// EndpointCA store the CA bundle of the barman endpoint.
    /// Useful when using self-signed certificates to avoid
    /// errors with certificate issuer and barman-cloud-wal-archive
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "endpointCA")]
    pub endpoint_ca: Option<ClusterExternalClustersBarmanObjectStoreEndpointCa>,
    /// Endpoint to be used to upload data to the cloud,
    /// overriding the automatic endpoint discovery
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "endpointURL")]
    pub endpoint_url: Option<String>,
    /// The credentials to use to upload data to Google Cloud Storage
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "googleCredentials")]
    pub google_credentials: Option<ClusterExternalClustersBarmanObjectStoreGoogleCredentials>,
    /// HistoryTags is a list of key value pairs that will be passed to the
    /// Barman --history-tags option.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "historyTags")]
    pub history_tags: Option<BTreeMap<String, String>>,
    /// The credentials to use to upload data to S3
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3Credentials")]
    pub s3_credentials: Option<ClusterExternalClustersBarmanObjectStoreS3Credentials>,
    /// The server name on S3, the cluster name is used if this
    /// parameter is omitted
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "serverName")]
    pub server_name: Option<String>,
    /// Tags is a list of key value pairs that will be passed to the
    /// Barman --tags option.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tags: Option<BTreeMap<String, String>>,
    /// The configuration for the backup of the WAL stream.
    /// When not defined, WAL files will be stored uncompressed and may be
    /// unencrypted in the object store, according to the bucket default policy.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub wal: Option<ClusterExternalClustersBarmanObjectStoreWal>,
}

/// The credentials to use to upload data to Azure Blob Storage
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersBarmanObjectStoreAzureCredentials {
    /// The connection string to be used
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "connectionString")]
    pub connection_string: Option<ClusterExternalClustersBarmanObjectStoreAzureCredentialsConnectionString>,
    /// Use the Azure AD based authentication without providing explicitly the keys.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inheritFromAzureAD")]
    pub inherit_from_azure_ad: Option<bool>,
    /// The storage account where to upload data
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "storageAccount")]
    pub storage_account: Option<ClusterExternalClustersBarmanObjectStoreAzureCredentialsStorageAccount>,
    /// The storage account key to be used in conjunction
    /// with the storage account name
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "storageKey")]
    pub storage_key: Option<ClusterExternalClustersBarmanObjectStoreAzureCredentialsStorageKey>,
    /// A shared-access-signature to be used in conjunction with
    /// the storage account name
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "storageSasToken")]
    pub storage_sas_token: Option<ClusterExternalClustersBarmanObjectStoreAzureCredentialsStorageSasToken>,
}

/// The connection string to be used
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersBarmanObjectStoreAzureCredentialsConnectionString {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The storage account where to upload data
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersBarmanObjectStoreAzureCredentialsStorageAccount {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The storage account key to be used in conjunction
/// with the storage account name
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersBarmanObjectStoreAzureCredentialsStorageKey {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// A shared-access-signature to be used in conjunction with
/// the storage account name
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersBarmanObjectStoreAzureCredentialsStorageSasToken {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The configuration to be used to backup the data files
/// When not defined, base backups files will be stored uncompressed and may
/// be unencrypted in the object store, according to the bucket default
/// policy.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersBarmanObjectStoreData {
    /// AdditionalCommandArgs represents additional arguments that can be appended
    /// to the 'barman-cloud-backup' command-line invocation. These arguments
    /// provide flexibility to customize the backup process further according to
    /// specific requirements or configurations.
    /// 
    /// Example:
    /// In a scenario where specialized backup options are required, such as setting
    /// a specific timeout or defining custom behavior, users can use this field
    /// to specify additional command arguments.
    /// 
    /// Note:
    /// It's essential to ensure that the provided arguments are valid and supported
    /// by the 'barman-cloud-backup' command, to avoid potential errors or unintended
    /// behavior during execution.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "additionalCommandArgs")]
    pub additional_command_args: Option<Vec<String>>,
    /// Compress a backup file (a tar file per tablespace) while streaming it
    /// to the object store. Available options are empty string (no
    /// compression, default), `gzip`, `bzip2`, and `snappy`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub compression: Option<ClusterExternalClustersBarmanObjectStoreDataCompression>,
    /// Whenever to force the encryption of files (if the bucket is
    /// not already configured for that).
    /// Allowed options are empty string (use the bucket policy, default),
    /// `AES256` and `aws:kms`
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encryption: Option<ClusterExternalClustersBarmanObjectStoreDataEncryption>,
    /// Control whether the I/O workload for the backup initial checkpoint will
    /// be limited, according to the `checkpoint_completion_target` setting on
    /// the PostgreSQL server. If set to true, an immediate checkpoint will be
    /// used, meaning PostgreSQL will complete the checkpoint as soon as
    /// possible. `false` by default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "immediateCheckpoint")]
    pub immediate_checkpoint: Option<bool>,
    /// The number of parallel jobs to be used to upload the backup, defaults
    /// to 2
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub jobs: Option<i32>,
}

/// The configuration to be used to backup the data files
/// When not defined, base backups files will be stored uncompressed and may
/// be unencrypted in the object store, according to the bucket default
/// policy.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterExternalClustersBarmanObjectStoreDataCompression {
    #[serde(rename = "bzip2")]
    Bzip2,
    #[serde(rename = "gzip")]
    Gzip,
    #[serde(rename = "snappy")]
    Snappy,
}

/// The configuration to be used to backup the data files
/// When not defined, base backups files will be stored uncompressed and may
/// be unencrypted in the object store, according to the bucket default
/// policy.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterExternalClustersBarmanObjectStoreDataEncryption {
    #[serde(rename = "AES256")]
    Aes256,
    #[serde(rename = "aws:kms")]
    AwsKms,
}

/// EndpointCA store the CA bundle of the barman endpoint.
/// Useful when using self-signed certificates to avoid
/// errors with certificate issuer and barman-cloud-wal-archive
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersBarmanObjectStoreEndpointCa {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The credentials to use to upload data to Google Cloud Storage
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersBarmanObjectStoreGoogleCredentials {
    /// The secret containing the Google Cloud Storage JSON file with the credentials
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "applicationCredentials")]
    pub application_credentials: Option<ClusterExternalClustersBarmanObjectStoreGoogleCredentialsApplicationCredentials>,
    /// If set to true, will presume that it's running inside a GKE environment,
    /// default to false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "gkeEnvironment")]
    pub gke_environment: Option<bool>,
}

/// The secret containing the Google Cloud Storage JSON file with the credentials
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersBarmanObjectStoreGoogleCredentialsApplicationCredentials {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The credentials to use to upload data to S3
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersBarmanObjectStoreS3Credentials {
    /// The reference to the access key id
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "accessKeyId")]
    pub access_key_id: Option<ClusterExternalClustersBarmanObjectStoreS3CredentialsAccessKeyId>,
    /// Use the role based authentication without providing explicitly the keys.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inheritFromIAMRole")]
    pub inherit_from_iam_role: Option<bool>,
    /// The reference to the secret containing the region name
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub region: Option<ClusterExternalClustersBarmanObjectStoreS3CredentialsRegion>,
    /// The reference to the secret access key
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "secretAccessKey")]
    pub secret_access_key: Option<ClusterExternalClustersBarmanObjectStoreS3CredentialsSecretAccessKey>,
    /// The references to the session key
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sessionToken")]
    pub session_token: Option<ClusterExternalClustersBarmanObjectStoreS3CredentialsSessionToken>,
}

/// The reference to the access key id
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersBarmanObjectStoreS3CredentialsAccessKeyId {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The reference to the secret containing the region name
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersBarmanObjectStoreS3CredentialsRegion {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The reference to the secret access key
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersBarmanObjectStoreS3CredentialsSecretAccessKey {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The references to the session key
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersBarmanObjectStoreS3CredentialsSessionToken {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// The configuration for the backup of the WAL stream.
/// When not defined, WAL files will be stored uncompressed and may be
/// unencrypted in the object store, according to the bucket default policy.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersBarmanObjectStoreWal {
    /// Additional arguments that can be appended to the 'barman-cloud-wal-archive'
    /// command-line invocation. These arguments provide flexibility to customize
    /// the WAL archive process further, according to specific requirements or configurations.
    /// 
    /// Example:
    /// In a scenario where specialized backup options are required, such as setting
    /// a specific timeout or defining custom behavior, users can use this field
    /// to specify additional command arguments.
    /// 
    /// Note:
    /// It's essential to ensure that the provided arguments are valid and supported
    /// by the 'barman-cloud-wal-archive' command, to avoid potential errors or unintended
    /// behavior during execution.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "archiveAdditionalCommandArgs")]
    pub archive_additional_command_args: Option<Vec<String>>,
    /// Compress a WAL file before sending it to the object store. Available
    /// options are empty string (no compression, default), `gzip`, `bzip2`,
    /// `lz4`, `snappy`, `xz`, and `zstd`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub compression: Option<ClusterExternalClustersBarmanObjectStoreWalCompression>,
    /// Whenever to force the encryption of files (if the bucket is
    /// not already configured for that).
    /// Allowed options are empty string (use the bucket policy, default),
    /// `AES256` and `aws:kms`
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encryption: Option<ClusterExternalClustersBarmanObjectStoreWalEncryption>,
    /// Number of WAL files to be either archived in parallel (when the
    /// PostgreSQL instance is archiving to a backup object store) or
    /// restored in parallel (when a PostgreSQL standby is fetching WAL
    /// files from a recovery object store). If not specified, WAL files
    /// will be processed one at a time. It accepts a positive integer as a
    /// value - with 1 being the minimum accepted value.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxParallel")]
    pub max_parallel: Option<i64>,
    /// Additional arguments that can be appended to the 'barman-cloud-wal-restore'
    /// command-line invocation. These arguments provide flexibility to customize
    /// the WAL restore process further, according to specific requirements or configurations.
    /// 
    /// Example:
    /// In a scenario where specialized backup options are required, such as setting
    /// a specific timeout or defining custom behavior, users can use this field
    /// to specify additional command arguments.
    /// 
    /// Note:
    /// It's essential to ensure that the provided arguments are valid and supported
    /// by the 'barman-cloud-wal-restore' command, to avoid potential errors or unintended
    /// behavior during execution.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "restoreAdditionalCommandArgs")]
    pub restore_additional_command_args: Option<Vec<String>>,
}

/// The configuration for the backup of the WAL stream.
/// When not defined, WAL files will be stored uncompressed and may be
/// unencrypted in the object store, according to the bucket default policy.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterExternalClustersBarmanObjectStoreWalCompression {
    #[serde(rename = "bzip2")]
    Bzip2,
    #[serde(rename = "gzip")]
    Gzip,
    #[serde(rename = "lz4")]
    Lz4,
    #[serde(rename = "snappy")]
    Snappy,
    #[serde(rename = "xz")]
    Xz,
    #[serde(rename = "zstd")]
    Zstd,
}

/// The configuration for the backup of the WAL stream.
/// When not defined, WAL files will be stored uncompressed and may be
/// unencrypted in the object store, according to the bucket default policy.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterExternalClustersBarmanObjectStoreWalEncryption {
    #[serde(rename = "AES256")]
    Aes256,
    #[serde(rename = "aws:kms")]
    AwsKms,
}

/// The reference to the password to be used to connect to the server.
/// If a password is provided, CloudNativePG creates a PostgreSQL
/// passfile at `/controller/external/NAME/pass` (where "NAME" is the
/// cluster's name). This passfile is automatically referenced in the
/// connection string when establishing a connection to the remote
/// PostgreSQL server from the current PostgreSQL `Cluster`. This ensures
/// secure and efficient password management for external clusters.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersPassword {
    /// The key of the secret to select from.  Must be a valid secret key.
    pub key: String,
    /// Name of the referent.
    /// This field is effectively required, but due to backwards compatibility is
    /// allowed to be empty. Instances of this type with an empty value here are
    /// almost certainly wrong.
    /// More info: <https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Specify whether the Secret or its key must be defined
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub optional: Option<bool>,
}

/// The configuration of the plugin that is taking care
/// of WAL archiving and backups for this external cluster
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersPlugin {
    /// Enabled is true if this plugin will be used
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enabled: Option<bool>,
    /// Only one plugin can be declared as WALArchiver.
    /// Cannot be active if ".spec.backup.barmanObjectStore" configuration is present.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "isWALArchiver")]
    pub is_wal_archiver: Option<bool>,
    /// Name is the plugin name
    pub name: String,
    /// Parameters is the configuration of the plugin
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub parameters: Option<BTreeMap<String, String>>,
}

/// The reference to an SSL certificate to be used to connect to this
/// instance
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersSslCert {
    /// The key of the secret to select from.  Must be a valid secret key.
    pub key: String,
    /// Name of the referent.
    /// This field is effectively required, but due to backwards compatibility is
    /// allowed to be empty. Instances of this type with an empty value here are
    /// almost certainly wrong.
    /// More info: <https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Specify whether the Secret or its key must be defined
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub optional: Option<bool>,
}

/// The reference to an SSL private key to be used to connect to this
/// instance
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersSslKey {
    /// The key of the secret to select from.  Must be a valid secret key.
    pub key: String,
    /// Name of the referent.
    /// This field is effectively required, but due to backwards compatibility is
    /// allowed to be empty. Instances of this type with an empty value here are
    /// almost certainly wrong.
    /// More info: <https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Specify whether the Secret or its key must be defined
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub optional: Option<bool>,
}

/// The reference to an SSL CA public key to be used to connect to this
/// instance
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterExternalClustersSslRootCert {
    /// The key of the secret to select from.  Must be a valid secret key.
    pub key: String,
    /// Name of the referent.
    /// This field is effectively required, but due to backwards compatibility is
    /// allowed to be empty. Instances of this type with an empty value here are
    /// almost certainly wrong.
    /// More info: <https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Specify whether the Secret or its key must be defined
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub optional: Option<bool>,
}

/// Defines the major PostgreSQL version we want to use within an ImageCatalog
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterImageCatalogRef {
    /// APIGroup is the group for the resource being referenced.
    /// If APIGroup is not specified, the specified Kind must be in the core API group.
    /// For any other third-party types, APIGroup is required.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiGroup")]
    pub api_group: Option<String>,
    /// Kind is the type of resource being referenced
    pub kind: String,
    /// The major version of PostgreSQL we want to use from the ImageCatalog
    pub major: i64,
    /// Name is the name of resource being referenced
    pub name: String,
}

/// LocalObjectReference contains enough information to let you locate a
/// local object with a known type inside the same namespace
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterImagePullSecrets {
    /// Name of the referent.
    pub name: String,
}

/// Metadata that will be inherited by all objects related to the Cluster
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterInheritedMetadata {
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub annotations: Option<BTreeMap<String, String>>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub labels: Option<BTreeMap<String, String>>,
}

/// Specification of the desired behavior of the cluster.
/// More info: <https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterLogLevel {
    #[serde(rename = "error")]
    Error,
    #[serde(rename = "warning")]
    Warning,
    #[serde(rename = "info")]
    Info,
    #[serde(rename = "debug")]
    Debug,
    #[serde(rename = "trace")]
    Trace,
}

/// The configuration that is used by the portions of PostgreSQL that are managed by the instance manager
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterManaged {
    /// Database roles managed by the `Cluster`
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub roles: Option<Vec<ClusterManagedRoles>>,
    /// Services roles managed by the `Cluster`
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub services: Option<ClusterManagedServices>,
}

/// RoleConfiguration is the representation, in Kubernetes, of a PostgreSQL role
/// with the additional field Ensure specifying whether to ensure the presence or
/// absence of the role in the database
/// 
/// The defaults of the CREATE ROLE command are applied
/// Reference: <https://www.postgresql.org/docs/current/sql-createrole.html>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterManagedRoles {
    /// Whether a role bypasses every row-level security (RLS) policy.
    /// Default is `false`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub bypassrls: Option<bool>,
    /// Description of the role
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub comment: Option<String>,
    /// If the role can log in, this specifies how many concurrent
    /// connections the role can make. `-1` (the default) means no limit.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "connectionLimit")]
    pub connection_limit: Option<i64>,
    /// When set to `true`, the role being defined will be allowed to create
    /// new databases. Specifying `false` (default) will deny a role the
    /// ability to create databases.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub createdb: Option<bool>,
    /// Whether the role will be permitted to create, alter, drop, comment
    /// on, change the security label for, and grant or revoke membership in
    /// other roles. Default is `false`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub createrole: Option<bool>,
    /// DisablePassword indicates that a role's password should be set to NULL in Postgres
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "disablePassword")]
    pub disable_password: Option<bool>,
    /// Ensure the role is `present` or `absent` - defaults to "present"
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub ensure: Option<ClusterManagedRolesEnsure>,
    /// List of one or more existing roles to which this role will be
    /// immediately added as a new member. Default empty.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inRoles")]
    pub in_roles: Option<Vec<String>>,
    /// Whether a role "inherits" the privileges of roles it is a member of.
    /// Defaults is `true`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub inherit: Option<bool>,
    /// Whether the role is allowed to log in. A role having the `login`
    /// attribute can be thought of as a user. Roles without this attribute
    /// are useful for managing database privileges, but are not users in
    /// the usual sense of the word. Default is `false`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub login: Option<bool>,
    /// Name of the role
    pub name: String,
    /// Secret containing the password of the role (if present)
    /// If null, the password will be ignored unless DisablePassword is set
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "passwordSecret")]
    pub password_secret: Option<ClusterManagedRolesPasswordSecret>,
    /// Whether a role is a replication role. A role must have this
    /// attribute (or be a superuser) in order to be able to connect to the
    /// server in replication mode (physical or logical replication) and in
    /// order to be able to create or drop replication slots. A role having
    /// the `replication` attribute is a very highly privileged role, and
    /// should only be used on roles actually used for replication. Default
    /// is `false`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub replication: Option<bool>,
    /// Whether the role is a `superuser` who can override all access
    /// restrictions within the database - superuser status is dangerous and
    /// should be used only when really needed. You must yourself be a
    /// superuser to create a new superuser. Defaults is `false`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub superuser: Option<bool>,
    /// Date and time after which the role's password is no longer valid.
    /// When omitted, the password will never expire (default).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "validUntil")]
    pub valid_until: Option<String>,
}

/// RoleConfiguration is the representation, in Kubernetes, of a PostgreSQL role
/// with the additional field Ensure specifying whether to ensure the presence or
/// absence of the role in the database
/// 
/// The defaults of the CREATE ROLE command are applied
/// Reference: <https://www.postgresql.org/docs/current/sql-createrole.html>
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterManagedRolesEnsure {
    #[serde(rename = "present")]
    Present,
    #[serde(rename = "absent")]
    Absent,
}

/// Secret containing the password of the role (if present)
/// If null, the password will be ignored unless DisablePassword is set
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterManagedRolesPasswordSecret {
    /// Name of the referent.
    pub name: String,
}

/// Services roles managed by the `Cluster`
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterManagedServices {
    /// Additional is a list of additional managed services specified by the user.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub additional: Option<Vec<ClusterManagedServicesAdditional>>,
    /// DisabledDefaultServices is a list of service types that are disabled by default.
    /// Valid values are "r", and "ro", representing read, and read-only services.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "disabledDefaultServices")]
    pub disabled_default_services: Option<Vec<String>>,
}

/// ManagedService represents a specific service managed by the cluster.
/// It includes the type of service and its associated template specification.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct ClusterManagedServicesAdditional {
    /// SelectorType specifies the type of selectors that the service will have.
    /// Valid values are "rw", "r", and "ro", representing read-write, read, and read-only services.
    #[serde(rename = "selectorType")]
    pub selector_type: ClusterManagedServicesAdditionalSelectorType,
    /// ServiceTemplate is the template specification for the service.
    #[serde(rename = "serviceTemplate")]
    pub service_template: ClusterManagedServicesAdditionalServiceTemplate,
    /// UpdateStrategy describes how the service differences should be reconciled
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "updateStrategy")]
    pub update_strategy: Option<ClusterManagedServicesAdditionalUpdateStrategy>,
}

/// ManagedService represents a specific service managed by the cluster.
/// It includes the type of service and its associated template specification.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterManagedServicesAdditionalSelectorType {
    #[serde(rename = "rw")]
    Rw,
    #[serde(rename = "r")]
    R,
    #[serde(rename = "ro")]
    Ro,
}

/// ServiceTemplate is the template specification for the service.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterManagedServicesAdditionalServiceTemplate {
    /// Standard object's metadata.
    /// More info: <https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metadata: Option<ClusterManagedServicesAdditionalServiceTemplateMetadata>,
    /// Specification of the desired behavior of the service.
    /// More info: <https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub spec: Option<ClusterManagedServicesAdditionalServiceTemplateSpec>,
}

/// Standard object's metadata.
/// More info: <https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterManagedServicesAdditionalServiceTemplateMetadata {
    /// Annotations is an unstructured key value map stored with a resource that may be
    /// set by external tools to store and retrieve arbitrary metadata. They are not
    /// queryable and should be preserved when modifying objects.
    /// More info: <http://kubernetes.io/docs/user-guide/annotations>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub annotations: Option<BTreeMap<String, String>>,
    /// Map of string keys and values that can be used to organize and categorize
    /// (scope and select) objects. May match selectors of replication controllers
    /// and services.
    /// More info: <http://kubernetes.io/docs/user-guide/labels>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub labels: Option<BTreeMap<String, String>>,
    /// The name of the resource. Only supported for certain types
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// Specification of the desired behavior of the service.
/// More info: <https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterManagedServicesAdditionalServiceTemplateSpec {
    /// allocateLoadBalancerNodePorts defines if NodePorts will be automatically
    /// allocated for services with type LoadBalancer.  Default is "true". It
    /// may be set to "false" if the cluster load-balancer does not rely on
    /// NodePorts.  If the caller requests specific NodePorts (by specifying a
    /// value), those requests will be respected, regardless of this field.
    /// This field may only be set for services with type LoadBalancer and will
    /// be cleared if the type is changed to any other type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allocateLoadBalancerNodePorts")]
    pub allocate_load_balancer_node_ports: Option<bool>,
    /// clusterIP is the IP address of the service and is usually assigned
    /// randomly. If an address is specified manually, is in-range (as per
    /// system configuration), and is not in use, it will be allocated to the
    /// service; otherwise creation of the service will fail. This field may not
    /// be changed through updates unless the type field is also being changed
    /// to ExternalName (which requires this field to be blank) or the type
    /// field is being changed from ExternalName (in which case this field may
    /// optionally be specified, as describe above).  Valid values are "None",
    /// empty string (""), or a valid IP address. Setting this to "None" makes a
    /// "headless service" (no virtual IP), which is useful when direct endpoint
    /// connections are preferred and proxying is not required.  Only applies to
    /// types ClusterIP, NodePort, and LoadBalancer. If this field is specified
    /// when creating a Service of type ExternalName, creation will fail. This
    /// field will be wiped when updating a Service to type ExternalName.
    /// More info: <https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clusterIP")]
    pub cluster_ip: Option<String>,
    /// ClusterIPs is a list of IP addresses assigned to this service, and are
    /// usually assigned randomly.  If an address is specified manually, is
    /// in-range (as per system configuration), and is not in use, it will be
    /// allocated to the service; otherwise creation of the service will fail.
    /// This field may not be changed through updates unless the type field is
    /// also being changed to ExternalName (which requires this field to be
    /// empty) or the type field is being changed from ExternalName (in which
    /// case this field may optionally be specified, as describe above).  Valid
    /// values are "None", empty string (""), or a valid IP address.  Setting
    /// this to "None" makes a "headless service" (no virtual IP), which is
    /// useful when direct endpoint connections are preferred and proxying is
    /// not required.  Only applies to types ClusterIP, NodePort, and
    /// LoadBalancer. If this field is specified when creating a Service of type
    /// ExternalName, creation will fail. This field will be wiped when updating
    /// a Service to type ExternalName.  If this field is not specified, it will
    /// be initialized from the clusterIP field.  If this field is specified,
    /// clients must ensure that clusterIPs[0] and clusterIP have the same
    /// value.
    /// 
    /// This field may hold a maximum of two entries (dual-stack IPs, in either order).
    /// These IPs must correspond to the values of the ipFamilies field. Both
    /// clusterIPs and ipFamilies are governed by the ipFamilyPolicy field.
    /// More info: <https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clusterIPs")]
    pub cluster_i_ps: Option<Vec<String>>,
    /// externalIPs is a list of IP addresses for which nodes in the cluster
    /// will also accept traffic for this service.  These IPs are not managed by
    /// Kubernetes.  The user is responsible for ensuring that traffic arrives
    /// at a node with this IP.  A common example is external load-balancers
    /// that are not part of the Kubernetes system.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "externalIPs")]
    pub external_i_ps: Option<Vec<String>>,
    /// externalName is the external reference that discovery mechanisms will
    /// return as an alias for this service (e.g. a DNS CNAME record). No
    /// proxying will be involved.  Must be a lowercase RFC-1123 hostname
    /// (<https://tools.ietf.org/html/rfc1123)> and requires `type` to be "ExternalName".
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "externalName")]
    pub external_name: Option<String>,
    /// externalTrafficPolicy describes how nodes distribute service traffic they
    /// receive on one of the Service's "externally-facing" addresses (NodePorts,
    /// ExternalIPs, and LoadBalancer IPs). If set to "Local", the proxy will configure
    /// the service in a way that assumes that external load balancers will take care
    /// of balancing the service traffic between nodes, and so each node will deliver
    /// traffic only to the node-local endpoints of the service, without masquerading
    /// the client source IP. (Traffic mistakenly sent to a node with no endpoints will
    /// be dropped.) The default value, "Cluster", uses the standard behavior of
    /// routing to all endpoints evenly (possibly modified by topology and other
    /// features). Note that traffic sent to an External IP or LoadBalancer IP from
    /// within the cluster will always get "Cluster" semantics, but clients sending to
    /// a NodePort from within the cluster may need to take traffic policy into account
    /// when picking a node.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "externalTrafficPolicy")]
    pub external_traffic_policy: Option<String>,
    /// healthCheckNodePort specifies the healthcheck nodePort for the service.
    /// This only applies when type is set to LoadBalancer and
    /// externalTrafficPolicy is set to Local. If a value is specified, is
    /// in-range, and is not in use, it will be used.  If not specified, a value
    /// will be automatically allocated.  External systems (e.g. load-balancers)
    /// can use this port to determine if a given node holds endpoints for this
    /// service or not.  If this field is specified when creating a Service
    /// which does not need it, creation will fail. This field will be wiped
    /// when updating a Service to no longer need it (e.g. changing type).
    /// This field cannot be updated once set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "healthCheckNodePort")]
    pub health_check_node_port: Option<i32>,
    /// InternalTrafficPolicy describes how nodes distribute service traffic they
    /// receive on the ClusterIP. If set to "Local", the proxy will assume that pods
    /// only want to talk to endpoints of the service on the same node as the pod,
    /// dropping the traffic if there are no local endpoints. The default value,
    /// "Cluster", uses the standard behavior of routing to all endpoints evenly
    /// (possibly modified by topology and other features).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "internalTrafficPolicy")]
    pub internal_traffic_policy: Option<String>,
    /// IPFamilies is a list of IP families (e.g. IPv4, IPv6) assigned to this
    /// service. This field is usually assigned automatically based on cluster
    /// configuration and the ipFamilyPolicy field. If this field is specified
    /// manually, the requested family is available in the cluster,
    /// and ipFamilyPolicy allows it, it will be used; otherwise creation of
    /// the service will fail. This field is conditionally mutable: it allows
    /// for adding or removing a secondary IP family, but it does not allow
    /// changing the primary IP family of the Service. Valid values are "IPv4"
    /// and "IPv6".  This field only applies to Services of types ClusterIP,
    /// NodePort, and LoadBalancer, and does apply to "headless" services.
    /// This field will be wiped when updating a Service to type ExternalName.
    /// 
    /// This field may hold a maximum of two entries (dual-stack families, in
    /// either order).  These families must correspond to the values of the
    /// clusterIPs field, if specified. Both clusterIPs and ipFamilies are
    /// governed by the ipFamilyPolicy field.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ipFamilies")]
    pub ip_families: Option<Vec<String>>,
    /// IPFamilyPolicy represents the dual-stack-ness requested or required by
    /// this Service. If there is no value provided, then this field will be set
    /// to SingleStack. Services can be "SingleStack" (a single IP family),
    /// "PreferDualStack" (two IP families on dual-stack configured clusters or
    /// a single IP family on single-stack clusters), or "RequireDualStack"
    /// (two IP families on dual-stack configured clusters, otherwise fail). The
    /// ipFamilies and clusterIPs fields depend on the value of this field. This
    /// field will be wiped when updating a service to type ExternalName.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ipFamilyPolicy")]
    pub ip_family_policy: Option<String>,
    /// loadBalancerClass is the class of the load balancer implementation this Service belongs to.
    /// If specified, the value of this field must be a label-style identifier, with an optional prefix,
    /// e.g. "internal-vip" or "example.com/internal-vip". Unprefixed names are reserved for end-users.
    /// This field can only be set when the Service type is 'LoadBalancer'. If not set, the default load
    /// balancer implementation is used, today this is typically done through the cloud provider integration,
    /// but should apply for any default implementation. If set, it is assumed that a load balancer
    /// implementation is watching for Services with a matching class. Any default load balancer
    /// implementation (e.g. cloud providers) should ignore Services that set this field.
    /// This field can only be set when creating or updating a Service to type 'LoadBalancer'.
    /// Once set, it can not be changed. This field will be wiped when a service is updated to a non 'LoadBalancer' type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "loadBalancerClass")]
    pub load_balancer_class: Option<String>,
    /// Only applies to Service Type: LoadBalancer.
    /// This feature depends on whether the underlying cloud-provider supports specifying
    /// the loadBalancerIP when a load balancer is created.
    /// This field will be ignored if the cloud-provider does not support the feature.
    /// Deprecated: This field was under-specified and its meaning varies across implementations.
    /// Using it is non-portable and it may not support dual-stack.
    /// Users are encouraged to use implementation-specific annotations when available.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "loadBalancerIP")]
    pub load_balancer_ip: Option<String>,
    /// If specified and supported by the platform, this will restrict traffic through the cloud-provider
    /// load-balancer will be restricted to the specified client IPs. This field will be ignored if the
    /// cloud-provider does not support the feature."
    /// More info: <https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "loadBalancerSourceRanges")]
    pub load_balancer_source_ranges: Option<Vec<String>>,
    /// The list of ports that are exposed by this service.
    /// More info: <https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub ports: Option<Vec<ClusterManagedServicesAdditionalServiceTemplateSpecPorts>>,
    /// publishNotReadyAddresses indicates that any agent which deals with endpoints for this
    /// Service should disregard any indications of ready/not-ready.
    /// The primary use case for setting this field is for a StatefulSet's Headless Service to
    /// propagate SRV DNS records for its Pods for the purpose of peer discovery.
    /// The Kubernetes controllers that generate Endpoints and EndpointSlice resources for
    /// Services interpret this to mean that all endpoints are considered "ready" even if the
    /// Pods themselves are not. Agents which consume only Kubernetes generated endpoints
    /// through the Endpoints or EndpointSlice resources can safely assume this behavior.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "publishNotReadyAddresses")]
    pub publish_not_ready_addresses: Option<bool>,
    /// Route service traffic to pods with label keys and values matching this
    /// selector. If empty or not present, the service is assumed to have an
    /// external process managing its endpoints, which Kubernetes will not
    /// modify. Only applies to types ClusterIP, NodePort, and LoadBalancer.
    /// Ignored if type is ExternalName.
    /// More info: <https://kubernetes.io/docs/concepts/services-networking/service/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selector: Option<BTreeMap<String, String>>,
    /// Supports "ClientIP" and "None". Used to maintain session affinity.
    /// Enable client IP based session affinity.
    /// Must be ClientIP or None.
    /// Defaults to None.
    /// More info: <https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sessionAffinity")]
    pub session_affinity: Option<String>,
    /// sessionAffinityConfig contains the configurations of session affinity.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sessionAffinityConfig")]
    pub session_affinity_config: Option<ClusterManagedServicesAdditionalServiceTemplateSpecSessionAffinityConfig>,
    /// TrafficDistribution offers a way to express preferences for how traffic
    /// is distributed to Service endpoints. Implementations can use this field
    /// as a hint, but are not required to guarantee strict adherence. If the
    /// field is not set, the implementation will apply its default routing
    /// strategy. If set to "PreferClose", implementations should prioritize
    /// endpoints that are in the same zone.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "trafficDistribution")]
    pub traffic_distribution: Option<String>,
    /// type determines how the Service is exposed. Defaults to ClusterIP. Valid
    /// options are ExternalName, ClusterIP, NodePort, and LoadBalancer.
    /// "ClusterIP" allocates a cluster-internal IP address for load-balancing
    /// to endpoints. Endpoints are determined by the selector or if that is not
    /// specified, by manual construction of an Endpoints object or
    /// EndpointSlice objects. If clusterIP is "None", no virtual IP is
    /// allocated and the endpoints are published as a set of endpoints rather
    /// than a virtual IP.
    /// "NodePort" builds on ClusterIP and allocates a port on every node which
    /// routes to the same endpoints as the clusterIP.
    /// "LoadBalancer" builds on NodePort and creates an external load-balancer
    /// (if supported in the current cloud) which routes to the same endpoints
    /// as the clusterIP.
    /// "ExternalName" aliases this service to the specified externalName.
    /// Several other fields do not apply to ExternalName services.
    /// More info: <https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<String>,
}

/// ServicePort contains information on service's port.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterManagedServicesAdditionalServiceTemplateSpecPorts {
    /// The application protocol for this port.
    /// This is used as a hint for implementations to offer richer behavior for protocols that they understand.
    /// This field follows standard Kubernetes label syntax.
    /// Valid values are either:
    /// 
    /// * Un-prefixed protocol names - reserved for IANA standard service names (as per
    /// RFC-6335 and <https://www.iana.org/assignments/service-names).>
    /// 
    /// * Kubernetes-defined prefixed names:
    ///   * 'kubernetes.io/h2c' - HTTP/2 prior knowledge over cleartext as described in <https://www.rfc-editor.org/rfc/rfc9113.html#name-starting-http-2-with-prior->
    ///   * 'kubernetes.io/ws'  - WebSocket over cleartext as described in <https://www.rfc-editor.org/rfc/rfc6455>
    ///   * 'kubernetes.io/wss' - WebSocket over TLS as described in <https://www.rfc-editor.org/rfc/rfc6455>
    /// 
    /// * Other protocols should use implementation-defined prefixed names such as
    /// mycompany.com/my-custom-protocol.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "appProtocol")]
    pub app_protocol: Option<String>,
    /// The name of this port within the service. This must be a DNS_LABEL.
    /// All ports within a ServiceSpec must have unique names. When considering
    /// the endpoints for a Service, this must match the 'name' field in the
    /// EndpointPort.
    /// Optional if only one ServicePort is defined on this service.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// The port on each node on which this service is exposed when type is
    /// NodePort or LoadBalancer.  Usually assigned by the system. If a value is
    /// specified, in-range, and not in use it will be used, otherwise the
    /// operation will fail.  If not specified, a port will be allocated if this
    /// Service requires one.  If this field is specified when creating a
    /// Service which does not need it, creation will fail. This field will be
    /// wiped when updating a Service to no longer need it (e.g. changing type
    /// from NodePort to ClusterIP).
    /// More info: <https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodePort")]
    pub node_port: Option<i32>,
    /// The port that will be exposed by this service.
    pub port: i32,
    /// The IP protocol for this port. Supports "TCP", "UDP", and "SCTP".
    /// Default is TCP.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub protocol: Option<String>,
    /// Number or name of the port to access on the pods targeted by the service.
    /// Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
    /// If this is a string, it will be looked up as a named port in the
    /// target Pod's container ports. If this is not specified, the value
    /// of the 'port' field is used (an identity map).
    /// This field is ignored for services with clusterIP=None, and should be
    /// omitted or set equal to the 'port' field.
    /// More info: <https://kubernetes.io/docs/concepts/services-networking/service/#defining-a-service>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "targetPort")]
    pub target_port: Option<IntOrString>,
}

/// sessionAffinityConfig contains the configurations of session affinity.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterManagedServicesAdditionalServiceTemplateSpecSessionAffinityConfig {
    /// clientIP contains the configurations of Client IP based session affinity.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clientIP")]
    pub client_ip: Option<ClusterManagedServicesAdditionalServiceTemplateSpecSessionAffinityConfigClientIp>,
}

/// clientIP contains the configurations of Client IP based session affinity.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterManagedServicesAdditionalServiceTemplateSpecSessionAffinityConfigClientIp {
    /// timeoutSeconds specifies the seconds of ClientIP type session sticky time.
    /// The value must be >0 && <=86400(for 1 day) if ServiceAffinity == "ClientIP".
    /// Default value is 10800(for 3 hours).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "timeoutSeconds")]
    pub timeout_seconds: Option<i32>,
}

/// ManagedService represents a specific service managed by the cluster.
/// It includes the type of service and its associated template specification.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterManagedServicesAdditionalUpdateStrategy {
    #[serde(rename = "patch")]
    Patch,
    #[serde(rename = "replace")]
    Replace,
}

/// The configuration of the monitoring infrastructure of this cluster
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterMonitoring {
    /// The list of config maps containing the custom queries
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "customQueriesConfigMap")]
    pub custom_queries_config_map: Option<Vec<ClusterMonitoringCustomQueriesConfigMap>>,
    /// The list of secrets containing the custom queries
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "customQueriesSecret")]
    pub custom_queries_secret: Option<Vec<ClusterMonitoringCustomQueriesSecret>>,
    /// Whether the default queries should be injected.
    /// Set it to `true` if you don't want to inject default queries into the cluster.
    /// Default: false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "disableDefaultQueries")]
    pub disable_default_queries: Option<bool>,
    /// Enable or disable the `PodMonitor`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enablePodMonitor")]
    pub enable_pod_monitor: Option<bool>,
    /// The list of metric relabelings for the `PodMonitor`. Applied to samples before ingestion.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podMonitorMetricRelabelings")]
    pub pod_monitor_metric_relabelings: Option<Vec<ClusterMonitoringPodMonitorMetricRelabelings>>,
    /// The list of relabelings for the `PodMonitor`. Applied to samples before scraping.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podMonitorRelabelings")]
    pub pod_monitor_relabelings: Option<Vec<ClusterMonitoringPodMonitorRelabelings>>,
    /// Configure TLS communication for the metrics endpoint.
    /// Changing tls.enabled option will force a rollout of all instances.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<ClusterMonitoringTls>,
}

/// ConfigMapKeySelector contains enough information to let you locate
/// the key of a ConfigMap
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterMonitoringCustomQueriesConfigMap {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// SecretKeySelector contains enough information to let you locate
/// the key of a Secret
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterMonitoringCustomQueriesSecret {
    /// The key to select
    pub key: String,
    /// Name of the referent.
    pub name: String,
}

/// RelabelConfig allows dynamic rewriting of the label set for targets, alerts,
/// scraped samples and remote write samples.
/// 
/// More info: <https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterMonitoringPodMonitorMetricRelabelings {
    /// Action to perform based on the regex matching.
    /// 
    /// `Uppercase` and `Lowercase` actions require Prometheus >= v2.36.0.
    /// `DropEqual` and `KeepEqual` actions require Prometheus >= v2.41.0.
    /// 
    /// Default: "Replace"
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub action: Option<ClusterMonitoringPodMonitorMetricRelabelingsAction>,
    /// Modulus to take of the hash of the source label values.
    /// 
    /// Only applicable when the action is `HashMod`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub modulus: Option<i64>,
    /// Regular expression against which the extracted value is matched.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub regex: Option<String>,
    /// Replacement value against which a Replace action is performed if the
    /// regular expression matches.
    /// 
    /// Regex capture groups are available.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub replacement: Option<String>,
    /// Separator is the string between concatenated SourceLabels.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub separator: Option<String>,
    /// The source labels select values from existing labels. Their content is
    /// concatenated using the configured Separator and matched against the
    /// configured regular expression.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceLabels")]
    pub source_labels: Option<Vec<String>>,
    /// Label to which the resulting string is written in a replacement.
    /// 
    /// It is mandatory for `Replace`, `HashMod`, `Lowercase`, `Uppercase`,
    /// `KeepEqual` and `DropEqual` actions.
    /// 
    /// Regex capture groups are available.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "targetLabel")]
    pub target_label: Option<String>,
}

/// RelabelConfig allows dynamic rewriting of the label set for targets, alerts,
/// scraped samples and remote write samples.
/// 
/// More info: <https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config>
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterMonitoringPodMonitorMetricRelabelingsAction {
    #[serde(rename = "replace")]
    Replace,
    #[serde(rename = "Replace")]
    ReplaceX,
    #[serde(rename = "keep")]
    Keep,
    #[serde(rename = "Keep")]
    KeepX,
    #[serde(rename = "drop")]
    Drop,
    #[serde(rename = "Drop")]
    DropX,
    #[serde(rename = "hashmod")]
    Hashmod,
    HashMod,
    #[serde(rename = "labelmap")]
    Labelmap,
    LabelMap,
    #[serde(rename = "labeldrop")]
    Labeldrop,
    LabelDrop,
    #[serde(rename = "labelkeep")]
    Labelkeep,
    LabelKeep,
    #[serde(rename = "lowercase")]
    Lowercase,
    #[serde(rename = "Lowercase")]
    LowercaseX,
    #[serde(rename = "uppercase")]
    Uppercase,
    #[serde(rename = "Uppercase")]
    UppercaseX,
    #[serde(rename = "keepequal")]
    Keepequal,
    KeepEqual,
    #[serde(rename = "dropequal")]
    Dropequal,
    DropEqual,
}

/// RelabelConfig allows dynamic rewriting of the label set for targets, alerts,
/// scraped samples and remote write samples.
/// 
/// More info: <https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterMonitoringPodMonitorRelabelings {
    /// Action to perform based on the regex matching.
    /// 
    /// `Uppercase` and `Lowercase` actions require Prometheus >= v2.36.0.
    /// `DropEqual` and `KeepEqual` actions require Prometheus >= v2.41.0.
    /// 
    /// Default: "Replace"
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub action: Option<ClusterMonitoringPodMonitorRelabelingsAction>,
    /// Modulus to take of the hash of the source label values.
    /// 
    /// Only applicable when the action is `HashMod`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub modulus: Option<i64>,
    /// Regular expression against which the extracted value is matched.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub regex: Option<String>,
    /// Replacement value against which a Replace action is performed if the
    /// regular expression matches.
    /// 
    /// Regex capture groups are available.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub replacement: Option<String>,
    /// Separator is the string between concatenated SourceLabels.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub separator: Option<String>,
    /// The source labels select values from existing labels. Their content is
    /// concatenated using the configured Separator and matched against the
    /// configured regular expression.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceLabels")]
    pub source_labels: Option<Vec<String>>,
    /// Label to which the resulting string is written in a replacement.
    /// 
    /// It is mandatory for `Replace`, `HashMod`, `Lowercase`, `Uppercase`,
    /// `KeepEqual` and `DropEqual` actions.
    /// 
    /// Regex capture groups are available.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "targetLabel")]
    pub target_label: Option<String>,
}

/// RelabelConfig allows dynamic rewriting of the label set for targets, alerts,
/// scraped samples and remote write samples.
/// 
/// More info: <https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config>
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterMonitoringPodMonitorRelabelingsAction {
    #[serde(rename = "replace")]
    Replace,
    #[serde(rename = "Replace")]
    ReplaceX,
    #[serde(rename = "keep")]
    Keep,
    #[serde(rename = "Keep")]
    KeepX,
    #[serde(rename = "drop")]
    Drop,
    #[serde(rename = "Drop")]
    DropX,
    #[serde(rename = "hashmod")]
    Hashmod,
    HashMod,
    #[serde(rename = "labelmap")]
    Labelmap,
    LabelMap,
    #[serde(rename = "labeldrop")]
    Labeldrop,
    LabelDrop,
    #[serde(rename = "labelkeep")]
    Labelkeep,
    LabelKeep,
    #[serde(rename = "lowercase")]
    Lowercase,
    #[serde(rename = "Lowercase")]
    LowercaseX,
    #[serde(rename = "uppercase")]
    Uppercase,
    #[serde(rename = "Uppercase")]
    UppercaseX,
    #[serde(rename = "keepequal")]
    Keepequal,
    KeepEqual,
    #[serde(rename = "dropequal")]
    Dropequal,
    DropEqual,
}

/// Configure TLS communication for the metrics endpoint.
/// Changing tls.enabled option will force a rollout of all instances.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterMonitoringTls {
    /// Enable TLS for the monitoring endpoint.
    /// Changing this option will force a rollout of all instances.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enabled: Option<bool>,
}

/// Define a maintenance window for the Kubernetes nodes
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterNodeMaintenanceWindow {
    /// Is there a node maintenance activity in progress?
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inProgress")]
    pub in_progress: Option<bool>,
    /// Reuse the existing PVC (wait for the node to come
    /// up again) or not (recreate it elsewhere - when `instances` >1)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "reusePVC")]
    pub reuse_pvc: Option<bool>,
}

/// PluginConfiguration specifies a plugin that need to be loaded for this
/// cluster to be reconciled
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPlugins {
    /// Enabled is true if this plugin will be used
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enabled: Option<bool>,
    /// Only one plugin can be declared as WALArchiver.
    /// Cannot be active if ".spec.backup.barmanObjectStore" configuration is present.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "isWALArchiver")]
    pub is_wal_archiver: Option<bool>,
    /// Name is the plugin name
    pub name: String,
    /// Parameters is the configuration of the plugin
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub parameters: Option<BTreeMap<String, String>>,
}

/// Configuration of the PostgreSQL server
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPostgresql {
    /// If this parameter is true, the user will be able to invoke `ALTER SYSTEM`
    /// on this CloudNativePG Cluster.
    /// This should only be used for debugging and troubleshooting.
    /// Defaults to false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableAlterSystem")]
    pub enable_alter_system: Option<bool>,
    /// The configuration of the extensions to be added
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub extensions: Option<Vec<ClusterPostgresqlExtensions>>,
    /// Options to specify LDAP configuration
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub ldap: Option<ClusterPostgresqlLdap>,
    /// PostgreSQL configuration options (postgresql.conf)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub parameters: Option<BTreeMap<String, String>>,
    /// PostgreSQL Host Based Authentication rules (lines to be appended
    /// to the pg_hba.conf file)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub pg_hba: Option<Vec<String>>,
    /// PostgreSQL User Name Maps rules (lines to be appended
    /// to the pg_ident.conf file)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub pg_ident: Option<Vec<String>>,
    /// Specifies the maximum number of seconds to wait when promoting an instance to primary.
    /// Default value is 40000000, greater than one year in seconds,
    /// big enough to simulate an infinite timeout
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "promotionTimeout")]
    pub promotion_timeout: Option<i32>,
    /// Lists of shared preload libraries to add to the default ones
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub shared_preload_libraries: Option<Vec<String>>,
    /// Requirements to be met by sync replicas. This will affect how the "synchronous_standby_names" parameter will be
    /// set up.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "syncReplicaElectionConstraint")]
    pub sync_replica_election_constraint: Option<ClusterPostgresqlSyncReplicaElectionConstraint>,
    /// Configuration of the PostgreSQL synchronous replication feature
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub synchronous: Option<ClusterPostgresqlSynchronous>,
}

/// ExtensionConfiguration is the configuration used to add
/// PostgreSQL extensions to the Cluster.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPostgresqlExtensions {
    /// The list of directories inside the image which should be added to dynamic_library_path.
    /// If not defined, defaults to "/lib".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub dynamic_library_path: Option<Vec<String>>,
    /// The list of directories inside the image which should be added to extension_control_path.
    /// If not defined, defaults to "/share".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub extension_control_path: Option<Vec<String>>,
    /// The image containing the extension, required
    pub image: ClusterPostgresqlExtensionsImage,
    /// The list of directories inside the image which should be added to ld_library_path.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub ld_library_path: Option<Vec<String>>,
    /// The name of the extension, required
    pub name: String,
}

/// The image containing the extension, required
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPostgresqlExtensionsImage {
    /// Policy for pulling OCI objects. Possible values are:
    /// Always: the kubelet always attempts to pull the reference. Container creation will fail If the pull fails.
    /// Never: the kubelet never pulls the reference and only uses a local image or artifact. Container creation will fail if the reference isn't present.
    /// IfNotPresent: the kubelet pulls if the reference isn't already present on disk. Container creation will fail if the reference isn't present and the pull fails.
    /// Defaults to Always if :latest tag is specified, or IfNotPresent otherwise.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "pullPolicy")]
    pub pull_policy: Option<String>,
    /// Required: Image or artifact reference to be used.
    /// Behaves in the same way as pod.spec.containers[*].image.
    /// Pull secrets will be assembled in the same way as for the container image by looking up node credentials, SA image pull secrets, and pod spec image pull secrets.
    /// More info: <https://kubernetes.io/docs/concepts/containers/images>
    /// This field is optional to allow higher level config management to default or override
    /// container images in workload controllers like Deployments and StatefulSets.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub reference: Option<String>,
}

/// Options to specify LDAP configuration
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPostgresqlLdap {
    /// Bind as authentication configuration
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "bindAsAuth")]
    pub bind_as_auth: Option<ClusterPostgresqlLdapBindAsAuth>,
    /// Bind+Search authentication configuration
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "bindSearchAuth")]
    pub bind_search_auth: Option<ClusterPostgresqlLdapBindSearchAuth>,
    /// LDAP server port
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub port: Option<i64>,
    /// LDAP schema to be used, possible options are `ldap` and `ldaps`
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub scheme: Option<ClusterPostgresqlLdapScheme>,
    /// LDAP hostname or IP address
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub server: Option<String>,
    /// Set to 'true' to enable LDAP over TLS. 'false' is default
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<bool>,
}

/// Bind as authentication configuration
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPostgresqlLdapBindAsAuth {
    /// Prefix for the bind authentication option
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub prefix: Option<String>,
    /// Suffix for the bind authentication option
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub suffix: Option<String>,
}

/// Bind+Search authentication configuration
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPostgresqlLdapBindSearchAuth {
    /// Root DN to begin the user search
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "baseDN")]
    pub base_dn: Option<String>,
    /// DN of the user to bind to the directory
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "bindDN")]
    pub bind_dn: Option<String>,
    /// Secret with the password for the user to bind to the directory
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "bindPassword")]
    pub bind_password: Option<ClusterPostgresqlLdapBindSearchAuthBindPassword>,
    /// Attribute to match against the username
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "searchAttribute")]
    pub search_attribute: Option<String>,
    /// Search filter to use when doing the search+bind authentication
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "searchFilter")]
    pub search_filter: Option<String>,
}

/// Secret with the password for the user to bind to the directory
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPostgresqlLdapBindSearchAuthBindPassword {
    /// The key of the secret to select from.  Must be a valid secret key.
    pub key: String,
    /// Name of the referent.
    /// This field is effectively required, but due to backwards compatibility is
    /// allowed to be empty. Instances of this type with an empty value here are
    /// almost certainly wrong.
    /// More info: <https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Specify whether the Secret or its key must be defined
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub optional: Option<bool>,
}

/// Options to specify LDAP configuration
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterPostgresqlLdapScheme {
    #[serde(rename = "ldap")]
    Ldap,
    #[serde(rename = "ldaps")]
    Ldaps,
}

/// Requirements to be met by sync replicas. This will affect how the "synchronous_standby_names" parameter will be
/// set up.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPostgresqlSyncReplicaElectionConstraint {
    /// This flag enables the constraints for sync replicas
    pub enabled: bool,
    /// A list of node labels values to extract and compare to evaluate if the pods reside in the same topology or not
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeLabelsAntiAffinity")]
    pub node_labels_anti_affinity: Option<Vec<String>>,
}

/// Configuration of the PostgreSQL synchronous replication feature
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct ClusterPostgresqlSynchronous {
    /// If set to "required", data durability is strictly enforced. Write operations
    /// with synchronous commit settings (`on`, `remote_write`, or `remote_apply`) will
    /// block if there are insufficient healthy replicas, ensuring data persistence.
    /// If set to "preferred", data durability is maintained when healthy replicas
    /// are available, but the required number of instances will adjust dynamically
    /// if replicas become unavailable. This setting relaxes strict durability enforcement
    /// to allow for operational continuity. This setting is only applicable if both
    /// `standbyNamesPre` and `standbyNamesPost` are unset (empty).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataDurability")]
    pub data_durability: Option<ClusterPostgresqlSynchronousDataDurability>,
    /// Specifies the maximum number of local cluster pods that can be
    /// automatically included in the `synchronous_standby_names` option in
    /// PostgreSQL.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxStandbyNamesFromCluster")]
    pub max_standby_names_from_cluster: Option<i64>,
    /// Method to select synchronous replication standbys from the listed
    /// servers, accepting 'any' (quorum-based synchronous replication) or
    /// 'first' (priority-based synchronous replication) as values.
    pub method: ClusterPostgresqlSynchronousMethod,
    /// Specifies the number of synchronous standby servers that
    /// transactions must wait for responses from.
    pub number: i64,
    /// A user-defined list of application names to be added to
    /// `synchronous_standby_names` after local cluster pods (the order is
    /// only useful for priority-based synchronous replication).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "standbyNamesPost")]
    pub standby_names_post: Option<Vec<String>>,
    /// A user-defined list of application names to be added to
    /// `synchronous_standby_names` before local cluster pods (the order is
    /// only useful for priority-based synchronous replication).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "standbyNamesPre")]
    pub standby_names_pre: Option<Vec<String>>,
}

/// Configuration of the PostgreSQL synchronous replication feature
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterPostgresqlSynchronousDataDurability {
    #[serde(rename = "required")]
    Required,
    #[serde(rename = "preferred")]
    Preferred,
}

/// Configuration of the PostgreSQL synchronous replication feature
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterPostgresqlSynchronousMethod {
    #[serde(rename = "any")]
    Any,
    #[serde(rename = "first")]
    First,
}

/// Specification of the desired behavior of the cluster.
/// More info: <https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterPrimaryUpdateMethod {
    #[serde(rename = "switchover")]
    Switchover,
    #[serde(rename = "restart")]
    Restart,
}

/// Specification of the desired behavior of the cluster.
/// More info: <https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterPrimaryUpdateStrategy {
    #[serde(rename = "unsupervised")]
    Unsupervised,
    #[serde(rename = "supervised")]
    Supervised,
}

/// The configuration of the probes to be injected
/// in the PostgreSQL Pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProbes {
    /// The liveness probe configuration
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub liveness: Option<ClusterProbesLiveness>,
    /// The readiness probe configuration
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub readiness: Option<ClusterProbesReadiness>,
    /// The startup probe configuration
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub startup: Option<ClusterProbesStartup>,
}

/// The liveness probe configuration
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProbesLiveness {
    /// Minimum consecutive failures for the probe to be considered failed after having succeeded.
    /// Defaults to 3. Minimum value is 1.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "failureThreshold")]
    pub failure_threshold: Option<i32>,
    /// Number of seconds after the container has started before liveness probes are initiated.
    /// More info: <https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "initialDelaySeconds")]
    pub initial_delay_seconds: Option<i32>,
    /// Configure the feature that extends the liveness probe for a primary
    /// instance. In addition to the basic checks, this verifies whether the
    /// primary is isolated from the Kubernetes API server and from its
    /// replicas, ensuring that it can be safely shut down if network
    /// partition or API unavailability is detected. Enabled by default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "isolationCheck")]
    pub isolation_check: Option<ClusterProbesLivenessIsolationCheck>,
    /// How often (in seconds) to perform the probe.
    /// Default to 10 seconds. Minimum value is 1.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "periodSeconds")]
    pub period_seconds: Option<i32>,
    /// Minimum consecutive successes for the probe to be considered successful after having failed.
    /// Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "successThreshold")]
    pub success_threshold: Option<i32>,
    /// Optional duration in seconds the pod needs to terminate gracefully upon probe failure.
    /// The grace period is the duration in seconds after the processes running in the pod are sent
    /// a termination signal and the time when the processes are forcibly halted with a kill signal.
    /// Set this value longer than the expected cleanup time for your process.
    /// If this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this
    /// value overrides the value provided by the pod spec.
    /// Value must be non-negative integer. The value zero indicates stop immediately via
    /// the kill signal (no opportunity to shut down).
    /// This is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.
    /// Minimum value is 1. spec.terminationGracePeriodSeconds is used if unset.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "terminationGracePeriodSeconds")]
    pub termination_grace_period_seconds: Option<i64>,
    /// Number of seconds after which the probe times out.
    /// Defaults to 1 second. Minimum value is 1.
    /// More info: <https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "timeoutSeconds")]
    pub timeout_seconds: Option<i32>,
}

/// Configure the feature that extends the liveness probe for a primary
/// instance. In addition to the basic checks, this verifies whether the
/// primary is isolated from the Kubernetes API server and from its
/// replicas, ensuring that it can be safely shut down if network
/// partition or API unavailability is detected. Enabled by default.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProbesLivenessIsolationCheck {
    /// Timeout in milliseconds for connections during the primary isolation check
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "connectionTimeout")]
    pub connection_timeout: Option<i64>,
    /// Whether primary isolation checking is enabled for the liveness probe
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enabled: Option<bool>,
    /// Timeout in milliseconds for requests during the primary isolation check
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requestTimeout")]
    pub request_timeout: Option<i64>,
}

/// The readiness probe configuration
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProbesReadiness {
    /// Minimum consecutive failures for the probe to be considered failed after having succeeded.
    /// Defaults to 3. Minimum value is 1.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "failureThreshold")]
    pub failure_threshold: Option<i32>,
    /// Number of seconds after the container has started before liveness probes are initiated.
    /// More info: <https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "initialDelaySeconds")]
    pub initial_delay_seconds: Option<i32>,
    /// Lag limit. Used only for `streaming` strategy
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumLag")]
    pub maximum_lag: Option<IntOrString>,
    /// How often (in seconds) to perform the probe.
    /// Default to 10 seconds. Minimum value is 1.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "periodSeconds")]
    pub period_seconds: Option<i32>,
    /// Minimum consecutive successes for the probe to be considered successful after having failed.
    /// Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "successThreshold")]
    pub success_threshold: Option<i32>,
    /// Optional duration in seconds the pod needs to terminate gracefully upon probe failure.
    /// The grace period is the duration in seconds after the processes running in the pod are sent
    /// a termination signal and the time when the processes are forcibly halted with a kill signal.
    /// Set this value longer than the expected cleanup time for your process.
    /// If this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this
    /// value overrides the value provided by the pod spec.
    /// Value must be non-negative integer. The value zero indicates stop immediately via
    /// the kill signal (no opportunity to shut down).
    /// This is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.
    /// Minimum value is 1. spec.terminationGracePeriodSeconds is used if unset.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "terminationGracePeriodSeconds")]
    pub termination_grace_period_seconds: Option<i64>,
    /// Number of seconds after which the probe times out.
    /// Defaults to 1 second. Minimum value is 1.
    /// More info: <https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "timeoutSeconds")]
    pub timeout_seconds: Option<i32>,
    /// The probe strategy
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<ClusterProbesReadinessType>,
}

/// The readiness probe configuration
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterProbesReadinessType {
    #[serde(rename = "pg_isready")]
    PgIsready,
    #[serde(rename = "streaming")]
    Streaming,
    #[serde(rename = "query")]
    Query,
}

/// The startup probe configuration
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProbesStartup {
    /// Minimum consecutive failures for the probe to be considered failed after having succeeded.
    /// Defaults to 3. Minimum value is 1.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "failureThreshold")]
    pub failure_threshold: Option<i32>,
    /// Number of seconds after the container has started before liveness probes are initiated.
    /// More info: <https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "initialDelaySeconds")]
    pub initial_delay_seconds: Option<i32>,
    /// Lag limit. Used only for `streaming` strategy
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumLag")]
    pub maximum_lag: Option<IntOrString>,
    /// How often (in seconds) to perform the probe.
    /// Default to 10 seconds. Minimum value is 1.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "periodSeconds")]
    pub period_seconds: Option<i32>,
    /// Minimum consecutive successes for the probe to be considered successful after having failed.
    /// Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "successThreshold")]
    pub success_threshold: Option<i32>,
    /// Optional duration in seconds the pod needs to terminate gracefully upon probe failure.
    /// The grace period is the duration in seconds after the processes running in the pod are sent
    /// a termination signal and the time when the processes are forcibly halted with a kill signal.
    /// Set this value longer than the expected cleanup time for your process.
    /// If this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this
    /// value overrides the value provided by the pod spec.
    /// Value must be non-negative integer. The value zero indicates stop immediately via
    /// the kill signal (no opportunity to shut down).
    /// This is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.
    /// Minimum value is 1. spec.terminationGracePeriodSeconds is used if unset.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "terminationGracePeriodSeconds")]
    pub termination_grace_period_seconds: Option<i64>,
    /// Number of seconds after which the probe times out.
    /// Defaults to 1 second. Minimum value is 1.
    /// More info: <https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "timeoutSeconds")]
    pub timeout_seconds: Option<i32>,
    /// The probe strategy
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<ClusterProbesStartupType>,
}

/// The startup probe configuration
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterProbesStartupType {
    #[serde(rename = "pg_isready")]
    PgIsready,
    #[serde(rename = "streaming")]
    Streaming,
    #[serde(rename = "query")]
    Query,
}

/// Template to be used to define projected volumes, projected volumes will be mounted
/// under `/projected` base folder
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProjectedVolumeTemplate {
    /// defaultMode are the mode bits used to set permissions on created files by default.
    /// Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511.
    /// YAML accepts both octal and decimal values, JSON requires decimal values for mode bits.
    /// Directories within the path are not affected by this setting.
    /// This might be in conflict with other options that affect the file
    /// mode, like fsGroup, and the result can be other mode bits set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "defaultMode")]
    pub default_mode: Option<i32>,
    /// sources is the list of volume projections. Each entry in this list
    /// handles one source.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub sources: Option<Vec<ClusterProjectedVolumeTemplateSources>>,
}

/// Projection that may be projected along with other supported volume types.
/// Exactly one of these fields must be set.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProjectedVolumeTemplateSources {
    /// ClusterTrustBundle allows a pod to access the `.spec.trustBundle` field
    /// of ClusterTrustBundle objects in an auto-updating file.
    /// 
    /// Alpha, gated by the ClusterTrustBundleProjection feature gate.
    /// 
    /// ClusterTrustBundle objects can either be selected by name, or by the
    /// combination of signer name and a label selector.
    /// 
    /// Kubelet performs aggressive normalization of the PEM contents written
    /// into the pod filesystem.  Esoteric PEM features such as inter-block
    /// comments and block headers are stripped.  Certificates are deduplicated.
    /// The ordering of certificates within the file is arbitrary, and Kubelet
    /// may change the order over time.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clusterTrustBundle")]
    pub cluster_trust_bundle: Option<ClusterProjectedVolumeTemplateSourcesClusterTrustBundle>,
    /// configMap information about the configMap data to project
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configMap")]
    pub config_map: Option<ClusterProjectedVolumeTemplateSourcesConfigMap>,
    /// downwardAPI information about the downwardAPI data to project
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "downwardAPI")]
    pub downward_api: Option<ClusterProjectedVolumeTemplateSourcesDownwardApi>,
    /// Projects an auto-rotating credential bundle (private key and certificate
    /// chain) that the pod can use either as a TLS client or server.
    /// 
    /// Kubelet generates a private key and uses it to send a
    /// PodCertificateRequest to the named signer.  Once the signer approves the
    /// request and issues a certificate chain, Kubelet writes the key and
    /// certificate chain to the pod filesystem.  The pod does not start until
    /// certificates have been issued for each podCertificate projected volume
    /// source in its spec.
    /// 
    /// Kubelet will begin trying to rotate the certificate at the time indicated
    /// by the signer using the PodCertificateRequest.Status.BeginRefreshAt
    /// timestamp.
    /// 
    /// Kubelet can write a single file, indicated by the credentialBundlePath
    /// field, or separate files, indicated by the keyPath and
    /// certificateChainPath fields.
    /// 
    /// The credential bundle is a single file in PEM format.  The first PEM
    /// entry is the private key (in PKCS#8 format), and the remaining PEM
    /// entries are the certificate chain issued by the signer (typically,
    /// signers will return their certificate chain in leaf-to-root order).
    /// 
    /// Prefer using the credential bundle format, since your application code
    /// can read it atomically.  If you use keyPath and certificateChainPath,
    /// your application must make two separate file reads. If these coincide
    /// with a certificate rotation, it is possible that the private key and leaf
    /// certificate you read may not correspond to each other.  Your application
    /// will need to check for this condition, and re-read until they are
    /// consistent.
    /// 
    /// The named signer controls chooses the format of the certificate it
    /// issues; consult the signer implementation's documentation to learn how to
    /// use the certificates it issues.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podCertificate")]
    pub pod_certificate: Option<ClusterProjectedVolumeTemplateSourcesPodCertificate>,
    /// secret information about the secret data to project
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub secret: Option<ClusterProjectedVolumeTemplateSourcesSecret>,
    /// serviceAccountToken is information about the serviceAccountToken data to project
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "serviceAccountToken")]
    pub service_account_token: Option<ClusterProjectedVolumeTemplateSourcesServiceAccountToken>,
}

/// ClusterTrustBundle allows a pod to access the `.spec.trustBundle` field
/// of ClusterTrustBundle objects in an auto-updating file.
/// 
/// Alpha, gated by the ClusterTrustBundleProjection feature gate.
/// 
/// ClusterTrustBundle objects can either be selected by name, or by the
/// combination of signer name and a label selector.
/// 
/// Kubelet performs aggressive normalization of the PEM contents written
/// into the pod filesystem.  Esoteric PEM features such as inter-block
/// comments and block headers are stripped.  Certificates are deduplicated.
/// The ordering of certificates within the file is arbitrary, and Kubelet
/// may change the order over time.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProjectedVolumeTemplateSourcesClusterTrustBundle {
    /// Select all ClusterTrustBundles that match this label selector.  Only has
    /// effect if signerName is set.  Mutually-exclusive with name.  If unset,
    /// interpreted as "match nothing".  If set but empty, interpreted as "match
    /// everything".
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<ClusterProjectedVolumeTemplateSourcesClusterTrustBundleLabelSelector>,
    /// Select a single ClusterTrustBundle by object name.  Mutually-exclusive
    /// with signerName and labelSelector.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// If true, don't block pod startup if the referenced ClusterTrustBundle(s)
    /// aren't available.  If using name, then the named ClusterTrustBundle is
    /// allowed not to exist.  If using signerName, then the combination of
    /// signerName and labelSelector is allowed to match zero
    /// ClusterTrustBundles.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub optional: Option<bool>,
    /// Relative path from the volume root to write the bundle.
    pub path: String,
    /// Select all ClusterTrustBundles that match this signer name.
    /// Mutually-exclusive with name.  The contents of all selected
    /// ClusterTrustBundles will be unified and deduplicated.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "signerName")]
    pub signer_name: Option<String>,
}

/// Select all ClusterTrustBundles that match this label selector.  Only has
/// effect if signerName is set.  Mutually-exclusive with name.  If unset,
/// interpreted as "match nothing".  If set but empty, interpreted as "match
/// everything".
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProjectedVolumeTemplateSourcesClusterTrustBundleLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterProjectedVolumeTemplateSourcesClusterTrustBundleLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProjectedVolumeTemplateSourcesClusterTrustBundleLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// configMap information about the configMap data to project
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProjectedVolumeTemplateSourcesConfigMap {
    /// items if unspecified, each key-value pair in the Data field of the referenced
    /// ConfigMap will be projected into the volume as a file whose name is the
    /// key and content is the value. If specified, the listed keys will be
    /// projected into the specified paths, and unlisted keys will not be
    /// present. If a key is specified which is not present in the ConfigMap,
    /// the volume setup will error unless it is marked optional. Paths must be
    /// relative and may not contain the '..' path or start with '..'.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub items: Option<Vec<ClusterProjectedVolumeTemplateSourcesConfigMapItems>>,
    /// Name of the referent.
    /// This field is effectively required, but due to backwards compatibility is
    /// allowed to be empty. Instances of this type with an empty value here are
    /// almost certainly wrong.
    /// More info: <https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// optional specify whether the ConfigMap or its keys must be defined
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub optional: Option<bool>,
}

/// Maps a string key to a path within a volume.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProjectedVolumeTemplateSourcesConfigMapItems {
    /// key is the key to project.
    pub key: String,
    /// mode is Optional: mode bits used to set permissions on this file.
    /// Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511.
    /// YAML accepts both octal and decimal values, JSON requires decimal values for mode bits.
    /// If not specified, the volume defaultMode will be used.
    /// This might be in conflict with other options that affect the file
    /// mode, like fsGroup, and the result can be other mode bits set.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub mode: Option<i32>,
    /// path is the relative path of the file to map the key to.
    /// May not be an absolute path.
    /// May not contain the path element '..'.
    /// May not start with the string '..'.
    pub path: String,
}

/// downwardAPI information about the downwardAPI data to project
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProjectedVolumeTemplateSourcesDownwardApi {
    /// Items is a list of DownwardAPIVolume file
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub items: Option<Vec<ClusterProjectedVolumeTemplateSourcesDownwardApiItems>>,
}

/// DownwardAPIVolumeFile represents information to create the file containing the pod field
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProjectedVolumeTemplateSourcesDownwardApiItems {
    /// Required: Selects a field of the pod: only annotations, labels, name, namespace and uid are supported.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldRef")]
    pub field_ref: Option<ClusterProjectedVolumeTemplateSourcesDownwardApiItemsFieldRef>,
    /// Optional: mode bits used to set permissions on this file, must be an octal value
    /// between 0000 and 0777 or a decimal value between 0 and 511.
    /// YAML accepts both octal and decimal values, JSON requires decimal values for mode bits.
    /// If not specified, the volume defaultMode will be used.
    /// This might be in conflict with other options that affect the file
    /// mode, like fsGroup, and the result can be other mode bits set.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub mode: Option<i32>,
    /// Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'
    pub path: String,
    /// Selects a resource of the container: only resources limits and requests
    /// (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "resourceFieldRef")]
    pub resource_field_ref: Option<ClusterProjectedVolumeTemplateSourcesDownwardApiItemsResourceFieldRef>,
}

/// Required: Selects a field of the pod: only annotations, labels, name, namespace and uid are supported.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProjectedVolumeTemplateSourcesDownwardApiItemsFieldRef {
    /// Version of the schema the FieldPath is written in terms of, defaults to "v1".
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiVersion")]
    pub api_version: Option<String>,
    /// Path of the field to select in the specified API version.
    #[serde(rename = "fieldPath")]
    pub field_path: String,
}

/// Selects a resource of the container: only resources limits and requests
/// (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProjectedVolumeTemplateSourcesDownwardApiItemsResourceFieldRef {
    /// Container name: required for volumes, optional for env vars
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "containerName")]
    pub container_name: Option<String>,
    /// Specifies the output format of the exposed resources, defaults to "1"
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub divisor: Option<IntOrString>,
    /// Required: resource to select
    pub resource: String,
}

/// Projects an auto-rotating credential bundle (private key and certificate
/// chain) that the pod can use either as a TLS client or server.
/// 
/// Kubelet generates a private key and uses it to send a
/// PodCertificateRequest to the named signer.  Once the signer approves the
/// request and issues a certificate chain, Kubelet writes the key and
/// certificate chain to the pod filesystem.  The pod does not start until
/// certificates have been issued for each podCertificate projected volume
/// source in its spec.
/// 
/// Kubelet will begin trying to rotate the certificate at the time indicated
/// by the signer using the PodCertificateRequest.Status.BeginRefreshAt
/// timestamp.
/// 
/// Kubelet can write a single file, indicated by the credentialBundlePath
/// field, or separate files, indicated by the keyPath and
/// certificateChainPath fields.
/// 
/// The credential bundle is a single file in PEM format.  The first PEM
/// entry is the private key (in PKCS#8 format), and the remaining PEM
/// entries are the certificate chain issued by the signer (typically,
/// signers will return their certificate chain in leaf-to-root order).
/// 
/// Prefer using the credential bundle format, since your application code
/// can read it atomically.  If you use keyPath and certificateChainPath,
/// your application must make two separate file reads. If these coincide
/// with a certificate rotation, it is possible that the private key and leaf
/// certificate you read may not correspond to each other.  Your application
/// will need to check for this condition, and re-read until they are
/// consistent.
/// 
/// The named signer controls chooses the format of the certificate it
/// issues; consult the signer implementation's documentation to learn how to
/// use the certificates it issues.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProjectedVolumeTemplateSourcesPodCertificate {
    /// Write the certificate chain at this path in the projected volume.
    /// 
    /// Most applications should use credentialBundlePath.  When using keyPath
    /// and certificateChainPath, your application needs to check that the key
    /// and leaf certificate are consistent, because it is possible to read the
    /// files mid-rotation.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certificateChainPath")]
    pub certificate_chain_path: Option<String>,
    /// Write the credential bundle at this path in the projected volume.
    /// 
    /// The credential bundle is a single file that contains multiple PEM blocks.
    /// The first PEM block is a PRIVATE KEY block, containing a PKCS#8 private
    /// key.
    /// 
    /// The remaining blocks are CERTIFICATE blocks, containing the issued
    /// certificate chain from the signer (leaf and any intermediates).
    /// 
    /// Using credentialBundlePath lets your Pod's application code make a single
    /// atomic read that retrieves a consistent key and certificate chain.  If you
    /// project them to separate files, your application code will need to
    /// additionally check that the leaf certificate was issued to the key.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "credentialBundlePath")]
    pub credential_bundle_path: Option<String>,
    /// Write the key at this path in the projected volume.
    /// 
    /// Most applications should use credentialBundlePath.  When using keyPath
    /// and certificateChainPath, your application needs to check that the key
    /// and leaf certificate are consistent, because it is possible to read the
    /// files mid-rotation.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "keyPath")]
    pub key_path: Option<String>,
    /// The type of keypair Kubelet will generate for the pod.
    /// 
    /// Valid values are "RSA3072", "RSA4096", "ECDSAP256", "ECDSAP384",
    /// "ECDSAP521", and "ED25519".
    #[serde(rename = "keyType")]
    pub key_type: String,
    /// maxExpirationSeconds is the maximum lifetime permitted for the
    /// certificate.
    /// 
    /// Kubelet copies this value verbatim into the PodCertificateRequests it
    /// generates for this projection.
    /// 
    /// If omitted, kube-apiserver will set it to 86400(24 hours). kube-apiserver
    /// will reject values shorter than 3600 (1 hour).  The maximum allowable
    /// value is 7862400 (91 days).
    /// 
    /// The signer implementation is then free to issue a certificate with any
    /// lifetime *shorter* than MaxExpirationSeconds, but no shorter than 3600
    /// seconds (1 hour).  This constraint is enforced by kube-apiserver.
    /// `kubernetes.io` signers will never issue certificates with a lifetime
    /// longer than 24 hours.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxExpirationSeconds")]
    pub max_expiration_seconds: Option<i32>,
    /// Kubelet's generated CSRs will be addressed to this signer.
    #[serde(rename = "signerName")]
    pub signer_name: String,
}

/// secret information about the secret data to project
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProjectedVolumeTemplateSourcesSecret {
    /// items if unspecified, each key-value pair in the Data field of the referenced
    /// Secret will be projected into the volume as a file whose name is the
    /// key and content is the value. If specified, the listed keys will be
    /// projected into the specified paths, and unlisted keys will not be
    /// present. If a key is specified which is not present in the Secret,
    /// the volume setup will error unless it is marked optional. Paths must be
    /// relative and may not contain the '..' path or start with '..'.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub items: Option<Vec<ClusterProjectedVolumeTemplateSourcesSecretItems>>,
    /// Name of the referent.
    /// This field is effectively required, but due to backwards compatibility is
    /// allowed to be empty. Instances of this type with an empty value here are
    /// almost certainly wrong.
    /// More info: <https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// optional field specify whether the Secret or its key must be defined
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub optional: Option<bool>,
}

/// Maps a string key to a path within a volume.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProjectedVolumeTemplateSourcesSecretItems {
    /// key is the key to project.
    pub key: String,
    /// mode is Optional: mode bits used to set permissions on this file.
    /// Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511.
    /// YAML accepts both octal and decimal values, JSON requires decimal values for mode bits.
    /// If not specified, the volume defaultMode will be used.
    /// This might be in conflict with other options that affect the file
    /// mode, like fsGroup, and the result can be other mode bits set.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub mode: Option<i32>,
    /// path is the relative path of the file to map the key to.
    /// May not be an absolute path.
    /// May not contain the path element '..'.
    /// May not start with the string '..'.
    pub path: String,
}

/// serviceAccountToken is information about the serviceAccountToken data to project
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterProjectedVolumeTemplateSourcesServiceAccountToken {
    /// audience is the intended audience of the token. A recipient of a token
    /// must identify itself with an identifier specified in the audience of the
    /// token, and otherwise should reject the token. The audience defaults to the
    /// identifier of the apiserver.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub audience: Option<String>,
    /// expirationSeconds is the requested duration of validity of the service
    /// account token. As the token approaches expiration, the kubelet volume
    /// plugin will proactively rotate the service account token. The kubelet will
    /// start trying to rotate the token if the token is older than 80 percent of
    /// its time to live or if the token is older than 24 hours.Defaults to 1 hour
    /// and must be at least 10 minutes.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "expirationSeconds")]
    pub expiration_seconds: Option<i64>,
    /// path is the path relative to the mount point of the file to project the
    /// token into.
    pub path: String,
}

/// Replica cluster configuration
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterReplica {
    /// If replica mode is enabled, this cluster will be a replica of an
    /// existing cluster. Replica cluster can be created from a recovery
    /// object store or via streaming through pg_basebackup.
    /// Refer to the Replica clusters page of the documentation for more information.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enabled: Option<bool>,
    /// When replica mode is enabled, this parameter allows you to replay
    /// transactions only when the system time is at least the configured
    /// time past the commit time. This provides an opportunity to correct
    /// data loss errors. Note that when this parameter is set, a promotion
    /// token cannot be used.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "minApplyDelay")]
    pub min_apply_delay: Option<String>,
    /// Primary defines which Cluster is defined to be the primary in the distributed PostgreSQL cluster, based on the
    /// topology specified in externalClusters
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub primary: Option<String>,
    /// A demotion token generated by an external cluster used to
    /// check if the promotion requirements are met.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "promotionToken")]
    pub promotion_token: Option<String>,
    /// Self defines the name of this cluster. It is used to determine if this is a primary
    /// or a replica cluster, comparing it with `primary`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "self")]
    pub r#_self: Option<String>,
    /// The name of the external cluster which is the replication origin
    pub source: String,
}

/// Replication slots management configuration
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterReplicationSlots {
    /// Replication slots for high availability configuration
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "highAvailability")]
    pub high_availability: Option<ClusterReplicationSlotsHighAvailability>,
    /// Configures the synchronization of the user defined physical replication slots
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "synchronizeReplicas")]
    pub synchronize_replicas: Option<ClusterReplicationSlotsSynchronizeReplicas>,
    /// Standby will update the status of the local replication slots
    /// every `updateInterval` seconds (default 30).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "updateInterval")]
    pub update_interval: Option<i64>,
}

/// Replication slots for high availability configuration
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterReplicationSlotsHighAvailability {
    /// If enabled (default), the operator will automatically manage replication slots
    /// on the primary instance and use them in streaming replication
    /// connections with all the standby instances that are part of the HA
    /// cluster. If disabled, the operator will not take advantage
    /// of replication slots in streaming connections with the replicas.
    /// This feature also controls replication slots in replica cluster,
    /// from the designated primary to its cascading replicas.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enabled: Option<bool>,
    /// Prefix for replication slots managed by the operator for HA.
    /// It may only contain lower case letters, numbers, and the underscore character.
    /// This can only be set at creation time. By default set to `_cnpg_`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "slotPrefix")]
    pub slot_prefix: Option<String>,
    /// When enabled, the operator automatically manages synchronization of logical
    /// decoding (replication) slots across high-availability clusters.
    /// 
    /// Requires one of the following conditions:
    /// - PostgreSQL version 17 or later
    /// - PostgreSQL version < 17 with pg_failover_slots extension enabled
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "synchronizeLogicalDecoding")]
    pub synchronize_logical_decoding: Option<bool>,
}

/// Configures the synchronization of the user defined physical replication slots
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterReplicationSlotsSynchronizeReplicas {
    /// When set to true, every replication slot that is on the primary is synchronized on each standby
    pub enabled: bool,
    /// List of regular expression patterns to match the names of replication slots to be excluded (by default empty)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "excludePatterns")]
    pub exclude_patterns: Option<Vec<String>>,
}

/// Resources requirements of every generated Pod. Please refer to
/// <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
/// for more information.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterResources {
    /// Claims lists the names of resources, defined in spec.resourceClaims,
    /// that are used by this container.
    /// 
    /// This field depends on the
    /// DynamicResourceAllocation feature gate.
    /// 
    /// This field is immutable. It can only be set for containers.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub claims: Option<Vec<ClusterResourcesClaims>>,
    /// Limits describes the maximum amount of compute resources allowed.
    /// More info: <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub limits: Option<BTreeMap<String, IntOrString>>,
    /// Requests describes the minimum amount of compute resources required.
    /// If Requests is omitted for a container, it defaults to Limits if that is explicitly specified,
    /// otherwise to an implementation-defined value. Requests cannot exceed Limits.
    /// More info: <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub requests: Option<BTreeMap<String, IntOrString>>,
}

/// ResourceClaim references one entry in PodSpec.ResourceClaims.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterResourcesClaims {
    /// Name must match the name of one entry in pod.spec.resourceClaims of
    /// the Pod where this field is used. It makes that resource available
    /// inside a container.
    pub name: String,
    /// Request is the name chosen for a request in the referenced claim.
    /// If empty, everything from the claim is made available, otherwise
    /// only the result of this request.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub request: Option<String>,
}

/// The SeccompProfile applied to every Pod and Container.
/// Defaults to: `RuntimeDefault`
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterSeccompProfile {
    /// localhostProfile indicates a profile defined in a file on the node should be used.
    /// The profile must be preconfigured on the node to work.
    /// Must be a descending path, relative to the kubelet's configured seccomp profile location.
    /// Must be set if type is "Localhost". Must NOT be set for any other type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "localhostProfile")]
    pub localhost_profile: Option<String>,
    /// type indicates which kind of seccomp profile will be applied.
    /// Valid options are:
    /// 
    /// Localhost - a profile defined in a file on the node should be used.
    /// RuntimeDefault - the container runtime default profile should be used.
    /// Unconfined - no profile should be applied.
    #[serde(rename = "type")]
    pub r#type: String,
}

/// Configure the generation of the service account
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterServiceAccountTemplate {
    /// Metadata are the metadata to be used for the generated
    /// service account
    pub metadata: ClusterServiceAccountTemplateMetadata,
}

/// Metadata are the metadata to be used for the generated
/// service account
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterServiceAccountTemplateMetadata {
    /// Annotations is an unstructured key value map stored with a resource that may be
    /// set by external tools to store and retrieve arbitrary metadata. They are not
    /// queryable and should be preserved when modifying objects.
    /// More info: <http://kubernetes.io/docs/user-guide/annotations>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub annotations: Option<BTreeMap<String, String>>,
    /// Map of string keys and values that can be used to organize and categorize
    /// (scope and select) objects. May match selectors of replication controllers
    /// and services.
    /// More info: <http://kubernetes.io/docs/user-guide/labels>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub labels: Option<BTreeMap<String, String>>,
    /// The name of the resource. Only supported for certain types
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// Configuration of the storage of the instances
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStorage {
    /// Template to be used to generate the Persistent Volume Claim
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "pvcTemplate")]
    pub pvc_template: Option<ClusterStoragePvcTemplate>,
    /// Resize existent PVCs, defaults to true
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "resizeInUseVolumes")]
    pub resize_in_use_volumes: Option<bool>,
    /// Size of the storage. Required if not already specified in the PVC template.
    /// Changes to this field are automatically reapplied to the created PVCs.
    /// Size cannot be decreased.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub size: Option<String>,
    /// StorageClass to use for PVCs. Applied after
    /// evaluating the PVC template, if available.
    /// If not specified, the generated PVCs will use the
    /// default storage class
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "storageClass")]
    pub storage_class: Option<String>,
}

/// Template to be used to generate the Persistent Volume Claim
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStoragePvcTemplate {
    /// accessModes contains the desired access modes the volume should have.
    /// More info: <https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "accessModes")]
    pub access_modes: Option<Vec<String>>,
    /// dataSource field can be used to specify either:
    /// * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)
    /// * An existing PVC (PersistentVolumeClaim)
    /// If the provisioner or an external controller can support the specified data source,
    /// it will create a new volume based on the contents of the specified data source.
    /// When the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,
    /// and dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.
    /// If the namespace is specified, then dataSourceRef will not be copied to dataSource.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataSource")]
    pub data_source: Option<ClusterStoragePvcTemplateDataSource>,
    /// dataSourceRef specifies the object from which to populate the volume with data, if a non-empty
    /// volume is desired. This may be any object from a non-empty API group (non
    /// core object) or a PersistentVolumeClaim object.
    /// When this field is specified, volume binding will only succeed if the type of
    /// the specified object matches some installed volume populator or dynamic
    /// provisioner.
    /// This field will replace the functionality of the dataSource field and as such
    /// if both fields are non-empty, they must have the same value. For backwards
    /// compatibility, when namespace isn't specified in dataSourceRef,
    /// both fields (dataSource and dataSourceRef) will be set to the same
    /// value automatically if one of them is empty and the other is non-empty.
    /// When namespace is specified in dataSourceRef,
    /// dataSource isn't set to the same value and must be empty.
    /// There are three important differences between dataSource and dataSourceRef:
    /// * While dataSource only allows two specific types of objects, dataSourceRef
    ///   allows any non-core object, as well as PersistentVolumeClaim objects.
    /// * While dataSource ignores disallowed values (dropping them), dataSourceRef
    ///   preserves all values, and generates an error if a disallowed value is
    ///   specified.
    /// * While dataSource only allows local objects, dataSourceRef allows objects
    ///   in any namespaces.
    /// (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
    /// (Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataSourceRef")]
    pub data_source_ref: Option<ClusterStoragePvcTemplateDataSourceRef>,
    /// resources represents the minimum resources the volume should have.
    /// If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements
    /// that are lower than previous value but must still be higher than capacity recorded in the
    /// status field of the claim.
    /// More info: <https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resources: Option<ClusterStoragePvcTemplateResources>,
    /// selector is a label query over volumes to consider for binding.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selector: Option<ClusterStoragePvcTemplateSelector>,
    /// storageClassName is the name of the StorageClass required by the claim.
    /// More info: <https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "storageClassName")]
    pub storage_class_name: Option<String>,
    /// volumeAttributesClassName may be used to set the VolumeAttributesClass used by this claim.
    /// If specified, the CSI driver will create or update the volume with the attributes defined
    /// in the corresponding VolumeAttributesClass. This has a different purpose than storageClassName,
    /// it can be changed after the claim is created. An empty string or nil value indicates that no
    /// VolumeAttributesClass will be applied to the claim. If the claim enters an Infeasible error state,
    /// this field can be reset to its previous value (including nil) to cancel the modification.
    /// If the resource referred to by volumeAttributesClass does not exist, this PersistentVolumeClaim will be
    /// set to a Pending state, as reflected by the modifyVolumeStatus field, until such as a resource
    /// exists.
    /// More info: <https://kubernetes.io/docs/concepts/storage/volume-attributes-classes/>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeAttributesClassName")]
    pub volume_attributes_class_name: Option<String>,
    /// volumeMode defines what type of volume is required by the claim.
    /// Value of Filesystem is implied when not included in claim spec.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeMode")]
    pub volume_mode: Option<String>,
    /// volumeName is the binding reference to the PersistentVolume backing this claim.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeName")]
    pub volume_name: Option<String>,
}

/// dataSource field can be used to specify either:
/// * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)
/// * An existing PVC (PersistentVolumeClaim)
/// If the provisioner or an external controller can support the specified data source,
/// it will create a new volume based on the contents of the specified data source.
/// When the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,
/// and dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.
/// If the namespace is specified, then dataSourceRef will not be copied to dataSource.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStoragePvcTemplateDataSource {
    /// APIGroup is the group for the resource being referenced.
    /// If APIGroup is not specified, the specified Kind must be in the core API group.
    /// For any other third-party types, APIGroup is required.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiGroup")]
    pub api_group: Option<String>,
    /// Kind is the type of resource being referenced
    pub kind: String,
    /// Name is the name of resource being referenced
    pub name: String,
}

/// dataSourceRef specifies the object from which to populate the volume with data, if a non-empty
/// volume is desired. This may be any object from a non-empty API group (non
/// core object) or a PersistentVolumeClaim object.
/// When this field is specified, volume binding will only succeed if the type of
/// the specified object matches some installed volume populator or dynamic
/// provisioner.
/// This field will replace the functionality of the dataSource field and as such
/// if both fields are non-empty, they must have the same value. For backwards
/// compatibility, when namespace isn't specified in dataSourceRef,
/// both fields (dataSource and dataSourceRef) will be set to the same
/// value automatically if one of them is empty and the other is non-empty.
/// When namespace is specified in dataSourceRef,
/// dataSource isn't set to the same value and must be empty.
/// There are three important differences between dataSource and dataSourceRef:
/// * While dataSource only allows two specific types of objects, dataSourceRef
///   allows any non-core object, as well as PersistentVolumeClaim objects.
/// * While dataSource ignores disallowed values (dropping them), dataSourceRef
///   preserves all values, and generates an error if a disallowed value is
///   specified.
/// * While dataSource only allows local objects, dataSourceRef allows objects
///   in any namespaces.
/// (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
/// (Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStoragePvcTemplateDataSourceRef {
    /// APIGroup is the group for the resource being referenced.
    /// If APIGroup is not specified, the specified Kind must be in the core API group.
    /// For any other third-party types, APIGroup is required.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiGroup")]
    pub api_group: Option<String>,
    /// Kind is the type of resource being referenced
    pub kind: String,
    /// Name is the name of resource being referenced
    pub name: String,
    /// Namespace is the namespace of resource being referenced
    /// Note that when a namespace is specified, a gateway.networking.k8s.io/ReferenceGrant object is required in the referent namespace to allow that namespace's owner to accept the reference. See the ReferenceGrant documentation for details.
    /// (Alpha) This field requires the CrossNamespaceVolumeDataSource feature gate to be enabled.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
}

/// resources represents the minimum resources the volume should have.
/// If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements
/// that are lower than previous value but must still be higher than capacity recorded in the
/// status field of the claim.
/// More info: <https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStoragePvcTemplateResources {
    /// Limits describes the maximum amount of compute resources allowed.
    /// More info: <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub limits: Option<BTreeMap<String, IntOrString>>,
    /// Requests describes the minimum amount of compute resources required.
    /// If Requests is omitted for a container, it defaults to Limits if that is explicitly specified,
    /// otherwise to an implementation-defined value. Requests cannot exceed Limits.
    /// More info: <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub requests: Option<BTreeMap<String, IntOrString>>,
}

/// selector is a label query over volumes to consider for binding.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStoragePvcTemplateSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterStoragePvcTemplateSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStoragePvcTemplateSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// The secret containing the superuser password. If not defined a new
/// secret will be created with a randomly generated password
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterSuperuserSecret {
    /// Name of the referent.
    pub name: String,
}

/// TablespaceConfiguration is the configuration of a tablespace, and includes
/// the storage specification for the tablespace
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterTablespaces {
    /// The name of the tablespace
    pub name: String,
    /// Owner is the PostgreSQL user owning the tablespace
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub owner: Option<ClusterTablespacesOwner>,
    /// The storage configuration for the tablespace
    pub storage: ClusterTablespacesStorage,
    /// When set to true, the tablespace will be added as a `temp_tablespaces`
    /// entry in PostgreSQL, and will be available to automatically house temp
    /// database objects, or other temporary files. Please refer to PostgreSQL
    /// documentation for more information on the `temp_tablespaces` GUC.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub temporary: Option<bool>,
}

/// Owner is the PostgreSQL user owning the tablespace
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterTablespacesOwner {
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// The storage configuration for the tablespace
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterTablespacesStorage {
    /// Template to be used to generate the Persistent Volume Claim
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "pvcTemplate")]
    pub pvc_template: Option<ClusterTablespacesStoragePvcTemplate>,
    /// Resize existent PVCs, defaults to true
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "resizeInUseVolumes")]
    pub resize_in_use_volumes: Option<bool>,
    /// Size of the storage. Required if not already specified in the PVC template.
    /// Changes to this field are automatically reapplied to the created PVCs.
    /// Size cannot be decreased.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub size: Option<String>,
    /// StorageClass to use for PVCs. Applied after
    /// evaluating the PVC template, if available.
    /// If not specified, the generated PVCs will use the
    /// default storage class
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "storageClass")]
    pub storage_class: Option<String>,
}

/// Template to be used to generate the Persistent Volume Claim
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterTablespacesStoragePvcTemplate {
    /// accessModes contains the desired access modes the volume should have.
    /// More info: <https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "accessModes")]
    pub access_modes: Option<Vec<String>>,
    /// dataSource field can be used to specify either:
    /// * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)
    /// * An existing PVC (PersistentVolumeClaim)
    /// If the provisioner or an external controller can support the specified data source,
    /// it will create a new volume based on the contents of the specified data source.
    /// When the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,
    /// and dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.
    /// If the namespace is specified, then dataSourceRef will not be copied to dataSource.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataSource")]
    pub data_source: Option<ClusterTablespacesStoragePvcTemplateDataSource>,
    /// dataSourceRef specifies the object from which to populate the volume with data, if a non-empty
    /// volume is desired. This may be any object from a non-empty API group (non
    /// core object) or a PersistentVolumeClaim object.
    /// When this field is specified, volume binding will only succeed if the type of
    /// the specified object matches some installed volume populator or dynamic
    /// provisioner.
    /// This field will replace the functionality of the dataSource field and as such
    /// if both fields are non-empty, they must have the same value. For backwards
    /// compatibility, when namespace isn't specified in dataSourceRef,
    /// both fields (dataSource and dataSourceRef) will be set to the same
    /// value automatically if one of them is empty and the other is non-empty.
    /// When namespace is specified in dataSourceRef,
    /// dataSource isn't set to the same value and must be empty.
    /// There are three important differences between dataSource and dataSourceRef:
    /// * While dataSource only allows two specific types of objects, dataSourceRef
    ///   allows any non-core object, as well as PersistentVolumeClaim objects.
    /// * While dataSource ignores disallowed values (dropping them), dataSourceRef
    ///   preserves all values, and generates an error if a disallowed value is
    ///   specified.
    /// * While dataSource only allows local objects, dataSourceRef allows objects
    ///   in any namespaces.
    /// (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
    /// (Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataSourceRef")]
    pub data_source_ref: Option<ClusterTablespacesStoragePvcTemplateDataSourceRef>,
    /// resources represents the minimum resources the volume should have.
    /// If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements
    /// that are lower than previous value but must still be higher than capacity recorded in the
    /// status field of the claim.
    /// More info: <https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resources: Option<ClusterTablespacesStoragePvcTemplateResources>,
    /// selector is a label query over volumes to consider for binding.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selector: Option<ClusterTablespacesStoragePvcTemplateSelector>,
    /// storageClassName is the name of the StorageClass required by the claim.
    /// More info: <https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "storageClassName")]
    pub storage_class_name: Option<String>,
    /// volumeAttributesClassName may be used to set the VolumeAttributesClass used by this claim.
    /// If specified, the CSI driver will create or update the volume with the attributes defined
    /// in the corresponding VolumeAttributesClass. This has a different purpose than storageClassName,
    /// it can be changed after the claim is created. An empty string or nil value indicates that no
    /// VolumeAttributesClass will be applied to the claim. If the claim enters an Infeasible error state,
    /// this field can be reset to its previous value (including nil) to cancel the modification.
    /// If the resource referred to by volumeAttributesClass does not exist, this PersistentVolumeClaim will be
    /// set to a Pending state, as reflected by the modifyVolumeStatus field, until such as a resource
    /// exists.
    /// More info: <https://kubernetes.io/docs/concepts/storage/volume-attributes-classes/>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeAttributesClassName")]
    pub volume_attributes_class_name: Option<String>,
    /// volumeMode defines what type of volume is required by the claim.
    /// Value of Filesystem is implied when not included in claim spec.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeMode")]
    pub volume_mode: Option<String>,
    /// volumeName is the binding reference to the PersistentVolume backing this claim.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeName")]
    pub volume_name: Option<String>,
}

/// dataSource field can be used to specify either:
/// * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)
/// * An existing PVC (PersistentVolumeClaim)
/// If the provisioner or an external controller can support the specified data source,
/// it will create a new volume based on the contents of the specified data source.
/// When the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,
/// and dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.
/// If the namespace is specified, then dataSourceRef will not be copied to dataSource.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterTablespacesStoragePvcTemplateDataSource {
    /// APIGroup is the group for the resource being referenced.
    /// If APIGroup is not specified, the specified Kind must be in the core API group.
    /// For any other third-party types, APIGroup is required.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiGroup")]
    pub api_group: Option<String>,
    /// Kind is the type of resource being referenced
    pub kind: String,
    /// Name is the name of resource being referenced
    pub name: String,
}

/// dataSourceRef specifies the object from which to populate the volume with data, if a non-empty
/// volume is desired. This may be any object from a non-empty API group (non
/// core object) or a PersistentVolumeClaim object.
/// When this field is specified, volume binding will only succeed if the type of
/// the specified object matches some installed volume populator or dynamic
/// provisioner.
/// This field will replace the functionality of the dataSource field and as such
/// if both fields are non-empty, they must have the same value. For backwards
/// compatibility, when namespace isn't specified in dataSourceRef,
/// both fields (dataSource and dataSourceRef) will be set to the same
/// value automatically if one of them is empty and the other is non-empty.
/// When namespace is specified in dataSourceRef,
/// dataSource isn't set to the same value and must be empty.
/// There are three important differences between dataSource and dataSourceRef:
/// * While dataSource only allows two specific types of objects, dataSourceRef
///   allows any non-core object, as well as PersistentVolumeClaim objects.
/// * While dataSource ignores disallowed values (dropping them), dataSourceRef
///   preserves all values, and generates an error if a disallowed value is
///   specified.
/// * While dataSource only allows local objects, dataSourceRef allows objects
///   in any namespaces.
/// (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
/// (Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterTablespacesStoragePvcTemplateDataSourceRef {
    /// APIGroup is the group for the resource being referenced.
    /// If APIGroup is not specified, the specified Kind must be in the core API group.
    /// For any other third-party types, APIGroup is required.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiGroup")]
    pub api_group: Option<String>,
    /// Kind is the type of resource being referenced
    pub kind: String,
    /// Name is the name of resource being referenced
    pub name: String,
    /// Namespace is the namespace of resource being referenced
    /// Note that when a namespace is specified, a gateway.networking.k8s.io/ReferenceGrant object is required in the referent namespace to allow that namespace's owner to accept the reference. See the ReferenceGrant documentation for details.
    /// (Alpha) This field requires the CrossNamespaceVolumeDataSource feature gate to be enabled.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
}

/// resources represents the minimum resources the volume should have.
/// If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements
/// that are lower than previous value but must still be higher than capacity recorded in the
/// status field of the claim.
/// More info: <https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterTablespacesStoragePvcTemplateResources {
    /// Limits describes the maximum amount of compute resources allowed.
    /// More info: <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub limits: Option<BTreeMap<String, IntOrString>>,
    /// Requests describes the minimum amount of compute resources required.
    /// If Requests is omitted for a container, it defaults to Limits if that is explicitly specified,
    /// otherwise to an implementation-defined value. Requests cannot exceed Limits.
    /// More info: <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub requests: Option<BTreeMap<String, IntOrString>>,
}

/// selector is a label query over volumes to consider for binding.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterTablespacesStoragePvcTemplateSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterTablespacesStoragePvcTemplateSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterTablespacesStoragePvcTemplateSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// TopologySpreadConstraint specifies how to spread matching pods among the given topology.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterTopologySpreadConstraints {
    /// LabelSelector is used to find matching pods.
    /// Pods that match this label selector are counted to determine the number of pods
    /// in their corresponding topology domain.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<ClusterTopologySpreadConstraintsLabelSelector>,
    /// MatchLabelKeys is a set of pod label keys to select the pods over which
    /// spreading will be calculated. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are ANDed with labelSelector
    /// to select the group of existing pods over which spreading will be calculated
    /// for the incoming pod. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector.
    /// MatchLabelKeys cannot be set when LabelSelector isn't set.
    /// Keys that don't exist in the incoming pod labels will
    /// be ignored. A null or empty list means only match against labelSelector.
    /// 
    /// This is a beta field and requires the MatchLabelKeysInPodTopologySpread feature gate to be enabled (enabled by default).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    /// MaxSkew describes the degree to which pods may be unevenly distributed.
    /// When `whenUnsatisfiable=DoNotSchedule`, it is the maximum permitted difference
    /// between the number of matching pods in the target topology and the global minimum.
    /// The global minimum is the minimum number of matching pods in an eligible domain
    /// or zero if the number of eligible domains is less than MinDomains.
    /// For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same
    /// labelSelector spread as 2/2/1:
    /// In this case, the global minimum is 1.
    /// | zone1 | zone2 | zone3 |
    /// |  P P  |  P P  |   P   |
    /// - if MaxSkew is 1, incoming pod can only be scheduled to zone3 to become 2/2/2;
    /// scheduling it onto zone1(zone2) would make the ActualSkew(3-1) on zone1(zone2)
    /// violate MaxSkew(1).
    /// - if MaxSkew is 2, incoming pod can be scheduled onto any zone.
    /// When `whenUnsatisfiable=ScheduleAnyway`, it is used to give higher precedence
    /// to topologies that satisfy it.
    /// It's a required field. Default value is 1 and 0 is not allowed.
    #[serde(rename = "maxSkew")]
    pub max_skew: i32,
    /// MinDomains indicates a minimum number of eligible domains.
    /// When the number of eligible domains with matching topology keys is less than minDomains,
    /// Pod Topology Spread treats "global minimum" as 0, and then the calculation of Skew is performed.
    /// And when the number of eligible domains with matching topology keys equals or greater than minDomains,
    /// this value has no effect on scheduling.
    /// As a result, when the number of eligible domains is less than minDomains,
    /// scheduler won't schedule more than maxSkew Pods to those domains.
    /// If value is nil, the constraint behaves as if MinDomains is equal to 1.
    /// Valid values are integers greater than 0.
    /// When value is not nil, WhenUnsatisfiable must be DoNotSchedule.
    /// 
    /// For example, in a 3-zone cluster, MaxSkew is set to 2, MinDomains is set to 5 and pods with the same
    /// labelSelector spread as 2/2/2:
    /// | zone1 | zone2 | zone3 |
    /// |  P P  |  P P  |  P P  |
    /// The number of domains is less than 5(MinDomains), so "global minimum" is treated as 0.
    /// In this situation, new pod with the same labelSelector cannot be scheduled,
    /// because computed skew will be 3(3 - 0) if new Pod is scheduled to any of the three zones,
    /// it will violate MaxSkew.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "minDomains")]
    pub min_domains: Option<i32>,
    /// NodeAffinityPolicy indicates how we will treat Pod's nodeAffinity/nodeSelector
    /// when calculating pod topology spread skew. Options are:
    /// - Honor: only nodes matching nodeAffinity/nodeSelector are included in the calculations.
    /// - Ignore: nodeAffinity/nodeSelector are ignored. All nodes are included in the calculations.
    /// 
    /// If this value is nil, the behavior is equivalent to the Honor policy.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeAffinityPolicy")]
    pub node_affinity_policy: Option<String>,
    /// NodeTaintsPolicy indicates how we will treat node taints when calculating
    /// pod topology spread skew. Options are:
    /// - Honor: nodes without taints, along with tainted nodes for which the incoming pod
    /// has a toleration, are included.
    /// - Ignore: node taints are ignored. All nodes are included.
    /// 
    /// If this value is nil, the behavior is equivalent to the Ignore policy.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeTaintsPolicy")]
    pub node_taints_policy: Option<String>,
    /// TopologyKey is the key of node labels. Nodes that have a label with this key
    /// and identical values are considered to be in the same topology.
    /// We consider each <key, value> as a "bucket", and try to put balanced number
    /// of pods into each bucket.
    /// We define a domain as a particular instance of a topology.
    /// Also, we define an eligible domain as a domain whose nodes meet the requirements of
    /// nodeAffinityPolicy and nodeTaintsPolicy.
    /// e.g. If TopologyKey is "kubernetes.io/hostname", each Node is a domain of that topology.
    /// And, if TopologyKey is "topology.kubernetes.io/zone", each zone is a domain of that topology.
    /// It's a required field.
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
    /// WhenUnsatisfiable indicates how to deal with a pod if it doesn't satisfy
    /// the spread constraint.
    /// - DoNotSchedule (default) tells the scheduler not to schedule it.
    /// - ScheduleAnyway tells the scheduler to schedule the pod in any location,
    ///   but giving higher precedence to topologies that would help reduce the
    ///   skew.
    /// A constraint is considered "Unsatisfiable" for an incoming pod
    /// if and only if every possible node assignment for that pod would violate
    /// "MaxSkew" on some topology.
    /// For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same
    /// labelSelector spread as 3/1/1:
    /// | zone1 | zone2 | zone3 |
    /// | P P P |   P   |   P   |
    /// If WhenUnsatisfiable is set to DoNotSchedule, incoming pod can only be scheduled
    /// to zone2(zone3) to become 3/2/1(3/1/2) as ActualSkew(2-1) on zone2(zone3) satisfies
    /// MaxSkew(1). In other words, the cluster can still be imbalanced, but scheduler
    /// won't make it *more* imbalanced.
    /// It's a required field.
    #[serde(rename = "whenUnsatisfiable")]
    pub when_unsatisfiable: String,
}

/// LabelSelector is used to find matching pods.
/// Pods that match this label selector are counted to determine the number of pods
/// in their corresponding topology domain.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterTopologySpreadConstraintsLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterTopologySpreadConstraintsLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterTopologySpreadConstraintsLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Configuration of the storage for PostgreSQL WAL (Write-Ahead Log)
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterWalStorage {
    /// Template to be used to generate the Persistent Volume Claim
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "pvcTemplate")]
    pub pvc_template: Option<ClusterWalStoragePvcTemplate>,
    /// Resize existent PVCs, defaults to true
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "resizeInUseVolumes")]
    pub resize_in_use_volumes: Option<bool>,
    /// Size of the storage. Required if not already specified in the PVC template.
    /// Changes to this field are automatically reapplied to the created PVCs.
    /// Size cannot be decreased.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub size: Option<String>,
    /// StorageClass to use for PVCs. Applied after
    /// evaluating the PVC template, if available.
    /// If not specified, the generated PVCs will use the
    /// default storage class
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "storageClass")]
    pub storage_class: Option<String>,
}

/// Template to be used to generate the Persistent Volume Claim
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterWalStoragePvcTemplate {
    /// accessModes contains the desired access modes the volume should have.
    /// More info: <https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "accessModes")]
    pub access_modes: Option<Vec<String>>,
    /// dataSource field can be used to specify either:
    /// * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)
    /// * An existing PVC (PersistentVolumeClaim)
    /// If the provisioner or an external controller can support the specified data source,
    /// it will create a new volume based on the contents of the specified data source.
    /// When the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,
    /// and dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.
    /// If the namespace is specified, then dataSourceRef will not be copied to dataSource.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataSource")]
    pub data_source: Option<ClusterWalStoragePvcTemplateDataSource>,
    /// dataSourceRef specifies the object from which to populate the volume with data, if a non-empty
    /// volume is desired. This may be any object from a non-empty API group (non
    /// core object) or a PersistentVolumeClaim object.
    /// When this field is specified, volume binding will only succeed if the type of
    /// the specified object matches some installed volume populator or dynamic
    /// provisioner.
    /// This field will replace the functionality of the dataSource field and as such
    /// if both fields are non-empty, they must have the same value. For backwards
    /// compatibility, when namespace isn't specified in dataSourceRef,
    /// both fields (dataSource and dataSourceRef) will be set to the same
    /// value automatically if one of them is empty and the other is non-empty.
    /// When namespace is specified in dataSourceRef,
    /// dataSource isn't set to the same value and must be empty.
    /// There are three important differences between dataSource and dataSourceRef:
    /// * While dataSource only allows two specific types of objects, dataSourceRef
    ///   allows any non-core object, as well as PersistentVolumeClaim objects.
    /// * While dataSource ignores disallowed values (dropping them), dataSourceRef
    ///   preserves all values, and generates an error if a disallowed value is
    ///   specified.
    /// * While dataSource only allows local objects, dataSourceRef allows objects
    ///   in any namespaces.
    /// (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
    /// (Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataSourceRef")]
    pub data_source_ref: Option<ClusterWalStoragePvcTemplateDataSourceRef>,
    /// resources represents the minimum resources the volume should have.
    /// If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements
    /// that are lower than previous value but must still be higher than capacity recorded in the
    /// status field of the claim.
    /// More info: <https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resources: Option<ClusterWalStoragePvcTemplateResources>,
    /// selector is a label query over volumes to consider for binding.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selector: Option<ClusterWalStoragePvcTemplateSelector>,
    /// storageClassName is the name of the StorageClass required by the claim.
    /// More info: <https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "storageClassName")]
    pub storage_class_name: Option<String>,
    /// volumeAttributesClassName may be used to set the VolumeAttributesClass used by this claim.
    /// If specified, the CSI driver will create or update the volume with the attributes defined
    /// in the corresponding VolumeAttributesClass. This has a different purpose than storageClassName,
    /// it can be changed after the claim is created. An empty string or nil value indicates that no
    /// VolumeAttributesClass will be applied to the claim. If the claim enters an Infeasible error state,
    /// this field can be reset to its previous value (including nil) to cancel the modification.
    /// If the resource referred to by volumeAttributesClass does not exist, this PersistentVolumeClaim will be
    /// set to a Pending state, as reflected by the modifyVolumeStatus field, until such as a resource
    /// exists.
    /// More info: <https://kubernetes.io/docs/concepts/storage/volume-attributes-classes/>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeAttributesClassName")]
    pub volume_attributes_class_name: Option<String>,
    /// volumeMode defines what type of volume is required by the claim.
    /// Value of Filesystem is implied when not included in claim spec.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeMode")]
    pub volume_mode: Option<String>,
    /// volumeName is the binding reference to the PersistentVolume backing this claim.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "volumeName")]
    pub volume_name: Option<String>,
}

/// dataSource field can be used to specify either:
/// * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)
/// * An existing PVC (PersistentVolumeClaim)
/// If the provisioner or an external controller can support the specified data source,
/// it will create a new volume based on the contents of the specified data source.
/// When the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,
/// and dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.
/// If the namespace is specified, then dataSourceRef will not be copied to dataSource.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterWalStoragePvcTemplateDataSource {
    /// APIGroup is the group for the resource being referenced.
    /// If APIGroup is not specified, the specified Kind must be in the core API group.
    /// For any other third-party types, APIGroup is required.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiGroup")]
    pub api_group: Option<String>,
    /// Kind is the type of resource being referenced
    pub kind: String,
    /// Name is the name of resource being referenced
    pub name: String,
}

/// dataSourceRef specifies the object from which to populate the volume with data, if a non-empty
/// volume is desired. This may be any object from a non-empty API group (non
/// core object) or a PersistentVolumeClaim object.
/// When this field is specified, volume binding will only succeed if the type of
/// the specified object matches some installed volume populator or dynamic
/// provisioner.
/// This field will replace the functionality of the dataSource field and as such
/// if both fields are non-empty, they must have the same value. For backwards
/// compatibility, when namespace isn't specified in dataSourceRef,
/// both fields (dataSource and dataSourceRef) will be set to the same
/// value automatically if one of them is empty and the other is non-empty.
/// When namespace is specified in dataSourceRef,
/// dataSource isn't set to the same value and must be empty.
/// There are three important differences between dataSource and dataSourceRef:
/// * While dataSource only allows two specific types of objects, dataSourceRef
///   allows any non-core object, as well as PersistentVolumeClaim objects.
/// * While dataSource ignores disallowed values (dropping them), dataSourceRef
///   preserves all values, and generates an error if a disallowed value is
///   specified.
/// * While dataSource only allows local objects, dataSourceRef allows objects
///   in any namespaces.
/// (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
/// (Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterWalStoragePvcTemplateDataSourceRef {
    /// APIGroup is the group for the resource being referenced.
    /// If APIGroup is not specified, the specified Kind must be in the core API group.
    /// For any other third-party types, APIGroup is required.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiGroup")]
    pub api_group: Option<String>,
    /// Kind is the type of resource being referenced
    pub kind: String,
    /// Name is the name of resource being referenced
    pub name: String,
    /// Namespace is the namespace of resource being referenced
    /// Note that when a namespace is specified, a gateway.networking.k8s.io/ReferenceGrant object is required in the referent namespace to allow that namespace's owner to accept the reference. See the ReferenceGrant documentation for details.
    /// (Alpha) This field requires the CrossNamespaceVolumeDataSource feature gate to be enabled.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
}

/// resources represents the minimum resources the volume should have.
/// If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements
/// that are lower than previous value but must still be higher than capacity recorded in the
/// status field of the claim.
/// More info: <https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterWalStoragePvcTemplateResources {
    /// Limits describes the maximum amount of compute resources allowed.
    /// More info: <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub limits: Option<BTreeMap<String, IntOrString>>,
    /// Requests describes the minimum amount of compute resources required.
    /// If Requests is omitted for a container, it defaults to Limits if that is explicitly specified,
    /// otherwise to an implementation-defined value. Requests cannot exceed Limits.
    /// More info: <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub requests: Option<BTreeMap<String, IntOrString>>,
}

/// selector is a label query over volumes to consider for binding.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterWalStoragePvcTemplateSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterWalStoragePvcTemplateSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterWalStoragePvcTemplateSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Most recently observed status of the cluster. This data may not be up
/// to date. Populated by the system. Read-only.
/// More info: <https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStatus {
    /// AvailableArchitectures reports the available architectures of a cluster
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "availableArchitectures")]
    pub available_architectures: Option<Vec<ClusterStatusAvailableArchitectures>>,
    /// The configuration for the CA and related certificates, initialized with defaults.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub certificates: Option<ClusterStatusCertificates>,
    /// The commit hash number of which this operator running
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "cloudNativePGCommitHash")]
    pub cloud_native_pg_commit_hash: Option<String>,
    /// The hash of the binary of the operator
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "cloudNativePGOperatorHash")]
    pub cloud_native_pg_operator_hash: Option<String>,
    /// Conditions for cluster object
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub conditions: Option<Vec<Condition>>,
    /// The list of resource versions of the configmaps,
    /// managed by the operator. Every change here is done in the
    /// interest of the instance manager, which will refresh the
    /// configmap data
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configMapResourceVersion")]
    pub config_map_resource_version: Option<ClusterStatusConfigMapResourceVersion>,
    /// Current primary instance
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "currentPrimary")]
    pub current_primary: Option<String>,
    /// The timestamp when the primary was detected to be unhealthy
    /// This field is reported when `.spec.failoverDelay` is populated or during online upgrades
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "currentPrimaryFailingSinceTimestamp")]
    pub current_primary_failing_since_timestamp: Option<String>,
    /// The timestamp when the last actual promotion to primary has occurred
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "currentPrimaryTimestamp")]
    pub current_primary_timestamp: Option<String>,
    /// List of all the PVCs created by this cluster and still available
    /// which are not attached to a Pod
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "danglingPVC")]
    pub dangling_pvc: Option<Vec<String>>,
    /// DemotionToken is a JSON token containing the information
    /// from pg_controldata such as Database system identifier, Latest checkpoint's
    /// TimeLineID, Latest checkpoint's REDO location, Latest checkpoint's REDO
    /// WAL file, and Time of latest checkpoint
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "demotionToken")]
    pub demotion_token: Option<String>,
    /// The first recoverability point, stored as a date in RFC3339 format.
    /// This field is calculated from the content of FirstRecoverabilityPointByMethod.
    /// 
    /// Deprecated: the field is not set for backup plugins.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "firstRecoverabilityPoint")]
    pub first_recoverability_point: Option<String>,
    /// The first recoverability point, stored as a date in RFC3339 format, per backup method type.
    /// 
    /// Deprecated: the field is not set for backup plugins.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "firstRecoverabilityPointByMethod")]
    pub first_recoverability_point_by_method: Option<BTreeMap<String, String>>,
    /// List of all the PVCs not dangling nor initializing
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "healthyPVC")]
    pub healthy_pvc: Option<Vec<String>>,
    /// Image contains the image name used by the pods
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub image: Option<String>,
    /// List of all the PVCs that are being initialized by this cluster
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "initializingPVC")]
    pub initializing_pvc: Option<Vec<String>>,
    /// List of instance names in the cluster
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "instanceNames")]
    pub instance_names: Option<Vec<String>>,
    /// The total number of PVC Groups detected in the cluster. It may differ from the number of existing instance pods.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub instances: Option<i64>,
    /// The reported state of the instances during the last reconciliation loop
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "instancesReportedState")]
    pub instances_reported_state: Option<BTreeMap<String, ClusterStatusInstancesReportedState>>,
    /// InstancesStatus indicates in which status the instances are
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "instancesStatus")]
    pub instances_status: Option<BTreeMap<String, Vec<String>>>,
    /// How many Jobs have been created by this cluster
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jobCount")]
    pub job_count: Option<i32>,
    /// Last failed backup, stored as a date in RFC3339 format.
    /// 
    /// Deprecated: the field is not set for backup plugins.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "lastFailedBackup")]
    pub last_failed_backup: Option<String>,
    /// LastPromotionToken is the last verified promotion token that
    /// was used to promote a replica cluster
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "lastPromotionToken")]
    pub last_promotion_token: Option<String>,
    /// Last successful backup, stored as a date in RFC3339 format.
    /// This field is calculated from the content of LastSuccessfulBackupByMethod.
    /// 
    /// Deprecated: the field is not set for backup plugins.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "lastSuccessfulBackup")]
    pub last_successful_backup: Option<String>,
    /// Last successful backup, stored as a date in RFC3339 format, per backup method type.
    /// 
    /// Deprecated: the field is not set for backup plugins.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "lastSuccessfulBackupByMethod")]
    pub last_successful_backup_by_method: Option<BTreeMap<String, String>>,
    /// ID of the latest generated node (used to avoid node name clashing)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "latestGeneratedNode")]
    pub latest_generated_node: Option<i64>,
    /// ManagedRolesStatus reports the state of the managed roles in the cluster
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "managedRolesStatus")]
    pub managed_roles_status: Option<ClusterStatusManagedRolesStatus>,
    /// OnlineUpdateEnabled shows if the online upgrade is enabled inside the cluster
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "onlineUpdateEnabled")]
    pub online_update_enabled: Option<bool>,
    /// PGDataImageInfo contains the details of the latest image that has run on the current data directory.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "pgDataImageInfo")]
    pub pg_data_image_info: Option<ClusterStatusPgDataImageInfo>,
    /// Current phase of the cluster
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub phase: Option<String>,
    /// Reason for the current phase
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "phaseReason")]
    pub phase_reason: Option<String>,
    /// PluginStatus is the status of the loaded plugins
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "pluginStatus")]
    pub plugin_status: Option<Vec<ClusterStatusPluginStatus>>,
    /// The integration needed by poolers referencing the cluster
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "poolerIntegrations")]
    pub pooler_integrations: Option<ClusterStatusPoolerIntegrations>,
    /// How many PVCs have been created by this cluster
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "pvcCount")]
    pub pvc_count: Option<i32>,
    /// Current list of read pods
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "readService")]
    pub read_service: Option<String>,
    /// The total number of ready instances in the cluster. It is equal to the number of ready instance pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "readyInstances")]
    pub ready_instances: Option<i64>,
    /// List of all the PVCs that have ResizingPVC condition.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "resizingPVC")]
    pub resizing_pvc: Option<Vec<String>>,
    /// The list of resource versions of the secrets
    /// managed by the operator. Every change here is done in the
    /// interest of the instance manager, which will refresh the
    /// secret data
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "secretsResourceVersion")]
    pub secrets_resource_version: Option<ClusterStatusSecretsResourceVersion>,
    /// SwitchReplicaClusterStatus is the status of the switch to replica cluster
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "switchReplicaClusterStatus")]
    pub switch_replica_cluster_status: Option<ClusterStatusSwitchReplicaClusterStatus>,
    /// SystemID is the latest detected PostgreSQL SystemID
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "systemID")]
    pub system_id: Option<String>,
    /// TablespacesStatus reports the state of the declarative tablespaces in the cluster
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tablespacesStatus")]
    pub tablespaces_status: Option<Vec<ClusterStatusTablespacesStatus>>,
    /// Target primary instance, this is different from the previous one
    /// during a switchover or a failover
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "targetPrimary")]
    pub target_primary: Option<String>,
    /// The timestamp when the last request for a new primary has occurred
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "targetPrimaryTimestamp")]
    pub target_primary_timestamp: Option<String>,
    /// The timeline of the Postgres cluster
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "timelineID")]
    pub timeline_id: Option<i64>,
    /// Instances topology.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub topology: Option<ClusterStatusTopology>,
    /// List of all the PVCs that are unusable because another PVC is missing
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "unusablePVC")]
    pub unusable_pvc: Option<Vec<String>>,
    /// Current write pod
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeService")]
    pub write_service: Option<String>,
}

/// AvailableArchitecture represents the state of a cluster's architecture
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStatusAvailableArchitectures {
    /// GoArch is the name of the executable architecture
    #[serde(rename = "goArch")]
    pub go_arch: String,
    /// Hash is the hash of the executable
    pub hash: String,
}

/// The configuration for the CA and related certificates, initialized with defaults.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStatusCertificates {
    /// The secret containing the Client CA certificate. If not defined, a new secret will be created
    /// with a self-signed CA and will be used to generate all the client certificates.<br />
    /// <br />
    /// Contains:<br />
    /// <br />
    /// - `ca.crt`: CA that should be used to validate the client certificates,
    /// used as `ssl_ca_file` of all the instances.<br />
    /// - `ca.key`: key used to generate client certificates, if ReplicationTLSSecret is provided,
    /// this can be omitted.<br />
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clientCASecret")]
    pub client_ca_secret: Option<String>,
    /// Expiration dates for all certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub expirations: Option<BTreeMap<String, String>>,
    /// The secret of type kubernetes.io/tls containing the client certificate to authenticate as
    /// the `streaming_replica` user.
    /// If not defined, ClientCASecret must provide also `ca.key`, and a new secret will be
    /// created using the provided CA.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "replicationTLSSecret")]
    pub replication_tls_secret: Option<String>,
    /// The list of the server alternative DNS names to be added to the generated server TLS certificates, when required.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "serverAltDNSNames")]
    pub server_alt_dns_names: Option<Vec<String>>,
    /// The secret containing the Server CA certificate. If not defined, a new secret will be created
    /// with a self-signed CA and will be used to generate the TLS certificate ServerTLSSecret.<br />
    /// <br />
    /// Contains:<br />
    /// <br />
    /// - `ca.crt`: CA that should be used to validate the server certificate,
    /// used as `sslrootcert` in client connection strings.<br />
    /// - `ca.key`: key used to generate Server SSL certs, if ServerTLSSecret is provided,
    /// this can be omitted.<br />
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "serverCASecret")]
    pub server_ca_secret: Option<String>,
    /// The secret of type kubernetes.io/tls containing the server TLS certificate and key that will be set as
    /// `ssl_cert_file` and `ssl_key_file` so that clients can connect to postgres securely.
    /// If not defined, ServerCASecret must provide also `ca.key` and a new secret will be
    /// created using the provided CA.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "serverTLSSecret")]
    pub server_tls_secret: Option<String>,
}

/// The list of resource versions of the configmaps,
/// managed by the operator. Every change here is done in the
/// interest of the instance manager, which will refresh the
/// configmap data
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStatusConfigMapResourceVersion {
    /// A map with the versions of all the config maps used to pass metrics.
    /// Map keys are the config map names, map values are the versions
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metrics: Option<BTreeMap<String, String>>,
}

/// The reported state of the instances during the last reconciliation loop
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStatusInstancesReportedState {
    /// IP address of the instance
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub ip: Option<String>,
    /// indicates if an instance is the primary one
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "isPrimary")]
    pub is_primary: Option<bool>,
    /// indicates on which TimelineId the instance is
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "timeLineID")]
    pub time_line_id: Option<i64>,
}

/// ManagedRolesStatus reports the state of the managed roles in the cluster
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStatusManagedRolesStatus {
    /// ByStatus gives the list of roles in each state
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "byStatus")]
    pub by_status: Option<BTreeMap<String, Vec<String>>>,
    /// CannotReconcile lists roles that cannot be reconciled in PostgreSQL,
    /// with an explanation of the cause
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "cannotReconcile")]
    pub cannot_reconcile: Option<BTreeMap<String, Vec<String>>>,
    /// PasswordStatus gives the last transaction id and password secret version for each managed role
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "passwordStatus")]
    pub password_status: Option<BTreeMap<String, ClusterStatusManagedRolesStatusPasswordStatus>>,
}

/// PasswordStatus gives the last transaction id and password secret version for each managed role
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStatusManagedRolesStatusPasswordStatus {
    /// the resource version of the password secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "resourceVersion")]
    pub resource_version: Option<String>,
    /// the last transaction ID to affect the role definition in PostgreSQL
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "transactionID")]
    pub transaction_id: Option<i64>,
}

/// PGDataImageInfo contains the details of the latest image that has run on the current data directory.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStatusPgDataImageInfo {
    /// Image is the image name
    pub image: String,
    /// MajorVersion is the major version of the image
    #[serde(rename = "majorVersion")]
    pub major_version: i64,
}

/// PluginStatus is the status of a loaded plugin
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStatusPluginStatus {
    /// BackupCapabilities are the list of capabilities of the
    /// plugin regarding the Backup management
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "backupCapabilities")]
    pub backup_capabilities: Option<Vec<String>>,
    /// Capabilities are the list of capabilities of the
    /// plugin
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub capabilities: Option<Vec<String>>,
    /// Name is the name of the plugin
    pub name: String,
    /// OperatorCapabilities are the list of capabilities of the
    /// plugin regarding the reconciler
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "operatorCapabilities")]
    pub operator_capabilities: Option<Vec<String>>,
    /// RestoreJobHookCapabilities are the list of capabilities of the
    /// plugin regarding the RestoreJobHook management
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "restoreJobHookCapabilities")]
    pub restore_job_hook_capabilities: Option<Vec<String>>,
    /// Status contain the status reported by the plugin through the SetStatusInCluster interface
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub status: Option<String>,
    /// Version is the version of the plugin loaded by the
    /// latest reconciliation loop
    pub version: String,
    /// WALCapabilities are the list of capabilities of the
    /// plugin regarding the WAL management
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "walCapabilities")]
    pub wal_capabilities: Option<Vec<String>>,
}

/// The integration needed by poolers referencing the cluster
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStatusPoolerIntegrations {
    /// PgBouncerIntegrationStatus encapsulates the needed integration for the pgbouncer poolers referencing the cluster
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "pgBouncerIntegration")]
    pub pg_bouncer_integration: Option<ClusterStatusPoolerIntegrationsPgBouncerIntegration>,
}

/// PgBouncerIntegrationStatus encapsulates the needed integration for the pgbouncer poolers referencing the cluster
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStatusPoolerIntegrationsPgBouncerIntegration {
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub secrets: Option<Vec<String>>,
}

/// The list of resource versions of the secrets
/// managed by the operator. Every change here is done in the
/// interest of the instance manager, which will refresh the
/// secret data
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStatusSecretsResourceVersion {
    /// The resource version of the "app" user secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "applicationSecretVersion")]
    pub application_secret_version: Option<String>,
    /// The resource version of the Barman Endpoint CA if provided
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "barmanEndpointCA")]
    pub barman_endpoint_ca: Option<String>,
    /// Unused. Retained for compatibility with old versions.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "caSecretVersion")]
    pub ca_secret_version: Option<String>,
    /// The resource version of the PostgreSQL client-side CA secret version
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clientCaSecretVersion")]
    pub client_ca_secret_version: Option<String>,
    /// The resource versions of the external cluster secrets
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "externalClusterSecretVersion")]
    pub external_cluster_secret_version: Option<BTreeMap<String, String>>,
    /// The resource versions of the managed roles secrets
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "managedRoleSecretVersion")]
    pub managed_role_secret_version: Option<BTreeMap<String, String>>,
    /// A map with the versions of all the secrets used to pass metrics.
    /// Map keys are the secret names, map values are the versions
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metrics: Option<BTreeMap<String, String>>,
    /// The resource version of the "streaming_replica" user secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "replicationSecretVersion")]
    pub replication_secret_version: Option<String>,
    /// The resource version of the PostgreSQL server-side CA secret version
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "serverCaSecretVersion")]
    pub server_ca_secret_version: Option<String>,
    /// The resource version of the PostgreSQL server-side secret version
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "serverSecretVersion")]
    pub server_secret_version: Option<String>,
    /// The resource version of the "postgres" user secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "superuserSecretVersion")]
    pub superuser_secret_version: Option<String>,
}

/// SwitchReplicaClusterStatus is the status of the switch to replica cluster
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStatusSwitchReplicaClusterStatus {
    /// InProgress indicates if there is an ongoing procedure of switching a cluster to a replica cluster.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inProgress")]
    pub in_progress: Option<bool>,
}

/// TablespaceState represents the state of a tablespace in a cluster
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStatusTablespacesStatus {
    /// Error is the reconciliation error, if any
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub error: Option<String>,
    /// Name is the name of the tablespace
    pub name: String,
    /// Owner is the PostgreSQL user owning the tablespace
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub owner: Option<String>,
    /// State is the latest reconciliation state
    pub state: String,
}

/// Instances topology.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterStatusTopology {
    /// Instances contains the pod topology of the instances
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub instances: Option<BTreeMap<String, BTreeMap<String, String>>>,
    /// NodesUsed represents the count of distinct nodes accommodating the instances.
    /// A value of '1' suggests that all instances are hosted on a single node,
    /// implying the absence of High Availability (HA). Ideally, this value should
    /// be the same as the number of instances in the Postgres HA cluster, implying
    /// shared nothing architecture on the compute side.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodesUsed")]
    pub nodes_used: Option<i32>,
    /// SuccessfullyExtracted indicates if the topology data was extract. It is useful to enact fallback behaviors
    /// in synchronous replica election in case of failures
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "successfullyExtracted")]
    pub successfully_extracted: Option<bool>,
}

