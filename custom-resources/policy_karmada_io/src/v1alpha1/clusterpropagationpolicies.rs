// WARNING: generated by kopium - manual changes will be overwritten
// kopium command: kopium --docs --derive=Default --derive=PartialEq --smart-derive-elision --filename crd-catalog/karmada-io/karmada/policy.karmada.io/v1alpha1/clusterpropagationpolicies.yaml
// kopium version: 0.21.3

#[allow(unused_imports)]
mod prelude {
    pub use kube::CustomResource;
    pub use serde::{Serialize, Deserialize};
    pub use std::collections::BTreeMap;
}
use self::prelude::*;

/// Spec represents the desired behavior of ClusterPropagationPolicy.
#[derive(CustomResource, Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
#[kube(group = "policy.karmada.io", version = "v1alpha1", kind = "ClusterPropagationPolicy", plural = "clusterpropagationpolicies")]
#[kube(schema = "disabled")]
#[kube(derive="Default")]
#[kube(derive="PartialEq")]
pub struct ClusterPropagationPolicySpec {
    /// ActivationPreference indicates how the referencing resource template will
    /// be propagated, in case of policy changes.
    /// 
    /// If empty, the resource template will respond to policy changes
    /// immediately, in other words, any policy changes will drive the resource
    /// template to be propagated immediately as per the current propagation rules.
    /// 
    /// If the value is 'Lazy' means the policy changes will not take effect for now
    /// but defer to the resource template changes, in other words, the resource
    /// template will not be propagated as per the current propagation rules until
    /// there is an update on it.
    /// This is an experimental feature that might help in a scenario where a policy
    /// manages huge amount of resource templates, changes to a policy typically
    /// affect numerous applications simultaneously. A minor misconfiguration
    /// could lead to widespread failures. With this feature, the change can be
    /// gradually rolled out through iterative modifications of resource templates.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "activationPreference")]
    pub activation_preference: Option<ClusterPropagationPolicyActivationPreference>,
    /// Association tells if relevant resources should be selected automatically.
    /// e.g. a ConfigMap referred by a Deployment.
    /// default false.
    /// Deprecated: in favor of PropagateDeps.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub association: Option<bool>,
    /// ConflictResolution declares how potential conflict should be handled when
    /// a resource that is being propagated already exists in the target cluster.
    /// 
    /// It defaults to "Abort" which means stop propagating to avoid unexpected
    /// overwrites. The "Overwrite" might be useful when migrating legacy cluster
    /// resources to Karmada, in which case conflict is predictable and can be
    /// instructed to Karmada take over the resource by overwriting.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "conflictResolution")]
    pub conflict_resolution: Option<ClusterPropagationPolicyConflictResolution>,
    /// DependentOverrides represents the list of overrides(OverridePolicy)
    /// which must present before the current PropagationPolicy takes effect.
    /// 
    /// It used to explicitly specify overrides which current PropagationPolicy rely on.
    /// A typical scenario is the users create OverridePolicy(ies) and resources at the same time,
    /// they want to ensure the new-created policies would be adopted.
    /// 
    /// Note: For the overrides, OverridePolicy(ies) in current namespace and ClusterOverridePolicy(ies),
    /// which not present in this list will still be applied if they matches the resources.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dependentOverrides")]
    pub dependent_overrides: Option<Vec<String>>,
    /// Failover indicates how Karmada migrates applications in case of failures.
    /// If this value is nil, failover is disabled.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub failover: Option<ClusterPropagationPolicyFailover>,
    /// Placement represents the rule for select clusters to propagate resources.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub placement: Option<ClusterPropagationPolicyPlacement>,
    /// Preemption declares the behaviors for preempting.
    /// Valid options are "Always" and "Never".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub preemption: Option<ClusterPropagationPolicyPreemption>,
    /// PreserveResourcesOnDeletion controls whether resources should be preserved on the
    /// member clusters when the resource template is deleted.
    /// If set to true, resources will be preserved on the member clusters.
    /// Default is false, which means resources will be deleted along with the resource template.
    /// 
    /// This setting is particularly useful during workload migration scenarios to ensure
    /// that rollback can occur quickly without affecting the workloads running on the
    /// member clusters.
    /// 
    /// Additionally, this setting applies uniformly across all member clusters and will not
    /// selectively control preservation on only some clusters.
    /// 
    /// Note: This setting does not apply to the deletion of the policy itself.
    /// When the policy is deleted, the resource templates and their corresponding
    /// propagated resources in member clusters will remain unchanged unless explicitly deleted.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preserveResourcesOnDeletion")]
    pub preserve_resources_on_deletion: Option<bool>,
    /// Priority indicates the importance of a policy(PropagationPolicy or ClusterPropagationPolicy).
    /// A policy will be applied for the matched resource templates if there is
    /// no other policies with higher priority at the point of the resource
    /// template be processed.
    /// Once a resource template has been claimed by a policy, by default it will
    /// not be preempted by following policies even with a higher priority.
    /// See Preemption for more details.
    /// 
    /// In case of two policies have the same priority, the one with a more precise
    /// matching rules in ResourceSelectors wins:
    /// - matching by name(resourceSelector.name) has higher priority than
    ///   by selector(resourceSelector.labelSelector)
    /// - matching by selector(resourceSelector.labelSelector) has higher priority
    ///   than by APIVersion(resourceSelector.apiVersion) and Kind(resourceSelector.kind).
    /// If there is still no winner at this point, the one with the lower alphabetic
    /// order wins, e.g. policy 'bar' has higher priority than 'foo'.
    /// 
    /// The higher the value, the higher the priority. Defaults to zero.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub priority: Option<i32>,
    /// PropagateDeps tells if relevant resources should be propagated automatically.
    /// Take 'Deployment' which referencing 'ConfigMap' and 'Secret' as an example, when 'propagateDeps' is 'true',
    /// the referencing resources could be omitted(for saving config effort) from 'resourceSelectors' as they will be
    /// propagated along with the Deployment. In addition to the propagating process, the referencing resources will be
    /// migrated along with the Deployment in the fail-over scenario.
    /// 
    /// Defaults to false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "propagateDeps")]
    pub propagate_deps: Option<bool>,
    /// ResourceSelectors used to select resources.
    /// Nil or empty selector is not allowed and doesn't mean match all kinds
    /// of resources for security concerns that sensitive resources(like Secret)
    /// might be accidentally propagated.
    #[serde(rename = "resourceSelectors")]
    pub resource_selectors: Vec<ClusterPropagationPolicyResourceSelectors>,
    /// SchedulePriority defines how Karmada should resolve the priority and preemption policy
    /// for workload scheduling.
    /// 
    /// This setting is useful for controlling the scheduling behavior of offline workloads.
    /// By setting a higher or lower priority, users can control which workloads are scheduled first.
    /// Additionally, it allows specifying a preemption policy where higher-priority workloads can
    /// preempt lower-priority ones in scenarios of resource contention.
    /// 
    /// Note: This feature is currently in the alpha stage. The priority-based scheduling functionality is
    /// controlled by the PriorityBasedScheduling feature gate, and preemption is controlled by the
    /// PriorityBasedPreemptiveScheduling feature gate. Currently, only priority-based scheduling is
    /// supported. Preemption functionality is not yet available and will be introduced in future
    /// releases as the feature matures.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "schedulePriority")]
    pub schedule_priority: Option<ClusterPropagationPolicySchedulePriority>,
    /// SchedulerName represents which scheduler to proceed the scheduling.
    /// If specified, the policy will be dispatched by specified scheduler.
    /// If not specified, the policy will be dispatched by default scheduler.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "schedulerName")]
    pub scheduler_name: Option<String>,
    /// Suspension declares the policy for suspending different aspects of propagation.
    /// nil means no suspension. no default values.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub suspension: Option<ClusterPropagationPolicySuspension>,
}

/// Spec represents the desired behavior of ClusterPropagationPolicy.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterPropagationPolicyActivationPreference {
    Lazy,
}

/// Spec represents the desired behavior of ClusterPropagationPolicy.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterPropagationPolicyConflictResolution {
    Abort,
    Overwrite,
}

/// Failover indicates how Karmada migrates applications in case of failures.
/// If this value is nil, failover is disabled.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyFailover {
    /// Application indicates failover behaviors in case of application failure.
    /// If this value is nil, failover is disabled.
    /// If set, the PropagateDeps should be true so that the dependencies could
    /// be migrated along with the application.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub application: Option<ClusterPropagationPolicyFailoverApplication>,
    /// Cluster indicates failover behaviors in case of cluster failure.
    /// If this value is nil, the failover behavior in case of cluster failure
    /// will be controlled by the controller's no-execute-taint-eviction-purge-mode
    /// parameter.
    /// If set, the failover behavior in case of cluster failure will be defined
    /// by this value.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub cluster: Option<ClusterPropagationPolicyFailoverCluster>,
}

/// Application indicates failover behaviors in case of application failure.
/// If this value is nil, failover is disabled.
/// If set, the PropagateDeps should be true so that the dependencies could
/// be migrated along with the application.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyFailoverApplication {
    /// DecisionConditions indicates the decision conditions of performing the failover process.
    /// Only when all conditions are met can the failover process be performed.
    /// Currently, DecisionConditions includes several conditions:
    /// - TolerationSeconds (optional)
    #[serde(rename = "decisionConditions")]
    pub decision_conditions: ClusterPropagationPolicyFailoverApplicationDecisionConditions,
    /// GracePeriodSeconds is the maximum waiting duration in seconds before
    /// application on the migrated cluster should be deleted.
    /// Required only when PurgeMode is "Graciously" and defaults to 600s.
    /// If the application on the new cluster cannot reach a Healthy state,
    /// Karmada will delete the application after GracePeriodSeconds is reached.
    /// Value must be positive integer.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "gracePeriodSeconds")]
    pub grace_period_seconds: Option<i32>,
    /// PurgeMode represents how to deal with the legacy applications on the
    /// cluster from which the application is migrated.
    /// Valid options are "Directly", "Gracefully", "Never", "Immediately"(deprecated),
    /// and "Graciously"(deprecated).
    /// Defaults to "Gracefully".
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "purgeMode")]
    pub purge_mode: Option<ClusterPropagationPolicyFailoverApplicationPurgeMode>,
    /// StatePreservation defines the policy for preserving and restoring state data
    /// during failover events for stateful applications.
    /// 
    /// When an application fails over from one cluster to another, this policy enables
    /// the extraction of critical data from the original resource configuration.
    /// Upon successful migration, the extracted data is then re-injected into the new
    /// resource, ensuring that the application can resume operation with its previous
    /// state intact.
    /// This is particularly useful for stateful applications where maintaining data
    /// consistency across failover events is crucial.
    /// If not specified, means no state data will be preserved.
    /// 
    /// Note: This requires the StatefulFailoverInjection feature gate to be enabled,
    /// which is alpha.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "statePreservation")]
    pub state_preservation: Option<ClusterPropagationPolicyFailoverApplicationStatePreservation>,
}

/// DecisionConditions indicates the decision conditions of performing the failover process.
/// Only when all conditions are met can the failover process be performed.
/// Currently, DecisionConditions includes several conditions:
/// - TolerationSeconds (optional)
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyFailoverApplicationDecisionConditions {
    /// TolerationSeconds represents the period of time Karmada should wait
    /// after reaching the desired state before performing failover process.
    /// If not specified, Karmada will immediately perform failover process.
    /// Defaults to 300s.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tolerationSeconds")]
    pub toleration_seconds: Option<i32>,
}

/// Application indicates failover behaviors in case of application failure.
/// If this value is nil, failover is disabled.
/// If set, the PropagateDeps should be true so that the dependencies could
/// be migrated along with the application.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterPropagationPolicyFailoverApplicationPurgeMode {
    Directly,
    Gracefully,
    Never,
    Immediately,
    Graciously,
}

/// StatePreservation defines the policy for preserving and restoring state data
/// during failover events for stateful applications.
/// 
/// When an application fails over from one cluster to another, this policy enables
/// the extraction of critical data from the original resource configuration.
/// Upon successful migration, the extracted data is then re-injected into the new
/// resource, ensuring that the application can resume operation with its previous
/// state intact.
/// This is particularly useful for stateful applications where maintaining data
/// consistency across failover events is crucial.
/// If not specified, means no state data will be preserved.
/// 
/// Note: This requires the StatefulFailoverInjection feature gate to be enabled,
/// which is alpha.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyFailoverApplicationStatePreservation {
    /// Rules contains a list of StatePreservationRule configurations.
    /// Each rule specifies a JSONPath expression targeting specific pieces of
    /// state data to be preserved during failover events. An AliasLabelName is associated
    /// with each rule, serving as a label key when the preserved data is passed
    /// to the new cluster.
    pub rules: Vec<ClusterPropagationPolicyFailoverApplicationStatePreservationRules>,
}

/// StatePreservationRule defines a single rule for state preservation.
/// It includes a JSONPath expression and an alias name that will be used
/// as a label key when passing state information to the new cluster.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyFailoverApplicationStatePreservationRules {
    /// AliasLabelName is the name that will be used as a label key when the preserved
    /// data is passed to the new cluster. This facilitates the injection of the
    /// preserved state back into the application resources during recovery.
    #[serde(rename = "aliasLabelName")]
    pub alias_label_name: String,
    /// JSONPath is the JSONPath template used to identify the state data
    /// to be preserved from the original resource configuration.
    /// The JSONPath syntax follows the Kubernetes specification:
    /// <https://kubernetes.io/docs/reference/kubectl/jsonpath/>
    /// 
    /// Note: The JSONPath expression will start searching from the "status" field of
    /// the API resource object by default. For example, to extract the "availableReplicas"
    /// from a Deployment, the JSONPath expression should be "{.availableReplicas}", not
    /// "{.status.availableReplicas}".
    #[serde(rename = "jsonPath")]
    pub json_path: String,
}

/// Cluster indicates failover behaviors in case of cluster failure.
/// If this value is nil, the failover behavior in case of cluster failure
/// will be controlled by the controller's no-execute-taint-eviction-purge-mode
/// parameter.
/// If set, the failover behavior in case of cluster failure will be defined
/// by this value.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyFailoverCluster {
    /// PurgeMode represents how to deal with the legacy applications on the
    /// cluster from which the application is migrated.
    /// Valid options are "Directly", "Gracefully".
    /// Defaults to "Gracefully".
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "purgeMode")]
    pub purge_mode: Option<ClusterPropagationPolicyFailoverClusterPurgeMode>,
    /// StatePreservation defines the policy for preserving and restoring state data
    /// during failover events for stateful applications.
    /// 
    /// When an application fails over from one cluster to another, this policy enables
    /// the extraction of critical data from the original resource configuration.
    /// Upon successful migration, the extracted data is then re-injected into the new
    /// resource, ensuring that the application can resume operation with its previous
    /// state intact.
    /// This is particularly useful for stateful applications where maintaining data
    /// consistency across failover events is crucial.
    /// If not specified, means no state data will be preserved.
    /// 
    /// Note: This requires the StatefulFailoverInjection feature gate to be enabled,
    /// which is alpha.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "statePreservation")]
    pub state_preservation: Option<ClusterPropagationPolicyFailoverClusterStatePreservation>,
}

/// Cluster indicates failover behaviors in case of cluster failure.
/// If this value is nil, the failover behavior in case of cluster failure
/// will be controlled by the controller's no-execute-taint-eviction-purge-mode
/// parameter.
/// If set, the failover behavior in case of cluster failure will be defined
/// by this value.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterPropagationPolicyFailoverClusterPurgeMode {
    Directly,
    Gracefully,
}

/// StatePreservation defines the policy for preserving and restoring state data
/// during failover events for stateful applications.
/// 
/// When an application fails over from one cluster to another, this policy enables
/// the extraction of critical data from the original resource configuration.
/// Upon successful migration, the extracted data is then re-injected into the new
/// resource, ensuring that the application can resume operation with its previous
/// state intact.
/// This is particularly useful for stateful applications where maintaining data
/// consistency across failover events is crucial.
/// If not specified, means no state data will be preserved.
/// 
/// Note: This requires the StatefulFailoverInjection feature gate to be enabled,
/// which is alpha.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyFailoverClusterStatePreservation {
    /// Rules contains a list of StatePreservationRule configurations.
    /// Each rule specifies a JSONPath expression targeting specific pieces of
    /// state data to be preserved during failover events. An AliasLabelName is associated
    /// with each rule, serving as a label key when the preserved data is passed
    /// to the new cluster.
    pub rules: Vec<ClusterPropagationPolicyFailoverClusterStatePreservationRules>,
}

/// StatePreservationRule defines a single rule for state preservation.
/// It includes a JSONPath expression and an alias name that will be used
/// as a label key when passing state information to the new cluster.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyFailoverClusterStatePreservationRules {
    /// AliasLabelName is the name that will be used as a label key when the preserved
    /// data is passed to the new cluster. This facilitates the injection of the
    /// preserved state back into the application resources during recovery.
    #[serde(rename = "aliasLabelName")]
    pub alias_label_name: String,
    /// JSONPath is the JSONPath template used to identify the state data
    /// to be preserved from the original resource configuration.
    /// The JSONPath syntax follows the Kubernetes specification:
    /// <https://kubernetes.io/docs/reference/kubectl/jsonpath/>
    /// 
    /// Note: The JSONPath expression will start searching from the "status" field of
    /// the API resource object by default. For example, to extract the "availableReplicas"
    /// from a Deployment, the JSONPath expression should be "{.availableReplicas}", not
    /// "{.status.availableReplicas}".
    #[serde(rename = "jsonPath")]
    pub json_path: String,
}

/// Placement represents the rule for select clusters to propagate resources.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacement {
    /// ClusterAffinities represents scheduling restrictions to multiple cluster
    /// groups that indicated by ClusterAffinityTerm.
    /// 
    /// The scheduler will evaluate these groups one by one in the order they
    /// appear in the spec, the group that does not satisfy scheduling restrictions
    /// will be ignored which means all clusters in this group will not be selected
    /// unless it also belongs to the next group(a cluster could belong to multiple
    /// groups).
    /// 
    /// If none of the groups satisfy the scheduling restrictions, then scheduling
    /// fails, which means no cluster will be selected.
    /// 
    /// Note:
    ///   1. ClusterAffinities can not co-exist with ClusterAffinity.
    ///   2. If both ClusterAffinity and ClusterAffinities are not set, any cluster
    ///      can be scheduling candidates.
    /// 
    /// Potential use case 1:
    /// The private clusters in the local data center could be the main group, and
    /// the managed clusters provided by cluster providers could be the secondary
    /// group. So that the Karmada scheduler would prefer to schedule workloads
    /// to the main group and the second group will only be considered in case of
    /// the main group does not satisfy restrictions(like, lack of resources).
    /// 
    /// Potential use case 2:
    /// For the disaster recovery scenario, the clusters could be organized to
    /// primary and backup groups, the workloads would be scheduled to primary
    /// clusters firstly, and when primary cluster fails(like data center power off),
    /// Karmada scheduler could migrate workloads to the backup clusters.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clusterAffinities")]
    pub cluster_affinities: Option<Vec<ClusterPropagationPolicyPlacementClusterAffinities>>,
    /// ClusterAffinity represents scheduling restrictions to a certain set of clusters.
    /// Note:
    ///   1. ClusterAffinity can not co-exist with ClusterAffinities.
    ///   2. If both ClusterAffinity and ClusterAffinities are not set, any cluster
    ///      can be scheduling candidates.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clusterAffinity")]
    pub cluster_affinity: Option<ClusterPropagationPolicyPlacementClusterAffinity>,
    /// ClusterTolerations represents the tolerations.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clusterTolerations")]
    pub cluster_tolerations: Option<Vec<ClusterPropagationPolicyPlacementClusterTolerations>>,
    /// ReplicaScheduling represents the scheduling policy on dealing with the number of replicas
    /// when propagating resources that have replicas in spec (e.g. deployments, statefulsets) to member clusters.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "replicaScheduling")]
    pub replica_scheduling: Option<ClusterPropagationPolicyPlacementReplicaScheduling>,
    /// SpreadConstraints represents a list of the scheduling constraints.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "spreadConstraints")]
    pub spread_constraints: Option<Vec<ClusterPropagationPolicyPlacementSpreadConstraints>>,
}

/// ClusterAffinityTerm selects a set of cluster.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementClusterAffinities {
    /// AffinityName is the name of the cluster group.
    #[serde(rename = "affinityName")]
    pub affinity_name: String,
    /// ClusterNames is the list of clusters to be selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clusterNames")]
    pub cluster_names: Option<Vec<String>>,
    /// ExcludedClusters is the list of clusters to be ignored.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub exclude: Option<Vec<String>>,
    /// FieldSelector is a filter to select member clusters by fields.
    /// The key(field) of the match expression should be 'provider', 'region', or 'zone',
    /// and the operator of the match expression should be 'In' or 'NotIn'.
    /// If non-nil and non-empty, only the clusters match this filter will be selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldSelector")]
    pub field_selector: Option<ClusterPropagationPolicyPlacementClusterAffinitiesFieldSelector>,
    /// LabelSelector is a filter to select member clusters by labels.
    /// If non-nil and non-empty, only the clusters match this filter will be selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<ClusterPropagationPolicyPlacementClusterAffinitiesLabelSelector>,
}

/// FieldSelector is a filter to select member clusters by fields.
/// The key(field) of the match expression should be 'provider', 'region', or 'zone',
/// and the operator of the match expression should be 'In' or 'NotIn'.
/// If non-nil and non-empty, only the clusters match this filter will be selected.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementClusterAffinitiesFieldSelector {
    /// A list of field selector requirements.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterPropagationPolicyPlacementClusterAffinitiesFieldSelectorMatchExpressions>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementClusterAffinitiesFieldSelectorMatchExpressions {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// LabelSelector is a filter to select member clusters by labels.
/// If non-nil and non-empty, only the clusters match this filter will be selected.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementClusterAffinitiesLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterPropagationPolicyPlacementClusterAffinitiesLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementClusterAffinitiesLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// ClusterAffinity represents scheduling restrictions to a certain set of clusters.
/// Note:
///   1. ClusterAffinity can not co-exist with ClusterAffinities.
///   2. If both ClusterAffinity and ClusterAffinities are not set, any cluster
///      can be scheduling candidates.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementClusterAffinity {
    /// ClusterNames is the list of clusters to be selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clusterNames")]
    pub cluster_names: Option<Vec<String>>,
    /// ExcludedClusters is the list of clusters to be ignored.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub exclude: Option<Vec<String>>,
    /// FieldSelector is a filter to select member clusters by fields.
    /// The key(field) of the match expression should be 'provider', 'region', or 'zone',
    /// and the operator of the match expression should be 'In' or 'NotIn'.
    /// If non-nil and non-empty, only the clusters match this filter will be selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldSelector")]
    pub field_selector: Option<ClusterPropagationPolicyPlacementClusterAffinityFieldSelector>,
    /// LabelSelector is a filter to select member clusters by labels.
    /// If non-nil and non-empty, only the clusters match this filter will be selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<ClusterPropagationPolicyPlacementClusterAffinityLabelSelector>,
}

/// FieldSelector is a filter to select member clusters by fields.
/// The key(field) of the match expression should be 'provider', 'region', or 'zone',
/// and the operator of the match expression should be 'In' or 'NotIn'.
/// If non-nil and non-empty, only the clusters match this filter will be selected.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementClusterAffinityFieldSelector {
    /// A list of field selector requirements.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterPropagationPolicyPlacementClusterAffinityFieldSelectorMatchExpressions>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementClusterAffinityFieldSelectorMatchExpressions {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// LabelSelector is a filter to select member clusters by labels.
/// If non-nil and non-empty, only the clusters match this filter will be selected.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementClusterAffinityLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterPropagationPolicyPlacementClusterAffinityLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementClusterAffinityLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// The pod this Toleration is attached to tolerates any taint that matches
/// the triple <key,value,effect> using the matching operator <operator>.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementClusterTolerations {
    /// Effect indicates the taint effect to match. Empty means match all taint effects.
    /// When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub effect: Option<String>,
    /// Key is the taint key that the toleration applies to. Empty means match all taint keys.
    /// If the key is empty, operator must be Exists; this combination means to match all values and all keys.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub key: Option<String>,
    /// Operator represents a key's relationship to the value.
    /// Valid operators are Exists and Equal. Defaults to Equal.
    /// Exists is equivalent to wildcard for value, so that a pod can
    /// tolerate all taints of a particular category.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub operator: Option<String>,
    /// TolerationSeconds represents the period of time the toleration (which must be
    /// of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,
    /// it is not set, which means tolerate the taint forever (do not evict). Zero and
    /// negative values will be treated as 0 (evict immediately) by the system.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tolerationSeconds")]
    pub toleration_seconds: Option<i64>,
    /// Value is the taint value the toleration matches to.
    /// If the operator is Exists, the value should be empty, otherwise just a regular string.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<String>,
}

/// ReplicaScheduling represents the scheduling policy on dealing with the number of replicas
/// when propagating resources that have replicas in spec (e.g. deployments, statefulsets) to member clusters.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementReplicaScheduling {
    /// ReplicaDivisionPreference determines how the replicas is divided
    /// when ReplicaSchedulingType is "Divided". Valid options are Aggregated and Weighted.
    /// "Aggregated" divides replicas into clusters as few as possible,
    /// while respecting clusters' resource availabilities during the division.
    /// "Weighted" divides replicas by weight according to WeightPreference.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "replicaDivisionPreference")]
    pub replica_division_preference: Option<ClusterPropagationPolicyPlacementReplicaSchedulingReplicaDivisionPreference>,
    /// ReplicaSchedulingType determines how the replicas is scheduled when karmada propagating
    /// a resource. Valid options are Duplicated and Divided.
    /// "Duplicated" duplicates the same replicas to each candidate member cluster from resource.
    /// "Divided" divides replicas into parts according to number of valid candidate member
    /// clusters, and exact replicas for each cluster are determined by ReplicaDivisionPreference.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "replicaSchedulingType")]
    pub replica_scheduling_type: Option<ClusterPropagationPolicyPlacementReplicaSchedulingReplicaSchedulingType>,
    /// WeightPreference describes weight for each cluster or for each group of cluster
    /// If ReplicaDivisionPreference is set to "Weighted", and WeightPreference is not set, scheduler will weight all clusters the same.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "weightPreference")]
    pub weight_preference: Option<ClusterPropagationPolicyPlacementReplicaSchedulingWeightPreference>,
}

/// ReplicaScheduling represents the scheduling policy on dealing with the number of replicas
/// when propagating resources that have replicas in spec (e.g. deployments, statefulsets) to member clusters.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterPropagationPolicyPlacementReplicaSchedulingReplicaDivisionPreference {
    Aggregated,
    Weighted,
}

/// ReplicaScheduling represents the scheduling policy on dealing with the number of replicas
/// when propagating resources that have replicas in spec (e.g. deployments, statefulsets) to member clusters.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterPropagationPolicyPlacementReplicaSchedulingReplicaSchedulingType {
    Duplicated,
    Divided,
}

/// WeightPreference describes weight for each cluster or for each group of cluster
/// If ReplicaDivisionPreference is set to "Weighted", and WeightPreference is not set, scheduler will weight all clusters the same.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementReplicaSchedulingWeightPreference {
    /// DynamicWeight specifies the factor to generates dynamic weight list.
    /// If specified, StaticWeightList will be ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dynamicWeight")]
    pub dynamic_weight: Option<ClusterPropagationPolicyPlacementReplicaSchedulingWeightPreferenceDynamicWeight>,
    /// StaticWeightList defines the static cluster weight.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "staticWeightList")]
    pub static_weight_list: Option<Vec<ClusterPropagationPolicyPlacementReplicaSchedulingWeightPreferenceStaticWeightList>>,
}

/// WeightPreference describes weight for each cluster or for each group of cluster
/// If ReplicaDivisionPreference is set to "Weighted", and WeightPreference is not set, scheduler will weight all clusters the same.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterPropagationPolicyPlacementReplicaSchedulingWeightPreferenceDynamicWeight {
    AvailableReplicas,
}

/// StaticClusterWeight defines the static cluster weight.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementReplicaSchedulingWeightPreferenceStaticWeightList {
    /// TargetCluster describes the filter to select clusters.
    #[serde(rename = "targetCluster")]
    pub target_cluster: ClusterPropagationPolicyPlacementReplicaSchedulingWeightPreferenceStaticWeightListTargetCluster,
    /// Weight expressing the preference to the cluster(s) specified by 'TargetCluster'.
    pub weight: i64,
}

/// TargetCluster describes the filter to select clusters.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementReplicaSchedulingWeightPreferenceStaticWeightListTargetCluster {
    /// ClusterNames is the list of clusters to be selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clusterNames")]
    pub cluster_names: Option<Vec<String>>,
    /// ExcludedClusters is the list of clusters to be ignored.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub exclude: Option<Vec<String>>,
    /// FieldSelector is a filter to select member clusters by fields.
    /// The key(field) of the match expression should be 'provider', 'region', or 'zone',
    /// and the operator of the match expression should be 'In' or 'NotIn'.
    /// If non-nil and non-empty, only the clusters match this filter will be selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldSelector")]
    pub field_selector: Option<ClusterPropagationPolicyPlacementReplicaSchedulingWeightPreferenceStaticWeightListTargetClusterFieldSelector>,
    /// LabelSelector is a filter to select member clusters by labels.
    /// If non-nil and non-empty, only the clusters match this filter will be selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<ClusterPropagationPolicyPlacementReplicaSchedulingWeightPreferenceStaticWeightListTargetClusterLabelSelector>,
}

/// FieldSelector is a filter to select member clusters by fields.
/// The key(field) of the match expression should be 'provider', 'region', or 'zone',
/// and the operator of the match expression should be 'In' or 'NotIn'.
/// If non-nil and non-empty, only the clusters match this filter will be selected.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementReplicaSchedulingWeightPreferenceStaticWeightListTargetClusterFieldSelector {
    /// A list of field selector requirements.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterPropagationPolicyPlacementReplicaSchedulingWeightPreferenceStaticWeightListTargetClusterFieldSelectorMatchExpressions>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementReplicaSchedulingWeightPreferenceStaticWeightListTargetClusterFieldSelectorMatchExpressions {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// LabelSelector is a filter to select member clusters by labels.
/// If non-nil and non-empty, only the clusters match this filter will be selected.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementReplicaSchedulingWeightPreferenceStaticWeightListTargetClusterLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterPropagationPolicyPlacementReplicaSchedulingWeightPreferenceStaticWeightListTargetClusterLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementReplicaSchedulingWeightPreferenceStaticWeightListTargetClusterLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// SpreadConstraint represents the spread constraints on resources.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyPlacementSpreadConstraints {
    /// MaxGroups restricts the maximum number of cluster groups to be selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxGroups")]
    pub max_groups: Option<i64>,
    /// MinGroups restricts the minimum number of cluster groups to be selected.
    /// Defaults to 1.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "minGroups")]
    pub min_groups: Option<i64>,
    /// SpreadByField represents the fields on Karmada cluster API used for
    /// dynamically grouping member clusters into different groups.
    /// Resources will be spread among different cluster groups.
    /// Available fields for spreading are: cluster, region, zone, and provider.
    /// SpreadByField should not co-exist with SpreadByLabel.
    /// If both SpreadByField and SpreadByLabel are empty, SpreadByField will be set to "cluster" by system.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "spreadByField")]
    pub spread_by_field: Option<ClusterPropagationPolicyPlacementSpreadConstraintsSpreadByField>,
    /// SpreadByLabel represents the label key used for
    /// grouping member clusters into different groups.
    /// Resources will be spread among different cluster groups.
    /// SpreadByLabel should not co-exist with SpreadByField.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "spreadByLabel")]
    pub spread_by_label: Option<String>,
}

/// SpreadConstraint represents the spread constraints on resources.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterPropagationPolicyPlacementSpreadConstraintsSpreadByField {
    #[serde(rename = "cluster")]
    Cluster,
    #[serde(rename = "region")]
    Region,
    #[serde(rename = "zone")]
    Zone,
    #[serde(rename = "provider")]
    Provider,
}

/// Spec represents the desired behavior of ClusterPropagationPolicy.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterPropagationPolicyPreemption {
    Always,
    Never,
}

/// ResourceSelector the resources will be selected.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyResourceSelectors {
    /// APIVersion represents the API version of the target resources.
    #[serde(rename = "apiVersion")]
    pub api_version: String,
    /// Kind represents the Kind of the target resources.
    pub kind: String,
    /// A label query over a set of resources.
    /// If name is not empty, labelSelector will be ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<ClusterPropagationPolicyResourceSelectorsLabelSelector>,
    /// Name of the target resource.
    /// Default is empty, which means selecting all resources.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the target resource.
    /// Default is empty, which means inherit from the parent object scope.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
}

/// A label query over a set of resources.
/// If name is not empty, labelSelector will be ignored.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyResourceSelectorsLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<ClusterPropagationPolicyResourceSelectorsLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicyResourceSelectorsLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// SchedulePriority defines how Karmada should resolve the priority and preemption policy
/// for workload scheduling.
/// 
/// This setting is useful for controlling the scheduling behavior of offline workloads.
/// By setting a higher or lower priority, users can control which workloads are scheduled first.
/// Additionally, it allows specifying a preemption policy where higher-priority workloads can
/// preempt lower-priority ones in scenarios of resource contention.
/// 
/// Note: This feature is currently in the alpha stage. The priority-based scheduling functionality is
/// controlled by the PriorityBasedScheduling feature gate, and preemption is controlled by the
/// PriorityBasedPreemptiveScheduling feature gate. Currently, only priority-based scheduling is
/// supported. Preemption functionality is not yet available and will be introduced in future
/// releases as the feature matures.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct ClusterPropagationPolicySchedulePriority {
    /// PriorityClassName specifies which PriorityClass to use. Its behavior depends on PriorityClassSource:
    /// 
    /// Behavior of PriorityClassName:
    /// 
    /// For KubePriorityClass:
    /// - When specified: Uses the named Kubernetes PriorityClass.
    /// 
    /// For PodPriorityClass:
    /// - Uses PriorityClassName from the PodTemplate.
    /// - Not yet implemented.
    /// 
    /// For FederatedPriorityClass:
    /// - Not yet implemented.
    #[serde(rename = "priorityClassName")]
    pub priority_class_name: String,
    /// PriorityClassSource specifies where Karmada should look for the PriorityClass definition.
    /// Available options:
    /// - KubePriorityClass: Uses Kubernetes PriorityClass (scheduling.k8s.io/v1)
    /// - PodPriorityClass: Uses PriorityClassName from PodTemplate: PodSpec.PriorityClassName (not yet implemented)
    /// - FederatedPriorityClass: Uses Karmada FederatedPriorityClass (not yet implemented)
    #[serde(rename = "priorityClassSource")]
    pub priority_class_source: ClusterPropagationPolicySchedulePriorityPriorityClassSource,
}

/// SchedulePriority defines how Karmada should resolve the priority and preemption policy
/// for workload scheduling.
/// 
/// This setting is useful for controlling the scheduling behavior of offline workloads.
/// By setting a higher or lower priority, users can control which workloads are scheduled first.
/// Additionally, it allows specifying a preemption policy where higher-priority workloads can
/// preempt lower-priority ones in scenarios of resource contention.
/// 
/// Note: This feature is currently in the alpha stage. The priority-based scheduling functionality is
/// controlled by the PriorityBasedScheduling feature gate, and preemption is controlled by the
/// PriorityBasedPreemptiveScheduling feature gate. Currently, only priority-based scheduling is
/// supported. Preemption functionality is not yet available and will be introduced in future
/// releases as the feature matures.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum ClusterPropagationPolicySchedulePriorityPriorityClassSource {
    KubePriorityClass,
}

/// Suspension declares the policy for suspending different aspects of propagation.
/// nil means no suspension. no default values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicySuspension {
    /// Dispatching controls whether dispatching should be suspended.
    /// nil means not suspend, no default value, only accepts 'true'.
    /// Note: true means stop propagating to all clusters. Can not co-exist
    /// with DispatchingOnClusters which is used to suspend particular clusters.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub dispatching: Option<bool>,
    /// DispatchingOnClusters declares a list of clusters to which the dispatching
    /// should be suspended.
    /// Note: Can not co-exist with Dispatching which is used to suspend all.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dispatchingOnClusters")]
    pub dispatching_on_clusters: Option<ClusterPropagationPolicySuspensionDispatchingOnClusters>,
}

/// DispatchingOnClusters declares a list of clusters to which the dispatching
/// should be suspended.
/// Note: Can not co-exist with Dispatching which is used to suspend all.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct ClusterPropagationPolicySuspensionDispatchingOnClusters {
    /// ClusterNames is the list of clusters to be selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clusterNames")]
    pub cluster_names: Option<Vec<String>>,
}

