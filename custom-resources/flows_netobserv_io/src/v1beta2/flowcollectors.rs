// WARNING: generated by kopium - manual changes will be overwritten
// kopium command: kopium --docs --derive=Default --derive=PartialEq --smart-derive-elision --filename crd-catalog/netobserv/network-observability-operator/flows.netobserv.io/v1beta2/flowcollectors.yaml
// kopium version: 0.22.5

#[allow(unused_imports)]
mod prelude {
    pub use kube::CustomResource;
    pub use serde::{Serialize, Deserialize};
    pub use std::collections::BTreeMap;
    pub use k8s_openapi::apimachinery::pkg::util::intstr::IntOrString;
    pub use k8s_openapi::apimachinery::pkg::apis::meta::v1::Condition;
}
use self::prelude::*;

/// Defines the desired state of the FlowCollector resource.
/// <br><br>
/// *: the mention of "unsupported" or "deprecated" for a feature throughout this document means that this feature
/// is not officially supported by Red Hat. It might have been, for example, contributed by the community
/// and accepted without a formal agreement for maintenance. The product maintainers might provide some support
/// for these features as a best effort only.
#[derive(CustomResource, Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
#[kube(group = "flows.netobserv.io", version = "v1beta2", kind = "FlowCollector", plural = "flowcollectors")]
#[kube(status = "FlowCollectorStatus")]
#[kube(schema = "disabled")]
#[kube(derive="Default")]
#[kube(derive="PartialEq")]
pub struct FlowCollectorSpec {
    /// Agent configuration for flows extraction.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub agent: Option<FlowCollectorAgent>,
    /// `consolePlugin` defines the settings related to the OpenShift Console plugin, when available.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "consolePlugin")]
    pub console_plugin: Option<FlowCollectorConsolePlugin>,
    /// `deploymentModel` defines the desired type of deployment for flow processing. Possible values are:<br>
    /// - `Service` (default) to make the flow processor listen as a Kubernetes Service, backed by a scalable Deployment.<br>
    /// - `Kafka` to make flows sent to a Kafka pipeline before consumption by the processor.<br>
    /// - `Direct` to make the flow processor listen directly from the agents using the host network, backed by a DaemonSet. Only recommended on small clusters, below 15 nodes.<br>
    /// Kafka can provide better scalability, resiliency, and high availability (for more details, see <https://www.redhat.com/en/topics/integration/what-is-apache-kafka).<br>>
    /// `Direct` is not recommended on large clusters as it is less memory efficient.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "deploymentModel")]
    pub deployment_model: Option<FlowCollectorDeploymentModel>,
    /// `exporters` defines additional optional exporters for custom consumption or storage.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub exporters: Option<Vec<FlowCollectorExporters>>,
    /// Kafka configuration, allowing to use Kafka as a broker as part of the flow collection pipeline. Available when the `spec.deploymentModel` is `Kafka`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub kafka: Option<FlowCollectorKafka>,
    /// `loki`, the flow store, client settings.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub loki: Option<FlowCollectorLoki>,
    /// Namespace where NetObserv pods are deployed.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// `networkPolicy` defines network policy settings for NetObserv components isolation.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "networkPolicy")]
    pub network_policy: Option<FlowCollectorNetworkPolicy>,
    /// `processor` defines the settings of the component that receives the flows from the agent,
    /// enriches them, generates metrics, and forwards them to the Loki persistence layer and/or any available exporter.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub processor: Option<FlowCollectorProcessor>,
    /// `prometheus` defines Prometheus settings, such as querier configuration used to fetch metrics from the Console plugin.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub prometheus: Option<FlowCollectorPrometheus>,
}

/// Agent configuration for flows extraction.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgent {
    /// `ebpf` describes the settings related to the eBPF-based flow reporter when `spec.agent.type`
    /// is set to `eBPF`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub ebpf: Option<FlowCollectorAgentEbpf>,
    /// `ipfix` [deprecated (*)] - describes the settings related to the IPFIX-based flow reporter when `spec.agent.type`
    /// is set to `IPFIX`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub ipfix: Option<FlowCollectorAgentIpfix>,
    /// `type` [deprecated (*)] selects the flows tracing agent. Previously, this field allowed to select between `eBPF` or `IPFIX`.
    /// Only `eBPF` is allowed now, so this field is deprecated and is planned for removal in a future version of the API.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorAgentType>,
}

/// `ebpf` describes the settings related to the eBPF-based flow reporter when `spec.agent.type`
/// is set to `eBPF`.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpf {
    /// `advanced` allows setting some aspects of the internal configuration of the eBPF agent.
    /// This section is aimed mostly for debugging and fine-grained performance optimizations,
    /// such as `GOGC` and `GOMAXPROCS` environment variables. Set these values at your own risk. You can also
    /// override the default Linux capabilities from there.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub advanced: Option<FlowCollectorAgentEbpfAdvanced>,
    /// `cacheActiveTimeout` is the max period during which the reporter aggregates flows before sending.
    /// Increasing `cacheMaxFlows` and `cacheActiveTimeout` can decrease the network traffic overhead and the CPU load,
    /// however you can expect higher memory consumption and an increased latency in the flow collection.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "cacheActiveTimeout")]
    pub cache_active_timeout: Option<String>,
    /// `cacheMaxFlows` is the max number of flows in an aggregate; when reached, the reporter sends the flows.
    /// Increasing `cacheMaxFlows` and `cacheActiveTimeout` can decrease the network traffic overhead and the CPU load,
    /// however you can expect higher memory consumption and an increased latency in the flow collection.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "cacheMaxFlows")]
    pub cache_max_flows: Option<i32>,
    /// `excludeInterfaces` contains the interface names that are excluded from flow tracing.
    /// An entry enclosed by slashes, such as `/br-/`, is matched as a regular expression.
    /// Otherwise it is matched as a case-sensitive string.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "excludeInterfaces")]
    pub exclude_interfaces: Option<Vec<String>>,
    /// List of additional features to enable. They are all disabled by default. Enabling additional features might have performance impacts. Possible values are:<br>
    /// - `PacketDrop`: Enable the packets drop flows logging feature. This feature requires mounting
    /// the kernel debug filesystem, so the eBPF agent pods must run as privileged via `spec.agent.ebpf.privileged`.<br>
    /// - `DNSTracking`: Enable the DNS tracking feature.<br>
    /// - `FlowRTT`: Enable flow latency (sRTT) extraction in the eBPF agent from TCP traffic.<br>
    /// - `NetworkEvents`: Enable the network events monitoring feature, such as correlating flows and network policies.
    /// This feature requires mounting the kernel debug filesystem, so the eBPF agent pods must run as privileged via `spec.agent.ebpf.privileged`.
    /// It requires using the OVN-Kubernetes network plugin with the Observability feature.
    /// IMPORTANT: This feature is available as a Technology Preview.<br>
    /// - `PacketTranslation`: Enable enriching flows with packet translation information, such as Service NAT.<br>
    /// - `EbpfManager`: [Unsupported (*)]. Use eBPF Manager to manage NetObserv eBPF programs. Pre-requisite: the eBPF Manager operator (or upstream bpfman operator) must be installed.<br>
    /// - `UDNMapping`: Enable interfaces mapping to User Defined Networks (UDN). <br>
    /// This feature requires mounting the kernel debug filesystem, so the eBPF agent pods must run as privileged via `spec.agent.ebpf.privileged`.
    /// It requires using the OVN-Kubernetes network plugin with the Observability feature. <br>
    /// - `IPSec`, to track flows between nodes with IPsec encryption. <br>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub features: Option<Vec<String>>,
    /// `flowFilter` defines the eBPF agent configuration regarding flow filtering.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "flowFilter")]
    pub flow_filter: Option<FlowCollectorAgentEbpfFlowFilter>,
    /// `imagePullPolicy` is the Kubernetes pull policy for the image defined above
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "imagePullPolicy")]
    pub image_pull_policy: Option<FlowCollectorAgentEbpfImagePullPolicy>,
    /// `interfaces` contains the interface names from where flows are collected. If empty, the agent
    /// fetches all the interfaces in the system, excepting the ones listed in `excludeInterfaces`.
    /// An entry enclosed by slashes, such as `/br-/`, is matched as a regular expression.
    /// Otherwise it is matched as a case-sensitive string.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub interfaces: Option<Vec<String>>,
    /// `kafkaBatchSize` limits the maximum size of a request in bytes before being sent to a partition. Ignored when not using Kafka. Default: 1MB.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kafkaBatchSize")]
    pub kafka_batch_size: Option<i64>,
    /// `logLevel` defines the log level for the NetObserv eBPF Agent
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "logLevel")]
    pub log_level: Option<FlowCollectorAgentEbpfLogLevel>,
    /// `metrics` defines the eBPF agent configuration regarding metrics.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metrics: Option<FlowCollectorAgentEbpfMetrics>,
    /// Privileged mode for the eBPF Agent container. When set to `true`, the agent is able to capture more traffic, including from secondary interfaces.
    /// When ignored or set to `false`, the operator sets granular capabilities (BPF, PERFMON, NET_ADMIN) to the container.
    /// Some agent features require the privileged mode, such as packet drops tracking (see `features`) and SR-IOV support.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub privileged: Option<bool>,
    /// `resources` are the compute resources required by this container.
    /// For more information, see <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resources: Option<FlowCollectorAgentEbpfResources>,
    /// Sampling interval of the eBPF probe. 100 means one packet on 100 is sent. 0 or 1 means all packets are sampled.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub sampling: Option<i32>,
}

/// `advanced` allows setting some aspects of the internal configuration of the eBPF agent.
/// This section is aimed mostly for debugging and fine-grained performance optimizations,
/// such as `GOGC` and `GOMAXPROCS` environment variables. Set these values at your own risk. You can also
/// override the default Linux capabilities from there.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvanced {
    /// Linux capabilities override, when not running as privileged. Default capabilities are BPF, PERFMON and NET_ADMIN.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "capOverride")]
    pub cap_override: Option<Vec<String>>,
    /// `env` allows passing custom environment variables to underlying components. Useful for passing
    /// some very concrete performance-tuning options, such as `GOGC` and `GOMAXPROCS`, that should not be
    /// publicly exposed as part of the FlowCollector descriptor, as they are only useful
    /// in edge debug or support scenarios.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub env: Option<BTreeMap<String, String>>,
    /// scheduling controls how the pods are scheduled on nodes.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub scheduling: Option<FlowCollectorAgentEbpfAdvancedScheduling>,
}

/// scheduling controls how the pods are scheduled on nodes.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedScheduling {
    /// If specified, the pod's scheduling constraints. For documentation, refer to <https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling.>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub affinity: Option<FlowCollectorAgentEbpfAdvancedSchedulingAffinity>,
    /// `nodeSelector` allows scheduling of pods only onto nodes that have each of the specified labels.
    /// For documentation, refer to <https://kubernetes.io/docs/concepts/configuration/assign-pod-node/.>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeSelector")]
    pub node_selector: Option<BTreeMap<String, String>>,
    /// If specified, indicates the pod's priority. For documentation, refer to <https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#how-to-use-priority-and-preemption.>
    /// If not specified, default priority is used, or zero if there is no default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "priorityClassName")]
    pub priority_class_name: Option<String>,
    /// `tolerations` is a list of tolerations that allow the pod to schedule onto nodes with matching taints.
    /// For documentation, refer to <https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling.>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tolerations: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingTolerations>>,
}

/// If specified, the pod's scheduling constraints. For documentation, refer to <https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling.>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinity {
    /// Describes node affinity scheduling rules for the pod.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeAffinity")]
    pub node_affinity: Option<FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinity>,
    /// Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podAffinity")]
    pub pod_affinity: Option<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinity>,
    /// Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podAntiAffinity")]
    pub pod_anti_affinity: Option<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinity>,
}

/// Describes node affinity scheduling rules for the pod.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinity {
    /// The scheduler will prefer to schedule pods to nodes that satisfy
    /// the affinity expressions specified by this field, but it may choose
    /// a node that violates one or more of the expressions. The node that is
    /// most preferred is the one with the greatest sum of weights, i.e.
    /// for each node that meets all of the scheduling requirements (resource
    /// request, requiredDuringScheduling affinity expressions, etc.),
    /// compute a sum by iterating through the elements of this field and adding
    /// "weight" to the sum if the node matches the corresponding matchExpressions; the
    /// node(s) with the highest sum are the most preferred.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    /// If the affinity requirements specified by this field are not met at
    /// scheduling time, the pod will not be scheduled onto the node.
    /// If the affinity requirements specified by this field cease to be met
    /// at some point during pod execution (e.g. due to an update), the system
    /// may or may not try to eventually evict the pod from its node.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution>,
}

/// An empty preferred scheduling term matches all objects with implicit weight 0
/// (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    /// A node selector term, associated with the corresponding weight.
    pub preference: FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference,
    /// Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
    pub weight: i32,
}

/// A node selector term, associated with the corresponding weight.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
    /// A list of node selector requirements by node's labels.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions>>,
    /// A list of node selector requirements by node's fields.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchFields")]
    pub match_fields: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// If the affinity requirements specified by this field are not met at
/// scheduling time, the pod will not be scheduled onto the node.
/// If the affinity requirements specified by this field cease to be met
/// at some point during pod execution (e.g. due to an update), the system
/// may or may not try to eventually evict the pod from its node.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    /// Required. A list of node selector terms. The terms are ORed.
    #[serde(rename = "nodeSelectorTerms")]
    pub node_selector_terms: Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms>,
}

/// A null or empty node selector term matches no objects. The requirements of
/// them are ANDed.
/// The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
    /// A list of node selector requirements by node's labels.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions>>,
    /// A list of node selector requirements by node's fields.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchFields")]
    pub match_fields: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinity {
    /// The scheduler will prefer to schedule pods to nodes that satisfy
    /// the affinity expressions specified by this field, but it may choose
    /// a node that violates one or more of the expressions. The node that is
    /// most preferred is the one with the greatest sum of weights, i.e.
    /// for each node that meets all of the scheduling requirements (resource
    /// request, requiredDuringScheduling affinity expressions, etc.),
    /// compute a sum by iterating through the elements of this field and adding
    /// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
    /// node(s) with the highest sum are the most preferred.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    /// If the affinity requirements specified by this field are not met at
    /// scheduling time, the pod will not be scheduled onto the node.
    /// If the affinity requirements specified by this field cease to be met
    /// at some point during pod execution (e.g. due to a pod label update), the
    /// system may or may not try to eventually evict the pod from its node.
    /// When there are multiple elements, the lists of nodes corresponding to each
    /// podAffinityTerm are intersected, i.e. all terms must be satisfied.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution>>,
}

/// The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    /// Required. A pod affinity term, associated with the corresponding weight.
    #[serde(rename = "podAffinityTerm")]
    pub pod_affinity_term: FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm,
    /// weight associated with matching the corresponding podAffinityTerm,
    /// in the range 1-100.
    pub weight: i32,
}

/// Required. A pod affinity term, associated with the corresponding weight.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
    /// A label query over a set of resources, in this case pods.
    /// If it's null, this PodAffinityTerm matches with no Pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector>,
    /// MatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
    /// Also, matchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    /// MismatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
    /// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    /// A label query over the set of namespaces that the term applies to.
    /// The term is applied to the union of the namespaces selected by this field
    /// and the ones listed in the namespaces field.
    /// null selector and null or empty namespaces list means "this pod's namespace".
    /// An empty selector ({}) matches all namespaces.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector>,
    /// namespaces specifies a static list of namespace names that the term applies to.
    /// The term is applied to the union of the namespaces listed in this field
    /// and the ones selected by namespaceSelector.
    /// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    /// This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
    /// the labelSelector in the specified namespaces, where co-located is defined as running on a node
    /// whose value of the label with key topologyKey matches that of any node on which any of the
    /// selected pods is running.
    /// Empty topologyKey is not allowed.
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

/// A label query over a set of resources, in this case pods.
/// If it's null, this PodAffinityTerm matches with no Pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A label query over the set of namespaces that the term applies to.
/// The term is applied to the union of the namespaces selected by this field
/// and the ones listed in the namespaces field.
/// null selector and null or empty namespaces list means "this pod's namespace".
/// An empty selector ({}) matches all namespaces.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Defines a set of pods (namely those matching the labelSelector
/// relative to the given namespace(s)) that this pod should be
/// co-located (affinity) or not co-located (anti-affinity) with,
/// where co-located is defined as running on a node whose value of
/// the label with key <topologyKey> matches that of any node on which
/// a pod of the set of pods is running
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    /// A label query over a set of resources, in this case pods.
    /// If it's null, this PodAffinityTerm matches with no Pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector>,
    /// MatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
    /// Also, matchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    /// MismatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
    /// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    /// A label query over the set of namespaces that the term applies to.
    /// The term is applied to the union of the namespaces selected by this field
    /// and the ones listed in the namespaces field.
    /// null selector and null or empty namespaces list means "this pod's namespace".
    /// An empty selector ({}) matches all namespaces.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector>,
    /// namespaces specifies a static list of namespace names that the term applies to.
    /// The term is applied to the union of the namespaces listed in this field
    /// and the ones selected by namespaceSelector.
    /// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    /// This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
    /// the labelSelector in the specified namespaces, where co-located is defined as running on a node
    /// whose value of the label with key topologyKey matches that of any node on which any of the
    /// selected pods is running.
    /// Empty topologyKey is not allowed.
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

/// A label query over a set of resources, in this case pods.
/// If it's null, this PodAffinityTerm matches with no Pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A label query over the set of namespaces that the term applies to.
/// The term is applied to the union of the namespaces selected by this field
/// and the ones listed in the namespaces field.
/// null selector and null or empty namespaces list means "this pod's namespace".
/// An empty selector ({}) matches all namespaces.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinity {
    /// The scheduler will prefer to schedule pods to nodes that satisfy
    /// the anti-affinity expressions specified by this field, but it may choose
    /// a node that violates one or more of the expressions. The node that is
    /// most preferred is the one with the greatest sum of weights, i.e.
    /// for each node that meets all of the scheduling requirements (resource
    /// request, requiredDuringScheduling anti-affinity expressions, etc.),
    /// compute a sum by iterating through the elements of this field and subtracting
    /// "weight" from the sum if the node has pods which matches the corresponding podAffinityTerm; the
    /// node(s) with the highest sum are the most preferred.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    /// If the anti-affinity requirements specified by this field are not met at
    /// scheduling time, the pod will not be scheduled onto the node.
    /// If the anti-affinity requirements specified by this field cease to be met
    /// at some point during pod execution (e.g. due to a pod label update), the
    /// system may or may not try to eventually evict the pod from its node.
    /// When there are multiple elements, the lists of nodes corresponding to each
    /// podAffinityTerm are intersected, i.e. all terms must be satisfied.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution>>,
}

/// The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    /// Required. A pod affinity term, associated with the corresponding weight.
    #[serde(rename = "podAffinityTerm")]
    pub pod_affinity_term: FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm,
    /// weight associated with matching the corresponding podAffinityTerm,
    /// in the range 1-100.
    pub weight: i32,
}

/// Required. A pod affinity term, associated with the corresponding weight.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
    /// A label query over a set of resources, in this case pods.
    /// If it's null, this PodAffinityTerm matches with no Pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector>,
    /// MatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
    /// Also, matchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    /// MismatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
    /// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    /// A label query over the set of namespaces that the term applies to.
    /// The term is applied to the union of the namespaces selected by this field
    /// and the ones listed in the namespaces field.
    /// null selector and null or empty namespaces list means "this pod's namespace".
    /// An empty selector ({}) matches all namespaces.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector>,
    /// namespaces specifies a static list of namespace names that the term applies to.
    /// The term is applied to the union of the namespaces listed in this field
    /// and the ones selected by namespaceSelector.
    /// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    /// This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
    /// the labelSelector in the specified namespaces, where co-located is defined as running on a node
    /// whose value of the label with key topologyKey matches that of any node on which any of the
    /// selected pods is running.
    /// Empty topologyKey is not allowed.
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

/// A label query over a set of resources, in this case pods.
/// If it's null, this PodAffinityTerm matches with no Pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A label query over the set of namespaces that the term applies to.
/// The term is applied to the union of the namespaces selected by this field
/// and the ones listed in the namespaces field.
/// null selector and null or empty namespaces list means "this pod's namespace".
/// An empty selector ({}) matches all namespaces.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Defines a set of pods (namely those matching the labelSelector
/// relative to the given namespace(s)) that this pod should be
/// co-located (affinity) or not co-located (anti-affinity) with,
/// where co-located is defined as running on a node whose value of
/// the label with key <topologyKey> matches that of any node on which
/// a pod of the set of pods is running
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    /// A label query over a set of resources, in this case pods.
    /// If it's null, this PodAffinityTerm matches with no Pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector>,
    /// MatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
    /// Also, matchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    /// MismatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
    /// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    /// A label query over the set of namespaces that the term applies to.
    /// The term is applied to the union of the namespaces selected by this field
    /// and the ones listed in the namespaces field.
    /// null selector and null or empty namespaces list means "this pod's namespace".
    /// An empty selector ({}) matches all namespaces.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector>,
    /// namespaces specifies a static list of namespace names that the term applies to.
    /// The term is applied to the union of the namespaces listed in this field
    /// and the ones selected by namespaceSelector.
    /// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    /// This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
    /// the labelSelector in the specified namespaces, where co-located is defined as running on a node
    /// whose value of the label with key topologyKey matches that of any node on which any of the
    /// selected pods is running.
    /// Empty topologyKey is not allowed.
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

/// A label query over a set of resources, in this case pods.
/// If it's null, this PodAffinityTerm matches with no Pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A label query over the set of namespaces that the term applies to.
/// The term is applied to the union of the namespaces selected by this field
/// and the ones listed in the namespaces field.
/// null selector and null or empty namespaces list means "this pod's namespace".
/// An empty selector ({}) matches all namespaces.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// The pod this Toleration is attached to tolerates any taint that matches
/// the triple <key,value,effect> using the matching operator <operator>.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfAdvancedSchedulingTolerations {
    /// Effect indicates the taint effect to match. Empty means match all taint effects.
    /// When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub effect: Option<String>,
    /// Key is the taint key that the toleration applies to. Empty means match all taint keys.
    /// If the key is empty, operator must be Exists; this combination means to match all values and all keys.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub key: Option<String>,
    /// Operator represents a key's relationship to the value.
    /// Valid operators are Exists and Equal. Defaults to Equal.
    /// Exists is equivalent to wildcard for value, so that a pod can
    /// tolerate all taints of a particular category.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub operator: Option<String>,
    /// TolerationSeconds represents the period of time the toleration (which must be
    /// of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,
    /// it is not set, which means tolerate the taint forever (do not evict). Zero and
    /// negative values will be treated as 0 (evict immediately) by the system.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tolerationSeconds")]
    pub toleration_seconds: Option<i64>,
    /// Value is the taint value the toleration matches to.
    /// If the operator is Exists, the value should be empty, otherwise just a regular string.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<String>,
}

/// `flowFilter` defines the eBPF agent configuration regarding flow filtering.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfFlowFilter {
    /// `action` defines the action to perform on the flows that match the filter. The available options are `Accept`, which is the default, and `Reject`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub action: Option<FlowCollectorAgentEbpfFlowFilterAction>,
    /// `cidr` defines the IP CIDR to filter flows by.
    /// Examples: `10.10.10.0/24` or `100:100:100:100::/64`
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub cidr: Option<String>,
    /// `destPorts` optionally defines the destination ports to filter flows by.
    /// To filter a single port, set a single port as an integer value. For example, `destPorts: 80`.
    /// To filter a range of ports, use a "start-end" range in string format. For example, `destPorts: "80-100"`.
    /// To filter two ports, use a "port1,port2" in string format. For example, `ports: "80,100"`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destPorts")]
    pub dest_ports: Option<IntOrString>,
    /// `direction` optionally defines a direction to filter flows by. The available options are `Ingress` and `Egress`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub direction: Option<FlowCollectorAgentEbpfFlowFilterDirection>,
    /// Set `enable` to `true` to enable the eBPF flow filtering feature.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `icmpCode`, for Internet Control Message Protocol (ICMP) traffic, optionally defines the ICMP code to filter flows by.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "icmpCode")]
    pub icmp_code: Option<i64>,
    /// `icmpType`, for ICMP traffic, optionally defines the ICMP type to filter flows by.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "icmpType")]
    pub icmp_type: Option<i64>,
    /// `peerCIDR` defines the Peer IP CIDR to filter flows by.
    /// Examples: `10.10.10.0/24` or `100:100:100:100::/64`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "peerCIDR")]
    pub peer_cidr: Option<String>,
    /// `peerIP` optionally defines the remote IP address to filter flows by.
    /// Example: `10.10.10.10`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "peerIP")]
    pub peer_ip: Option<String>,
    /// `pktDrops` optionally filters only flows containing packet drops.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "pktDrops")]
    pub pkt_drops: Option<bool>,
    /// `ports` optionally defines the ports to filter flows by. It is used both for source and destination ports.
    /// To filter a single port, set a single port as an integer value. For example, `ports: 80`.
    /// To filter a range of ports, use a "start-end" range in string format. For example, `ports: "80-100"`.
    /// To filter two ports, use a "port1,port2" in string format. For example, `ports: "80,100"`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub ports: Option<IntOrString>,
    /// `protocol` optionally defines a protocol to filter flows by. The available options are `TCP`, `UDP`, `ICMP`, `ICMPv6`, and `SCTP`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub protocol: Option<FlowCollectorAgentEbpfFlowFilterProtocol>,
    /// `rules` defines a list of filtering rules on the eBPF Agents.
    /// When filtering is enabled, by default, flows that don't match any rule are rejected.
    /// To change the default, you can define a rule that accepts everything: `{ action: "Accept", cidr: "0.0.0.0/0" }`, and then refine with rejecting rules.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub rules: Option<Vec<FlowCollectorAgentEbpfFlowFilterRules>>,
    /// `sampling` is the sampling interval for the matched packets, overriding the global sampling defined at `spec.agent.ebpf.sampling`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub sampling: Option<i32>,
    /// `sourcePorts` optionally defines the source ports to filter flows by.
    /// To filter a single port, set a single port as an integer value. For example, `sourcePorts: 80`.
    /// To filter a range of ports, use a "start-end" range in string format. For example, `sourcePorts: "80-100"`.
    /// To filter two ports, use a "port1,port2" in string format. For example, `ports: "80,100"`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourcePorts")]
    pub source_ports: Option<IntOrString>,
    /// `tcpFlags` optionally defines TCP flags to filter flows by.
    /// In addition to the standard flags (RFC-9293), you can also filter by one of the three following combinations: `SYN-ACK`, `FIN-ACK`, and `RST-ACK`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tcpFlags")]
    pub tcp_flags: Option<FlowCollectorAgentEbpfFlowFilterTcpFlags>,
}

/// `flowFilter` defines the eBPF agent configuration regarding flow filtering.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfFlowFilterAction {
    Accept,
    Reject,
}

/// `flowFilter` defines the eBPF agent configuration regarding flow filtering.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfFlowFilterDirection {
    Ingress,
    Egress,
}

/// `flowFilter` defines the eBPF agent configuration regarding flow filtering.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfFlowFilterProtocol {
    #[serde(rename = "TCP")]
    Tcp,
    #[serde(rename = "UDP")]
    Udp,
    #[serde(rename = "ICMP")]
    Icmp,
    #[serde(rename = "ICMPv6")]
    IcmPv6,
    #[serde(rename = "SCTP")]
    Sctp,
}

/// `EBPFFlowFilterRule` defines the desired eBPF agent configuration regarding flow filtering rule.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfFlowFilterRules {
    /// `action` defines the action to perform on the flows that match the filter. The available options are `Accept`, which is the default, and `Reject`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub action: Option<FlowCollectorAgentEbpfFlowFilterRulesAction>,
    /// `cidr` defines the IP CIDR to filter flows by.
    /// Examples: `10.10.10.0/24` or `100:100:100:100::/64`
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub cidr: Option<String>,
    /// `destPorts` optionally defines the destination ports to filter flows by.
    /// To filter a single port, set a single port as an integer value. For example, `destPorts: 80`.
    /// To filter a range of ports, use a "start-end" range in string format. For example, `destPorts: "80-100"`.
    /// To filter two ports, use a "port1,port2" in string format. For example, `ports: "80,100"`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destPorts")]
    pub dest_ports: Option<IntOrString>,
    /// `direction` optionally defines a direction to filter flows by. The available options are `Ingress` and `Egress`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub direction: Option<FlowCollectorAgentEbpfFlowFilterRulesDirection>,
    /// `icmpCode`, for Internet Control Message Protocol (ICMP) traffic, optionally defines the ICMP code to filter flows by.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "icmpCode")]
    pub icmp_code: Option<i64>,
    /// `icmpType`, for ICMP traffic, optionally defines the ICMP type to filter flows by.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "icmpType")]
    pub icmp_type: Option<i64>,
    /// `peerCIDR` defines the Peer IP CIDR to filter flows by.
    /// Examples: `10.10.10.0/24` or `100:100:100:100::/64`
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "peerCIDR")]
    pub peer_cidr: Option<String>,
    /// `peerIP` optionally defines the remote IP address to filter flows by.
    /// Example: `10.10.10.10`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "peerIP")]
    pub peer_ip: Option<String>,
    /// `pktDrops` optionally filters only flows containing packet drops.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "pktDrops")]
    pub pkt_drops: Option<bool>,
    /// `ports` optionally defines the ports to filter flows by. It is used both for source and destination ports.
    /// To filter a single port, set a single port as an integer value. For example, `ports: 80`.
    /// To filter a range of ports, use a "start-end" range in string format. For example, `ports: "80-100"`.
    /// To filter two ports, use a "port1,port2" in string format. For example, `ports: "80,100"`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub ports: Option<IntOrString>,
    /// `protocol` optionally defines a protocol to filter flows by. The available options are `TCP`, `UDP`, `ICMP`, `ICMPv6`, and `SCTP`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub protocol: Option<FlowCollectorAgentEbpfFlowFilterRulesProtocol>,
    /// `sampling` is the sampling interval for the matched packets, overriding the global sampling defined at `spec.agent.ebpf.sampling`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub sampling: Option<i32>,
    /// `sourcePorts` optionally defines the source ports to filter flows by.
    /// To filter a single port, set a single port as an integer value. For example, `sourcePorts: 80`.
    /// To filter a range of ports, use a "start-end" range in string format. For example, `sourcePorts: "80-100"`.
    /// To filter two ports, use a "port1,port2" in string format. For example, `ports: "80,100"`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourcePorts")]
    pub source_ports: Option<IntOrString>,
    /// `tcpFlags` optionally defines TCP flags to filter flows by.
    /// In addition to the standard flags (RFC-9293), you can also filter by one of the three following combinations: `SYN-ACK`, `FIN-ACK`, and `RST-ACK`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tcpFlags")]
    pub tcp_flags: Option<FlowCollectorAgentEbpfFlowFilterRulesTcpFlags>,
}

/// `EBPFFlowFilterRule` defines the desired eBPF agent configuration regarding flow filtering rule.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfFlowFilterRulesAction {
    Accept,
    Reject,
}

/// `EBPFFlowFilterRule` defines the desired eBPF agent configuration regarding flow filtering rule.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfFlowFilterRulesDirection {
    Ingress,
    Egress,
}

/// `EBPFFlowFilterRule` defines the desired eBPF agent configuration regarding flow filtering rule.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfFlowFilterRulesProtocol {
    #[serde(rename = "TCP")]
    Tcp,
    #[serde(rename = "UDP")]
    Udp,
    #[serde(rename = "ICMP")]
    Icmp,
    #[serde(rename = "ICMPv6")]
    IcmPv6,
    #[serde(rename = "SCTP")]
    Sctp,
}

/// `EBPFFlowFilterRule` defines the desired eBPF agent configuration regarding flow filtering rule.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfFlowFilterRulesTcpFlags {
    #[serde(rename = "SYN")]
    Syn,
    #[serde(rename = "SYN-ACK")]
    SynAck,
    #[serde(rename = "ACK")]
    Ack,
    #[serde(rename = "FIN")]
    Fin,
    #[serde(rename = "RST")]
    Rst,
    #[serde(rename = "URG")]
    Urg,
    #[serde(rename = "ECE")]
    Ece,
    #[serde(rename = "CWR")]
    Cwr,
    #[serde(rename = "FIN-ACK")]
    FinAck,
    #[serde(rename = "RST-ACK")]
    RstAck,
}

/// `flowFilter` defines the eBPF agent configuration regarding flow filtering.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfFlowFilterTcpFlags {
    #[serde(rename = "SYN")]
    Syn,
    #[serde(rename = "SYN-ACK")]
    SynAck,
    #[serde(rename = "ACK")]
    Ack,
    #[serde(rename = "FIN")]
    Fin,
    #[serde(rename = "RST")]
    Rst,
    #[serde(rename = "URG")]
    Urg,
    #[serde(rename = "ECE")]
    Ece,
    #[serde(rename = "CWR")]
    Cwr,
    #[serde(rename = "FIN-ACK")]
    FinAck,
    #[serde(rename = "RST-ACK")]
    RstAck,
}

/// `ebpf` describes the settings related to the eBPF-based flow reporter when `spec.agent.type`
/// is set to `eBPF`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfImagePullPolicy {
    IfNotPresent,
    Always,
    Never,
}

/// `ebpf` describes the settings related to the eBPF-based flow reporter when `spec.agent.type`
/// is set to `eBPF`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfLogLevel {
    #[serde(rename = "trace")]
    Trace,
    #[serde(rename = "debug")]
    Debug,
    #[serde(rename = "info")]
    Info,
    #[serde(rename = "warn")]
    Warn,
    #[serde(rename = "error")]
    Error,
    #[serde(rename = "fatal")]
    Fatal,
    #[serde(rename = "panic")]
    Panic,
}

/// `metrics` defines the eBPF agent configuration regarding metrics.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfMetrics {
    /// `disableAlerts` is a list of alerts that should be disabled.
    /// Possible values are:<br>
    /// `NetObservDroppedFlows`, which is triggered when the eBPF agent is missing packets or flows, such as when the BPF hashmap is busy or full, or the capacity limiter is being triggered.<br>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "disableAlerts")]
    pub disable_alerts: Option<Vec<String>>,
    /// Set `enable` to `false` to disable eBPF agent metrics collection. It is enabled by default.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// Metrics server endpoint configuration for the Prometheus scraper.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub server: Option<FlowCollectorAgentEbpfMetricsServer>,
}

/// Metrics server endpoint configuration for the Prometheus scraper.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfMetricsServer {
    /// The metrics server HTTP port.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub port: Option<i32>,
    /// TLS configuration.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<FlowCollectorAgentEbpfMetricsServerTls>,
}

/// TLS configuration.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorAgentEbpfMetricsServerTls {
    /// `insecureSkipVerify` allows skipping client-side verification of the provided certificate.
    /// If set to `true`, the `providedCaFile` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// TLS configuration when `type` is set to `Provided`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub provided: Option<FlowCollectorAgentEbpfMetricsServerTlsProvided>,
    /// Reference to the CA file when `type` is set to `Provided`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "providedCaFile")]
    pub provided_ca_file: Option<FlowCollectorAgentEbpfMetricsServerTlsProvidedCaFile>,
    /// Select the type of TLS configuration:<br>
    /// - `Disabled` (default) to not configure TLS for the endpoint.
    /// - `Provided` to manually provide cert file and a key file. [Unsupported (*)].
    /// - `Auto` to use OpenShift auto generated certificate using annotations.
    #[serde(rename = "type")]
    pub r#type: FlowCollectorAgentEbpfMetricsServerTlsType,
}

/// TLS configuration when `type` is set to `Provided`.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfMetricsServerTlsProvided {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorAgentEbpfMetricsServerTlsProvidedType>,
}

/// TLS configuration when `type` is set to `Provided`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfMetricsServerTlsProvidedType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// Reference to the CA file when `type` is set to `Provided`.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfMetricsServerTlsProvidedCaFile {
    /// File name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub file: Option<String>,
    /// Name of the config map or secret containing the file.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing the file. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the file reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorAgentEbpfMetricsServerTlsProvidedCaFileType>,
}

/// Reference to the CA file when `type` is set to `Provided`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfMetricsServerTlsProvidedCaFileType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// TLS configuration.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentEbpfMetricsServerTlsType {
    Disabled,
    Provided,
    Auto,
}

/// `resources` are the compute resources required by this container.
/// For more information, see <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfResources {
    /// Claims lists the names of resources, defined in spec.resourceClaims,
    /// that are used by this container.
    /// 
    /// This field depends on the
    /// DynamicResourceAllocation feature gate.
    /// 
    /// This field is immutable. It can only be set for containers.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub claims: Option<Vec<FlowCollectorAgentEbpfResourcesClaims>>,
    /// Limits describes the maximum amount of compute resources allowed.
    /// More info: <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub limits: Option<BTreeMap<String, IntOrString>>,
    /// Requests describes the minimum amount of compute resources required.
    /// If Requests is omitted for a container, it defaults to Limits if that is explicitly specified,
    /// otherwise to an implementation-defined value. Requests cannot exceed Limits.
    /// More info: <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub requests: Option<BTreeMap<String, IntOrString>>,
}

/// ResourceClaim references one entry in PodSpec.ResourceClaims.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentEbpfResourcesClaims {
    /// Name must match the name of one entry in pod.spec.resourceClaims of
    /// the Pod where this field is used. It makes that resource available
    /// inside a container.
    pub name: String,
    /// Request is the name chosen for a request in the referenced claim.
    /// If empty, everything from the claim is made available, otherwise
    /// only the result of this request.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub request: Option<String>,
}

/// `ipfix` [deprecated (*)] - describes the settings related to the IPFIX-based flow reporter when `spec.agent.type`
/// is set to `IPFIX`.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentIpfix {
    /// `cacheActiveTimeout` is the max period during which the reporter aggregates flows before sending.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "cacheActiveTimeout")]
    pub cache_active_timeout: Option<String>,
    /// `cacheMaxFlows` is the max number of flows in an aggregate; when reached, the reporter sends the flows.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "cacheMaxFlows")]
    pub cache_max_flows: Option<i32>,
    /// `clusterNetworkOperator` defines the settings related to the OpenShift Cluster Network Operator, when available.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clusterNetworkOperator")]
    pub cluster_network_operator: Option<FlowCollectorAgentIpfixClusterNetworkOperator>,
    /// `forceSampleAll` allows disabling sampling in the IPFIX-based flow reporter.
    /// It is not recommended to sample all the traffic with IPFIX, as it might generate cluster instability.
    /// If you REALLY want to do that, set this flag to `true`. Use at your own risk.
    /// When it is set to `true`, the value of `sampling` is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "forceSampleAll")]
    pub force_sample_all: Option<bool>,
    /// `ovnKubernetes` defines the settings of the OVN-Kubernetes network plugin, when available. This configuration is used when using OVN's IPFIX exports, without OpenShift. When using OpenShift, refer to the `clusterNetworkOperator` property instead.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ovnKubernetes")]
    pub ovn_kubernetes: Option<FlowCollectorAgentIpfixOvnKubernetes>,
    /// `sampling` is the sampling interval on the reporter. 100 means one flow on 100 is sent.
    /// To ensure cluster stability, it is not possible to set a value below 2.
    /// If you really want to sample every packet, which might impact the cluster stability,
    /// refer to `forceSampleAll`. Alternatively, you can use the eBPF Agent instead of IPFIX.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub sampling: Option<i32>,
}

/// `clusterNetworkOperator` defines the settings related to the OpenShift Cluster Network Operator, when available.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentIpfixClusterNetworkOperator {
    /// Namespace  where the config map is going to be deployed.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
}

/// `ovnKubernetes` defines the settings of the OVN-Kubernetes network plugin, when available. This configuration is used when using OVN's IPFIX exports, without OpenShift. When using OpenShift, refer to the `clusterNetworkOperator` property instead.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorAgentIpfixOvnKubernetes {
    /// `containerName` defines the name of the container to configure for IPFIX.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "containerName")]
    pub container_name: Option<String>,
    /// `daemonSetName` defines the name of the DaemonSet controlling the OVN-Kubernetes pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "daemonSetName")]
    pub daemon_set_name: Option<String>,
    /// Namespace where OVN-Kubernetes pods are deployed.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
}

/// Agent configuration for flows extraction.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorAgentType {
    #[serde(rename = "eBPF")]
    EBpf,
    #[serde(rename = "IPFIX")]
    Ipfix,
}

/// `consolePlugin` defines the settings related to the OpenShift Console plugin, when available.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePlugin {
    /// `advanced` allows setting some aspects of the internal configuration of the console plugin.
    /// This section is aimed mostly for debugging and fine-grained performance optimizations,
    /// such as `GOGC` and `GOMAXPROCS` environment variables. Set these values at your own risk.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub advanced: Option<FlowCollectorConsolePluginAdvanced>,
    /// `autoscaler` [deprecated (*)] spec of a horizontal pod autoscaler to set up for the plugin Deployment.
    /// Deprecation notice: managed autoscaler will be removed in a future version. You may configure instead an autoscaler of your choice, and set `spec.consolePlugin.unmanagedReplicas` to `true`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub autoscaler: Option<FlowCollectorConsolePluginAutoscaler>,
    /// Enables the console plugin deployment.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `imagePullPolicy` is the Kubernetes pull policy for the image defined above.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "imagePullPolicy")]
    pub image_pull_policy: Option<FlowCollectorConsolePluginImagePullPolicy>,
    /// `logLevel` for the console plugin backend.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "logLevel")]
    pub log_level: Option<FlowCollectorConsolePluginLogLevel>,
    /// `portNaming` defines the configuration of the port-to-service name translation.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "portNaming")]
    pub port_naming: Option<FlowCollectorConsolePluginPortNaming>,
    /// `quickFilters` configures quick filter presets for the Console plugin.
    /// Filters for external traffic assume the subnet labels are configured to distinguish internal and external traffic (see `spec.processor.subnetLabels`).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "quickFilters")]
    pub quick_filters: Option<Vec<FlowCollectorConsolePluginQuickFilters>>,
    /// `replicas` defines the number of replicas (pods) to start.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub replicas: Option<i32>,
    /// `resources`, in terms of compute resources, required by this container.
    /// For more information, see <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/.>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resources: Option<FlowCollectorConsolePluginResources>,
    /// Deploy as a standalone console, instead of a plugin of the OpenShift Console.
    /// This is not recommended when using with OpenShift, as it doesn't provide an integrated experience.
    /// [Unsupported (*)].
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub standalone: Option<bool>,
    /// If `unmanagedReplicas` is `true`, the operator will not reconcile `replicas`. This is useful when using a pod autoscaler.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "unmanagedReplicas")]
    pub unmanaged_replicas: Option<bool>,
}

/// `advanced` allows setting some aspects of the internal configuration of the console plugin.
/// This section is aimed mostly for debugging and fine-grained performance optimizations,
/// such as `GOGC` and `GOMAXPROCS` environment variables. Set these values at your own risk.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvanced {
    /// `args` allows passing custom arguments to underlying components. Useful for overriding
    /// some parameters, such as a URL or a configuration path, that should not be
    /// publicly exposed as part of the FlowCollector descriptor, as they are only useful
    /// in edge debug or support scenarios.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub args: Option<Vec<String>>,
    /// `env` allows passing custom environment variables to underlying components. Useful for passing
    /// some very concrete performance-tuning options, such as `GOGC` and `GOMAXPROCS`, that should not be
    /// publicly exposed as part of the FlowCollector descriptor, as they are only useful
    /// in edge debug or support scenarios.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub env: Option<BTreeMap<String, String>>,
    /// `port` is the plugin service port. Do not use 9002, which is reserved for metrics.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub port: Option<i32>,
    /// `register` allows, when set to `true`, to automatically register the provided console plugin with the OpenShift Console operator.
    /// When set to `false`, you can still register it manually by editing console.operator.openshift.io/cluster with the following command:
    /// `oc patch console.operator.openshift.io cluster --type='json' -p '[{"op": "add", "path": "/spec/plugins/-", "value": "netobserv-plugin"}]'`
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub register: Option<bool>,
    /// `scheduling` controls how the pods are scheduled on nodes.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub scheduling: Option<FlowCollectorConsolePluginAdvancedScheduling>,
}

/// `scheduling` controls how the pods are scheduled on nodes.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedScheduling {
    /// If specified, the pod's scheduling constraints. For documentation, refer to <https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling.>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub affinity: Option<FlowCollectorConsolePluginAdvancedSchedulingAffinity>,
    /// `nodeSelector` allows scheduling of pods only onto nodes that have each of the specified labels.
    /// For documentation, refer to <https://kubernetes.io/docs/concepts/configuration/assign-pod-node/.>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeSelector")]
    pub node_selector: Option<BTreeMap<String, String>>,
    /// If specified, indicates the pod's priority. For documentation, refer to <https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#how-to-use-priority-and-preemption.>
    /// If not specified, default priority is used, or zero if there is no default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "priorityClassName")]
    pub priority_class_name: Option<String>,
    /// `tolerations` is a list of tolerations that allow the pod to schedule onto nodes with matching taints.
    /// For documentation, refer to <https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling.>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tolerations: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingTolerations>>,
}

/// If specified, the pod's scheduling constraints. For documentation, refer to <https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling.>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinity {
    /// Describes node affinity scheduling rules for the pod.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeAffinity")]
    pub node_affinity: Option<FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinity>,
    /// Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podAffinity")]
    pub pod_affinity: Option<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinity>,
    /// Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podAntiAffinity")]
    pub pod_anti_affinity: Option<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinity>,
}

/// Describes node affinity scheduling rules for the pod.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinity {
    /// The scheduler will prefer to schedule pods to nodes that satisfy
    /// the affinity expressions specified by this field, but it may choose
    /// a node that violates one or more of the expressions. The node that is
    /// most preferred is the one with the greatest sum of weights, i.e.
    /// for each node that meets all of the scheduling requirements (resource
    /// request, requiredDuringScheduling affinity expressions, etc.),
    /// compute a sum by iterating through the elements of this field and adding
    /// "weight" to the sum if the node matches the corresponding matchExpressions; the
    /// node(s) with the highest sum are the most preferred.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    /// If the affinity requirements specified by this field are not met at
    /// scheduling time, the pod will not be scheduled onto the node.
    /// If the affinity requirements specified by this field cease to be met
    /// at some point during pod execution (e.g. due to an update), the system
    /// may or may not try to eventually evict the pod from its node.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution>,
}

/// An empty preferred scheduling term matches all objects with implicit weight 0
/// (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    /// A node selector term, associated with the corresponding weight.
    pub preference: FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference,
    /// Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
    pub weight: i32,
}

/// A node selector term, associated with the corresponding weight.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
    /// A list of node selector requirements by node's labels.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions>>,
    /// A list of node selector requirements by node's fields.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchFields")]
    pub match_fields: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// If the affinity requirements specified by this field are not met at
/// scheduling time, the pod will not be scheduled onto the node.
/// If the affinity requirements specified by this field cease to be met
/// at some point during pod execution (e.g. due to an update), the system
/// may or may not try to eventually evict the pod from its node.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    /// Required. A list of node selector terms. The terms are ORed.
    #[serde(rename = "nodeSelectorTerms")]
    pub node_selector_terms: Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms>,
}

/// A null or empty node selector term matches no objects. The requirements of
/// them are ANDed.
/// The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
    /// A list of node selector requirements by node's labels.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions>>,
    /// A list of node selector requirements by node's fields.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchFields")]
    pub match_fields: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinity {
    /// The scheduler will prefer to schedule pods to nodes that satisfy
    /// the affinity expressions specified by this field, but it may choose
    /// a node that violates one or more of the expressions. The node that is
    /// most preferred is the one with the greatest sum of weights, i.e.
    /// for each node that meets all of the scheduling requirements (resource
    /// request, requiredDuringScheduling affinity expressions, etc.),
    /// compute a sum by iterating through the elements of this field and adding
    /// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
    /// node(s) with the highest sum are the most preferred.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    /// If the affinity requirements specified by this field are not met at
    /// scheduling time, the pod will not be scheduled onto the node.
    /// If the affinity requirements specified by this field cease to be met
    /// at some point during pod execution (e.g. due to a pod label update), the
    /// system may or may not try to eventually evict the pod from its node.
    /// When there are multiple elements, the lists of nodes corresponding to each
    /// podAffinityTerm are intersected, i.e. all terms must be satisfied.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution>>,
}

/// The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    /// Required. A pod affinity term, associated with the corresponding weight.
    #[serde(rename = "podAffinityTerm")]
    pub pod_affinity_term: FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm,
    /// weight associated with matching the corresponding podAffinityTerm,
    /// in the range 1-100.
    pub weight: i32,
}

/// Required. A pod affinity term, associated with the corresponding weight.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
    /// A label query over a set of resources, in this case pods.
    /// If it's null, this PodAffinityTerm matches with no Pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector>,
    /// MatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
    /// Also, matchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    /// MismatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
    /// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    /// A label query over the set of namespaces that the term applies to.
    /// The term is applied to the union of the namespaces selected by this field
    /// and the ones listed in the namespaces field.
    /// null selector and null or empty namespaces list means "this pod's namespace".
    /// An empty selector ({}) matches all namespaces.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector>,
    /// namespaces specifies a static list of namespace names that the term applies to.
    /// The term is applied to the union of the namespaces listed in this field
    /// and the ones selected by namespaceSelector.
    /// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    /// This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
    /// the labelSelector in the specified namespaces, where co-located is defined as running on a node
    /// whose value of the label with key topologyKey matches that of any node on which any of the
    /// selected pods is running.
    /// Empty topologyKey is not allowed.
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

/// A label query over a set of resources, in this case pods.
/// If it's null, this PodAffinityTerm matches with no Pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A label query over the set of namespaces that the term applies to.
/// The term is applied to the union of the namespaces selected by this field
/// and the ones listed in the namespaces field.
/// null selector and null or empty namespaces list means "this pod's namespace".
/// An empty selector ({}) matches all namespaces.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Defines a set of pods (namely those matching the labelSelector
/// relative to the given namespace(s)) that this pod should be
/// co-located (affinity) or not co-located (anti-affinity) with,
/// where co-located is defined as running on a node whose value of
/// the label with key <topologyKey> matches that of any node on which
/// a pod of the set of pods is running
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    /// A label query over a set of resources, in this case pods.
    /// If it's null, this PodAffinityTerm matches with no Pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector>,
    /// MatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
    /// Also, matchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    /// MismatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
    /// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    /// A label query over the set of namespaces that the term applies to.
    /// The term is applied to the union of the namespaces selected by this field
    /// and the ones listed in the namespaces field.
    /// null selector and null or empty namespaces list means "this pod's namespace".
    /// An empty selector ({}) matches all namespaces.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector>,
    /// namespaces specifies a static list of namespace names that the term applies to.
    /// The term is applied to the union of the namespaces listed in this field
    /// and the ones selected by namespaceSelector.
    /// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    /// This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
    /// the labelSelector in the specified namespaces, where co-located is defined as running on a node
    /// whose value of the label with key topologyKey matches that of any node on which any of the
    /// selected pods is running.
    /// Empty topologyKey is not allowed.
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

/// A label query over a set of resources, in this case pods.
/// If it's null, this PodAffinityTerm matches with no Pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A label query over the set of namespaces that the term applies to.
/// The term is applied to the union of the namespaces selected by this field
/// and the ones listed in the namespaces field.
/// null selector and null or empty namespaces list means "this pod's namespace".
/// An empty selector ({}) matches all namespaces.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinity {
    /// The scheduler will prefer to schedule pods to nodes that satisfy
    /// the anti-affinity expressions specified by this field, but it may choose
    /// a node that violates one or more of the expressions. The node that is
    /// most preferred is the one with the greatest sum of weights, i.e.
    /// for each node that meets all of the scheduling requirements (resource
    /// request, requiredDuringScheduling anti-affinity expressions, etc.),
    /// compute a sum by iterating through the elements of this field and subtracting
    /// "weight" from the sum if the node has pods which matches the corresponding podAffinityTerm; the
    /// node(s) with the highest sum are the most preferred.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    /// If the anti-affinity requirements specified by this field are not met at
    /// scheduling time, the pod will not be scheduled onto the node.
    /// If the anti-affinity requirements specified by this field cease to be met
    /// at some point during pod execution (e.g. due to a pod label update), the
    /// system may or may not try to eventually evict the pod from its node.
    /// When there are multiple elements, the lists of nodes corresponding to each
    /// podAffinityTerm are intersected, i.e. all terms must be satisfied.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution>>,
}

/// The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    /// Required. A pod affinity term, associated with the corresponding weight.
    #[serde(rename = "podAffinityTerm")]
    pub pod_affinity_term: FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm,
    /// weight associated with matching the corresponding podAffinityTerm,
    /// in the range 1-100.
    pub weight: i32,
}

/// Required. A pod affinity term, associated with the corresponding weight.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
    /// A label query over a set of resources, in this case pods.
    /// If it's null, this PodAffinityTerm matches with no Pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector>,
    /// MatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
    /// Also, matchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    /// MismatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
    /// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    /// A label query over the set of namespaces that the term applies to.
    /// The term is applied to the union of the namespaces selected by this field
    /// and the ones listed in the namespaces field.
    /// null selector and null or empty namespaces list means "this pod's namespace".
    /// An empty selector ({}) matches all namespaces.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector>,
    /// namespaces specifies a static list of namespace names that the term applies to.
    /// The term is applied to the union of the namespaces listed in this field
    /// and the ones selected by namespaceSelector.
    /// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    /// This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
    /// the labelSelector in the specified namespaces, where co-located is defined as running on a node
    /// whose value of the label with key topologyKey matches that of any node on which any of the
    /// selected pods is running.
    /// Empty topologyKey is not allowed.
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

/// A label query over a set of resources, in this case pods.
/// If it's null, this PodAffinityTerm matches with no Pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A label query over the set of namespaces that the term applies to.
/// The term is applied to the union of the namespaces selected by this field
/// and the ones listed in the namespaces field.
/// null selector and null or empty namespaces list means "this pod's namespace".
/// An empty selector ({}) matches all namespaces.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Defines a set of pods (namely those matching the labelSelector
/// relative to the given namespace(s)) that this pod should be
/// co-located (affinity) or not co-located (anti-affinity) with,
/// where co-located is defined as running on a node whose value of
/// the label with key <topologyKey> matches that of any node on which
/// a pod of the set of pods is running
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    /// A label query over a set of resources, in this case pods.
    /// If it's null, this PodAffinityTerm matches with no Pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector>,
    /// MatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
    /// Also, matchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    /// MismatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
    /// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    /// A label query over the set of namespaces that the term applies to.
    /// The term is applied to the union of the namespaces selected by this field
    /// and the ones listed in the namespaces field.
    /// null selector and null or empty namespaces list means "this pod's namespace".
    /// An empty selector ({}) matches all namespaces.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector>,
    /// namespaces specifies a static list of namespace names that the term applies to.
    /// The term is applied to the union of the namespaces listed in this field
    /// and the ones selected by namespaceSelector.
    /// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    /// This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
    /// the labelSelector in the specified namespaces, where co-located is defined as running on a node
    /// whose value of the label with key topologyKey matches that of any node on which any of the
    /// selected pods is running.
    /// Empty topologyKey is not allowed.
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

/// A label query over a set of resources, in this case pods.
/// If it's null, this PodAffinityTerm matches with no Pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A label query over the set of namespaces that the term applies to.
/// The term is applied to the union of the namespaces selected by this field
/// and the ones listed in the namespaces field.
/// null selector and null or empty namespaces list means "this pod's namespace".
/// An empty selector ({}) matches all namespaces.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// The pod this Toleration is attached to tolerates any taint that matches
/// the triple <key,value,effect> using the matching operator <operator>.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAdvancedSchedulingTolerations {
    /// Effect indicates the taint effect to match. Empty means match all taint effects.
    /// When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub effect: Option<String>,
    /// Key is the taint key that the toleration applies to. Empty means match all taint keys.
    /// If the key is empty, operator must be Exists; this combination means to match all values and all keys.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub key: Option<String>,
    /// Operator represents a key's relationship to the value.
    /// Valid operators are Exists and Equal. Defaults to Equal.
    /// Exists is equivalent to wildcard for value, so that a pod can
    /// tolerate all taints of a particular category.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub operator: Option<String>,
    /// TolerationSeconds represents the period of time the toleration (which must be
    /// of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,
    /// it is not set, which means tolerate the taint forever (do not evict). Zero and
    /// negative values will be treated as 0 (evict immediately) by the system.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tolerationSeconds")]
    pub toleration_seconds: Option<i64>,
    /// Value is the taint value the toleration matches to.
    /// If the operator is Exists, the value should be empty, otherwise just a regular string.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<String>,
}

/// `autoscaler` [deprecated (*)] spec of a horizontal pod autoscaler to set up for the plugin Deployment.
/// Deprecation notice: managed autoscaler will be removed in a future version. You may configure instead an autoscaler of your choice, and set `spec.consolePlugin.unmanagedReplicas` to `true`.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscaler {
    /// `maxReplicas` is the upper limit for the number of pods that can be set by the autoscaler; cannot be smaller than MinReplicas.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxReplicas")]
    pub max_replicas: Option<i32>,
    /// Metrics used by the pod autoscaler. For documentation, refer to <https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/horizontal-pod-autoscaler-v2/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metrics: Option<Vec<FlowCollectorConsolePluginAutoscalerMetrics>>,
    /// `minReplicas` is the lower limit for the number of replicas to which the autoscaler
    /// can scale down. It defaults to 1 pod. minReplicas is allowed to be 0 if the
    /// alpha feature gate HPAScaleToZero is enabled and at least one Object or External
    /// metric is configured. Scaling is active as long as at least one metric value is
    /// available.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "minReplicas")]
    pub min_replicas: Option<i32>,
    /// `status` describes the desired status regarding deploying an horizontal pod autoscaler.<br>
    /// - `Disabled` does not deploy an horizontal pod autoscaler.<br>
    /// - `Enabled` deploys an horizontal pod autoscaler.<br>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub status: Option<FlowCollectorConsolePluginAutoscalerStatus>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetrics {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "containerResource")]
    pub container_resource: Option<FlowCollectorConsolePluginAutoscalerMetricsContainerResource>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub external: Option<FlowCollectorConsolePluginAutoscalerMetricsExternal>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub object: Option<FlowCollectorConsolePluginAutoscalerMetricsObject>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub pods: Option<FlowCollectorConsolePluginAutoscalerMetricsPods>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resource: Option<FlowCollectorConsolePluginAutoscalerMetricsResource>,
    #[serde(rename = "type")]
    pub r#type: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsContainerResource {
    pub container: String,
    pub name: String,
    pub target: FlowCollectorConsolePluginAutoscalerMetricsContainerResourceTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsContainerResourceTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsExternal {
    pub metric: FlowCollectorConsolePluginAutoscalerMetricsExternalMetric,
    pub target: FlowCollectorConsolePluginAutoscalerMetricsExternalTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsExternalMetric {
    pub name: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selector: Option<FlowCollectorConsolePluginAutoscalerMetricsExternalMetricSelector>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsExternalMetricSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAutoscalerMetricsExternalMetricSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsExternalMetricSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsExternalTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsObject {
    #[serde(rename = "describedObject")]
    pub described_object: FlowCollectorConsolePluginAutoscalerMetricsObjectDescribedObject,
    pub metric: FlowCollectorConsolePluginAutoscalerMetricsObjectMetric,
    pub target: FlowCollectorConsolePluginAutoscalerMetricsObjectTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsObjectDescribedObject {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiVersion")]
    pub api_version: Option<String>,
    pub kind: String,
    pub name: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsObjectMetric {
    pub name: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selector: Option<FlowCollectorConsolePluginAutoscalerMetricsObjectMetricSelector>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsObjectMetricSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAutoscalerMetricsObjectMetricSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsObjectMetricSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsObjectTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsPods {
    pub metric: FlowCollectorConsolePluginAutoscalerMetricsPodsMetric,
    pub target: FlowCollectorConsolePluginAutoscalerMetricsPodsTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsPodsMetric {
    pub name: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selector: Option<FlowCollectorConsolePluginAutoscalerMetricsPodsMetricSelector>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsPodsMetricSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorConsolePluginAutoscalerMetricsPodsMetricSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsPodsMetricSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsPodsTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsResource {
    pub name: String,
    pub target: FlowCollectorConsolePluginAutoscalerMetricsResourceTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginAutoscalerMetricsResourceTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

/// `autoscaler` [deprecated (*)] spec of a horizontal pod autoscaler to set up for the plugin Deployment.
/// Deprecation notice: managed autoscaler will be removed in a future version. You may configure instead an autoscaler of your choice, and set `spec.consolePlugin.unmanagedReplicas` to `true`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorConsolePluginAutoscalerStatus {
    Disabled,
    Enabled,
}

/// `consolePlugin` defines the settings related to the OpenShift Console plugin, when available.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorConsolePluginImagePullPolicy {
    IfNotPresent,
    Always,
    Never,
}

/// `consolePlugin` defines the settings related to the OpenShift Console plugin, when available.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorConsolePluginLogLevel {
    #[serde(rename = "trace")]
    Trace,
    #[serde(rename = "debug")]
    Debug,
    #[serde(rename = "info")]
    Info,
    #[serde(rename = "warn")]
    Warn,
    #[serde(rename = "error")]
    Error,
    #[serde(rename = "fatal")]
    Fatal,
    #[serde(rename = "panic")]
    Panic,
}

/// `portNaming` defines the configuration of the port-to-service name translation.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginPortNaming {
    /// Enable the console plugin port-to-service name translation
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `portNames` defines additional port names to use in the console,
    /// for example, `portNames: {"3100": "loki"}`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "portNames")]
    pub port_names: Option<BTreeMap<String, String>>,
}

/// `QuickFilter` defines preset configuration for Console's quick filters
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginQuickFilters {
    /// `default` defines whether this filter should be active by default or not
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub default: Option<bool>,
    /// `filter` is a set of keys and values to be set when this filter is selected. Each key can relate to a list of values using a coma-separated string,
    /// for example, `filter: {"src_namespace": "namespace1,namespace2"}`.
    pub filter: BTreeMap<String, String>,
    /// Name of the filter, that is displayed in the Console
    pub name: String,
}

/// `resources`, in terms of compute resources, required by this container.
/// For more information, see <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/.>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginResources {
    /// Claims lists the names of resources, defined in spec.resourceClaims,
    /// that are used by this container.
    /// 
    /// This field depends on the
    /// DynamicResourceAllocation feature gate.
    /// 
    /// This field is immutable. It can only be set for containers.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub claims: Option<Vec<FlowCollectorConsolePluginResourcesClaims>>,
    /// Limits describes the maximum amount of compute resources allowed.
    /// More info: <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub limits: Option<BTreeMap<String, IntOrString>>,
    /// Requests describes the minimum amount of compute resources required.
    /// If Requests is omitted for a container, it defaults to Limits if that is explicitly specified,
    /// otherwise to an implementation-defined value. Requests cannot exceed Limits.
    /// More info: <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub requests: Option<BTreeMap<String, IntOrString>>,
}

/// ResourceClaim references one entry in PodSpec.ResourceClaims.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorConsolePluginResourcesClaims {
    /// Name must match the name of one entry in pod.spec.resourceClaims of
    /// the Pod where this field is used. It makes that resource available
    /// inside a container.
    pub name: String,
    /// Request is the name chosen for a request in the referenced claim.
    /// If empty, everything from the claim is made available, otherwise
    /// only the result of this request.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub request: Option<String>,
}

/// Defines the desired state of the FlowCollector resource.
/// <br><br>
/// *: the mention of "unsupported" or "deprecated" for a feature throughout this document means that this feature
/// is not officially supported by Red Hat. It might have been, for example, contributed by the community
/// and accepted without a formal agreement for maintenance. The product maintainers might provide some support
/// for these features as a best effort only.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorDeploymentModel {
    Service,
    Direct,
    Kafka,
}

/// `FlowCollectorExporter` defines an additional exporter to send enriched flows to.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorExporters {
    /// IPFIX configuration, such as the IP address and port to send enriched IPFIX flows to.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub ipfix: Option<FlowCollectorExportersIpfix>,
    /// Kafka configuration, such as the address and topic, to send enriched flows to.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub kafka: Option<FlowCollectorExportersKafka>,
    /// OpenTelemetry configuration, such as the IP address and port to send enriched logs or metrics to.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "openTelemetry")]
    pub open_telemetry: Option<FlowCollectorExportersOpenTelemetry>,
    /// `type` selects the type of exporters. The available options are `Kafka`, `IPFIX`, and `OpenTelemetry`.
    #[serde(rename = "type")]
    pub r#type: FlowCollectorExportersType,
}

/// IPFIX configuration, such as the IP address and port to send enriched IPFIX flows to.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorExportersIpfix {
    /// EnterpriseID, or Private Enterprise Number (PEN). To date, NetObserv does not own an assigned number,
    /// so it is left open for configuration. The PEN is needed to collect non standard data, such as Kubernetes names,
    /// RTT, etc.
    #[serde(rename = "enterpriseID")]
    pub enterprise_id: i64,
    /// Address of the IPFIX external receiver.
    #[serde(rename = "targetHost")]
    pub target_host: String,
    /// Port for the IPFIX external receiver.
    #[serde(rename = "targetPort")]
    pub target_port: i64,
    /// Transport protocol (`TCP` or `UDP`) to be used for the IPFIX connection, defaults to `TCP`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub transport: Option<FlowCollectorExportersIpfixTransport>,
}

/// IPFIX configuration, such as the IP address and port to send enriched IPFIX flows to.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorExportersIpfixTransport {
    #[serde(rename = "TCP")]
    Tcp,
    #[serde(rename = "UDP")]
    Udp,
}

/// Kafka configuration, such as the address and topic, to send enriched flows to.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorExportersKafka {
    /// Address of the Kafka server
    pub address: String,
    /// SASL authentication configuration. [Unsupported (*)].
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub sasl: Option<FlowCollectorExportersKafkaSasl>,
    /// TLS client configuration. When using TLS, verify that the address matches the Kafka port used for TLS, generally 9093.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<FlowCollectorExportersKafkaTls>,
    /// Kafka topic to use. It must exist. NetObserv does not create it.
    pub topic: String,
}

/// SASL authentication configuration. [Unsupported (*)].
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorExportersKafkaSasl {
    /// Reference to the secret or config map containing the client ID
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clientIDReference")]
    pub client_id_reference: Option<FlowCollectorExportersKafkaSaslClientIdReference>,
    /// Reference to the secret or config map containing the client secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clientSecretReference")]
    pub client_secret_reference: Option<FlowCollectorExportersKafkaSaslClientSecretReference>,
    /// Type of SASL authentication to use, or `Disabled` if SASL is not used
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorExportersKafkaSaslType>,
}

/// Reference to the secret or config map containing the client ID
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorExportersKafkaSaslClientIdReference {
    /// File name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub file: Option<String>,
    /// Name of the config map or secret containing the file.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing the file. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the file reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorExportersKafkaSaslClientIdReferenceType>,
}

/// Reference to the secret or config map containing the client ID
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorExportersKafkaSaslClientIdReferenceType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// Reference to the secret or config map containing the client secret
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorExportersKafkaSaslClientSecretReference {
    /// File name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub file: Option<String>,
    /// Name of the config map or secret containing the file.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing the file. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the file reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorExportersKafkaSaslClientSecretReferenceType>,
}

/// Reference to the secret or config map containing the client secret
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorExportersKafkaSaslClientSecretReferenceType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// SASL authentication configuration. [Unsupported (*)].
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorExportersKafkaSaslType {
    Disabled,
    Plain,
    #[serde(rename = "ScramSHA512")]
    ScramSha512,
}

/// TLS client configuration. When using TLS, verify that the address matches the Kafka port used for TLS, generally 9093.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorExportersKafkaTls {
    /// `caCert` defines the reference of the certificate for the Certificate Authority.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "caCert")]
    pub ca_cert: Option<FlowCollectorExportersKafkaTlsCaCert>,
    /// Enable TLS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `insecureSkipVerify` allows skipping client-side verification of the server certificate.
    /// If set to `true`, the `caCert` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userCert")]
    pub user_cert: Option<FlowCollectorExportersKafkaTlsUserCert>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorExportersKafkaTlsCaCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorExportersKafkaTlsCaCertType>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorExportersKafkaTlsCaCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorExportersKafkaTlsUserCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorExportersKafkaTlsUserCertType>,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorExportersKafkaTlsUserCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// OpenTelemetry configuration, such as the IP address and port to send enriched logs or metrics to.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorExportersOpenTelemetry {
    /// Custom fields mapping to an OpenTelemetry conformant format.
    /// By default, NetObserv format proposal is used: <https://github.com/rhobs/observability-data-model/blob/main/network-observability.md#format-proposal> .
    /// As there is currently no accepted standard for L3 or L4 enriched network logs, you can freely override it with your own.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldsMapping")]
    pub fields_mapping: Option<Vec<FlowCollectorExportersOpenTelemetryFieldsMapping>>,
    /// Headers to add to messages (optional)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub headers: Option<BTreeMap<String, String>>,
    /// OpenTelemetry configuration for logs.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub logs: Option<FlowCollectorExportersOpenTelemetryLogs>,
    /// OpenTelemetry configuration for metrics.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metrics: Option<FlowCollectorExportersOpenTelemetryMetrics>,
    /// Protocol of the OpenTelemetry connection. The available options are `http` and `grpc`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub protocol: Option<FlowCollectorExportersOpenTelemetryProtocol>,
    /// Address of the OpenTelemetry receiver.
    #[serde(rename = "targetHost")]
    pub target_host: String,
    /// Port for the OpenTelemetry receiver.
    #[serde(rename = "targetPort")]
    pub target_port: i64,
    /// TLS client configuration.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<FlowCollectorExportersOpenTelemetryTls>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorExportersOpenTelemetryFieldsMapping {
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub input: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub multiplier: Option<i64>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub output: Option<String>,
}

/// OpenTelemetry configuration for logs.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorExportersOpenTelemetryLogs {
    /// Set `enable` to `true` to send logs to an OpenTelemetry receiver.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
}

/// OpenTelemetry configuration for metrics.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorExportersOpenTelemetryMetrics {
    /// Set `enable` to `true` to send metrics to an OpenTelemetry receiver.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// Specify how often metrics are sent to a collector.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "pushTimeInterval")]
    pub push_time_interval: Option<String>,
}

/// OpenTelemetry configuration, such as the IP address and port to send enriched logs or metrics to.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorExportersOpenTelemetryProtocol {
    #[serde(rename = "http")]
    Http,
    #[serde(rename = "grpc")]
    Grpc,
}

/// TLS client configuration.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorExportersOpenTelemetryTls {
    /// `caCert` defines the reference of the certificate for the Certificate Authority.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "caCert")]
    pub ca_cert: Option<FlowCollectorExportersOpenTelemetryTlsCaCert>,
    /// Enable TLS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `insecureSkipVerify` allows skipping client-side verification of the server certificate.
    /// If set to `true`, the `caCert` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userCert")]
    pub user_cert: Option<FlowCollectorExportersOpenTelemetryTlsUserCert>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorExportersOpenTelemetryTlsCaCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorExportersOpenTelemetryTlsCaCertType>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorExportersOpenTelemetryTlsCaCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorExportersOpenTelemetryTlsUserCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorExportersOpenTelemetryTlsUserCertType>,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorExportersOpenTelemetryTlsUserCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `FlowCollectorExporter` defines an additional exporter to send enriched flows to.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorExportersType {
    Kafka,
    #[serde(rename = "IPFIX")]
    Ipfix,
    OpenTelemetry,
}

/// Kafka configuration, allowing to use Kafka as a broker as part of the flow collection pipeline. Available when the `spec.deploymentModel` is `Kafka`.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorKafka {
    /// Address of the Kafka server
    pub address: String,
    /// SASL authentication configuration. [Unsupported (*)].
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub sasl: Option<FlowCollectorKafkaSasl>,
    /// TLS client configuration. When using TLS, verify that the address matches the Kafka port used for TLS, generally 9093.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<FlowCollectorKafkaTls>,
    /// Kafka topic to use. It must exist. NetObserv does not create it.
    pub topic: String,
}

/// SASL authentication configuration. [Unsupported (*)].
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorKafkaSasl {
    /// Reference to the secret or config map containing the client ID
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clientIDReference")]
    pub client_id_reference: Option<FlowCollectorKafkaSaslClientIdReference>,
    /// Reference to the secret or config map containing the client secret
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clientSecretReference")]
    pub client_secret_reference: Option<FlowCollectorKafkaSaslClientSecretReference>,
    /// Type of SASL authentication to use, or `Disabled` if SASL is not used
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorKafkaSaslType>,
}

/// Reference to the secret or config map containing the client ID
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorKafkaSaslClientIdReference {
    /// File name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub file: Option<String>,
    /// Name of the config map or secret containing the file.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing the file. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the file reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorKafkaSaslClientIdReferenceType>,
}

/// Reference to the secret or config map containing the client ID
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorKafkaSaslClientIdReferenceType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// Reference to the secret or config map containing the client secret
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorKafkaSaslClientSecretReference {
    /// File name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub file: Option<String>,
    /// Name of the config map or secret containing the file.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing the file. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the file reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorKafkaSaslClientSecretReferenceType>,
}

/// Reference to the secret or config map containing the client secret
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorKafkaSaslClientSecretReferenceType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// SASL authentication configuration. [Unsupported (*)].
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorKafkaSaslType {
    Disabled,
    Plain,
    #[serde(rename = "ScramSHA512")]
    ScramSha512,
}

/// TLS client configuration. When using TLS, verify that the address matches the Kafka port used for TLS, generally 9093.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorKafkaTls {
    /// `caCert` defines the reference of the certificate for the Certificate Authority.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "caCert")]
    pub ca_cert: Option<FlowCollectorKafkaTlsCaCert>,
    /// Enable TLS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `insecureSkipVerify` allows skipping client-side verification of the server certificate.
    /// If set to `true`, the `caCert` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userCert")]
    pub user_cert: Option<FlowCollectorKafkaTlsUserCert>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorKafkaTlsCaCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorKafkaTlsCaCertType>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorKafkaTlsCaCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorKafkaTlsUserCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorKafkaTlsUserCertType>,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorKafkaTlsUserCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `loki`, the flow store, client settings.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorLoki {
    /// `advanced` allows setting some aspects of the internal configuration of the Loki clients.
    /// This section is aimed mostly for debugging and fine-grained performance optimizations.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub advanced: Option<FlowCollectorLokiAdvanced>,
    /// Set `enable` to `true` to store flows in Loki.
    /// The Console plugin can use either Loki or Prometheus as a data source for metrics (see also `spec.prometheus.querier`), or both.
    /// Not all queries are transposable from Loki to Prometheus. Hence, if Loki is disabled, some features of the plugin are disabled as well,
    /// such as getting per-pod information or viewing raw flows.
    /// If both Prometheus and Loki are enabled, Prometheus takes precedence and Loki is used as a fallback for queries that Prometheus cannot handle.
    /// If they are both disabled, the Console plugin is not deployed.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// Loki configuration for `LokiStack` mode. This is useful for an easy Loki Operator configuration.
    /// It is ignored for other modes.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "lokiStack")]
    pub loki_stack: Option<FlowCollectorLokiLokiStack>,
    /// Loki configuration for `Manual` mode. This is the most flexible configuration.
    /// It is ignored for other modes.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub manual: Option<FlowCollectorLokiManual>,
    /// Loki configuration for `Microservices` mode.
    /// Use this option when Loki is installed using the microservices deployment mode (<https://grafana.com/docs/loki/latest/fundamentals/architecture/deployment-modes/#microservices-mode).>
    /// It is ignored for other modes.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub microservices: Option<FlowCollectorLokiMicroservices>,
    /// `mode` must be set according to the installation mode of Loki:<br>
    /// - Use `LokiStack` when Loki is managed using the Loki Operator<br>
    /// - Use `Monolithic` when Loki is installed as a monolithic workload<br>
    /// - Use `Microservices` when Loki is installed as microservices, but without Loki Operator<br>
    /// - Use `Manual` if none of the options above match your setup<br>
    pub mode: FlowCollectorLokiMode,
    /// Loki configuration for `Monolithic` mode.
    /// Use this option when Loki is installed using the monolithic deployment mode (<https://grafana.com/docs/loki/latest/fundamentals/architecture/deployment-modes/#monolithic-mode).>
    /// It is ignored for other modes.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub monolithic: Option<FlowCollectorLokiMonolithic>,
    /// `readTimeout` is the maximum console plugin loki query total time limit.
    /// A timeout of zero means no timeout.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "readTimeout")]
    pub read_timeout: Option<String>,
    /// `writeBatchSize` is the maximum batch size (in bytes) of Loki logs to accumulate before sending.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeBatchSize")]
    pub write_batch_size: Option<i64>,
    /// `writeBatchWait` is the maximum time to wait before sending a Loki batch.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeBatchWait")]
    pub write_batch_wait: Option<String>,
    /// `writeTimeout` is the maximum Loki time connection / request limit.
    /// A timeout of zero means no timeout.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeTimeout")]
    pub write_timeout: Option<String>,
}

/// `advanced` allows setting some aspects of the internal configuration of the Loki clients.
/// This section is aimed mostly for debugging and fine-grained performance optimizations.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorLokiAdvanced {
    /// `excludeLabels` is a list of fields to be excluded from the list of Loki labels. [Unsupported (*)].
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "excludeLabels")]
    pub exclude_labels: Option<Vec<String>>,
    /// `staticLabels` is a map of common labels to set on each flow in Loki storage.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "staticLabels")]
    pub static_labels: Option<BTreeMap<String, String>>,
    /// `writeMaxBackoff` is the maximum backoff time for Loki client connection between retries.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeMaxBackoff")]
    pub write_max_backoff: Option<String>,
    /// `writeMaxRetries` is the maximum number of retries for Loki client connections.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeMaxRetries")]
    pub write_max_retries: Option<i32>,
    /// `writeMinBackoff` is the initial backoff time for Loki client connection between retries.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeMinBackoff")]
    pub write_min_backoff: Option<String>,
}

/// Loki configuration for `LokiStack` mode. This is useful for an easy Loki Operator configuration.
/// It is ignored for other modes.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorLokiLokiStack {
    /// Name of an existing LokiStack resource to use.
    pub name: String,
    /// Namespace where this `LokiStack` resource is located. If omitted, it is assumed to be the same as `spec.namespace`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
}

/// Loki configuration for `Manual` mode. This is the most flexible configuration.
/// It is ignored for other modes.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorLokiManual {
    /// `authToken` describes the way to get a token to authenticate to Loki.<br>
    /// - `Disabled` does not send any token with the request.<br>
    /// - `Forward` forwards the user token for authorization.<br>
    /// - `Host` [deprecated (*)] - uses the local pod service account to authenticate to Loki.<br>
    /// When using the Loki Operator, this must be set to `Forward`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "authToken")]
    pub auth_token: Option<FlowCollectorLokiManualAuthToken>,
    /// `ingesterUrl` is the address of an existing Loki ingester service to push the flows to. When using the Loki Operator,
    /// set it to the Loki gateway service with the `network` tenant set in path, for example
    /// <https://loki-gateway-http.netobserv.svc:8080/api/logs/v1/network.>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ingesterUrl")]
    pub ingester_url: Option<String>,
    /// `querierUrl` specifies the address of the Loki querier service.
    /// When using the Loki Operator, set it to the Loki gateway service with the `network` tenant set in path, for example
    /// <https://loki-gateway-http.netobserv.svc:8080/api/logs/v1/network.>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "querierUrl")]
    pub querier_url: Option<String>,
    /// TLS client configuration for Loki status URL.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "statusTls")]
    pub status_tls: Option<FlowCollectorLokiManualStatusTls>,
    /// `statusUrl` specifies the address of the Loki `/ready`, `/metrics` and `/config` endpoints, in case it is different from the
    /// Loki querier URL. If empty, the `querierUrl` value is used.
    /// This is useful to show error messages and some context in the frontend.
    /// When using the Loki Operator, set it to the Loki HTTP query frontend service, for example
    /// <https://loki-query-frontend-http.netobserv.svc:3100/.>
    /// `statusTLS` configuration is used when `statusUrl` is set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "statusUrl")]
    pub status_url: Option<String>,
    /// `tenantID` is the Loki `X-Scope-OrgID` that identifies the tenant for each request.
    /// When using the Loki Operator, set it to `network`, which corresponds to a special tenant mode.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tenantID")]
    pub tenant_id: Option<String>,
    /// TLS client configuration for Loki URL.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<FlowCollectorLokiManualTls>,
}

/// Loki configuration for `Manual` mode. This is the most flexible configuration.
/// It is ignored for other modes.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiManualAuthToken {
    Disabled,
    Host,
    Forward,
}

/// TLS client configuration for Loki status URL.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorLokiManualStatusTls {
    /// `caCert` defines the reference of the certificate for the Certificate Authority.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "caCert")]
    pub ca_cert: Option<FlowCollectorLokiManualStatusTlsCaCert>,
    /// Enable TLS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `insecureSkipVerify` allows skipping client-side verification of the server certificate.
    /// If set to `true`, the `caCert` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userCert")]
    pub user_cert: Option<FlowCollectorLokiManualStatusTlsUserCert>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorLokiManualStatusTlsCaCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorLokiManualStatusTlsCaCertType>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiManualStatusTlsCaCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorLokiManualStatusTlsUserCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorLokiManualStatusTlsUserCertType>,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiManualStatusTlsUserCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// TLS client configuration for Loki URL.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorLokiManualTls {
    /// `caCert` defines the reference of the certificate for the Certificate Authority.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "caCert")]
    pub ca_cert: Option<FlowCollectorLokiManualTlsCaCert>,
    /// Enable TLS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `insecureSkipVerify` allows skipping client-side verification of the server certificate.
    /// If set to `true`, the `caCert` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userCert")]
    pub user_cert: Option<FlowCollectorLokiManualTlsUserCert>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorLokiManualTlsCaCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorLokiManualTlsCaCertType>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiManualTlsCaCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorLokiManualTlsUserCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorLokiManualTlsUserCertType>,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiManualTlsUserCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// Loki configuration for `Microservices` mode.
/// Use this option when Loki is installed using the microservices deployment mode (<https://grafana.com/docs/loki/latest/fundamentals/architecture/deployment-modes/#microservices-mode).>
/// It is ignored for other modes.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorLokiMicroservices {
    /// `ingesterUrl` is the address of an existing Loki ingester service to push the flows to.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ingesterUrl")]
    pub ingester_url: Option<String>,
    /// `querierURL` specifies the address of the Loki querier service.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "querierUrl")]
    pub querier_url: Option<String>,
    /// `tenantID` is the Loki `X-Scope-OrgID` header that identifies the tenant for each request.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tenantID")]
    pub tenant_id: Option<String>,
    /// TLS client configuration for Loki URL.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<FlowCollectorLokiMicroservicesTls>,
}

/// TLS client configuration for Loki URL.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorLokiMicroservicesTls {
    /// `caCert` defines the reference of the certificate for the Certificate Authority.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "caCert")]
    pub ca_cert: Option<FlowCollectorLokiMicroservicesTlsCaCert>,
    /// Enable TLS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `insecureSkipVerify` allows skipping client-side verification of the server certificate.
    /// If set to `true`, the `caCert` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userCert")]
    pub user_cert: Option<FlowCollectorLokiMicroservicesTlsUserCert>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorLokiMicroservicesTlsCaCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorLokiMicroservicesTlsCaCertType>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiMicroservicesTlsCaCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorLokiMicroservicesTlsUserCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorLokiMicroservicesTlsUserCertType>,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiMicroservicesTlsUserCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `loki`, the flow store, client settings.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiMode {
    Manual,
    LokiStack,
    Monolithic,
    Microservices,
}

/// Loki configuration for `Monolithic` mode.
/// Use this option when Loki is installed using the monolithic deployment mode (<https://grafana.com/docs/loki/latest/fundamentals/architecture/deployment-modes/#monolithic-mode).>
/// It is ignored for other modes.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorLokiMonolithic {
    /// Set `installDemoLoki` to `true` to automatically create Loki deployment, service and storage.
    /// This is useful for development and demo purposes. Do not use it in production.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "installDemoLoki")]
    pub install_demo_loki: Option<bool>,
    /// `tenantID` is the Loki `X-Scope-OrgID` header that identifies the tenant for each request.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tenantID")]
    pub tenant_id: Option<String>,
    /// TLS client configuration for Loki URL.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<FlowCollectorLokiMonolithicTls>,
    /// `url` is the unique address of an existing Loki service that points to both the ingester and the querier.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub url: Option<String>,
}

/// TLS client configuration for Loki URL.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorLokiMonolithicTls {
    /// `caCert` defines the reference of the certificate for the Certificate Authority.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "caCert")]
    pub ca_cert: Option<FlowCollectorLokiMonolithicTlsCaCert>,
    /// Enable TLS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `insecureSkipVerify` allows skipping client-side verification of the server certificate.
    /// If set to `true`, the `caCert` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userCert")]
    pub user_cert: Option<FlowCollectorLokiMonolithicTlsUserCert>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorLokiMonolithicTlsCaCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorLokiMonolithicTlsCaCertType>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiMonolithicTlsCaCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorLokiMonolithicTlsUserCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorLokiMonolithicTlsUserCertType>,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorLokiMonolithicTlsUserCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `networkPolicy` defines network policy settings for NetObserv components isolation.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorNetworkPolicy {
    /// `additionalNamespaces` contains additional namespaces allowed to connect to the NetObserv namespace.
    /// It provides flexibility in the network policy configuration, but if you need a more specific
    /// configuration, you can disable it and install your own instead.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "additionalNamespaces")]
    pub additional_namespaces: Option<Vec<String>>,
    /// Deploys network policies on the namespaces used by NetObserv (main and privileged).
    /// These network policies better isolate the NetObserv components to prevent undesired connections from and to them.
    /// This option is enabled by default when using with OVNKubernetes, and disabled otherwise (it has not been tested with other CNIs).
    /// When disabled, you can manually create the network policies for the NetObserv components.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
}

/// `processor` defines the settings of the component that receives the flows from the agent,
/// enriches them, generates metrics, and forwards them to the Loki persistence layer and/or any available exporter.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessor {
    /// `addZone` allows availability zone awareness by labeling flows with their source and destination zones.
    /// This feature requires the "topology.kubernetes.io/zone" label to be set on nodes.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "addZone")]
    pub add_zone: Option<bool>,
    /// `advanced` allows setting some aspects of the internal configuration of the flow processor.
    /// This section is aimed mostly for debugging and fine-grained performance optimizations,
    /// such as `GOGC` and `GOMAXPROCS` environment variables. Set these values at your own risk.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub advanced: Option<FlowCollectorProcessorAdvanced>,
    /// `clusterName` is the name of the cluster to appear in the flows data. This is useful in a multi-cluster context. When using OpenShift, leave empty to make it automatically determined.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "clusterName")]
    pub cluster_name: Option<String>,
    /// `consumerReplicas` defines the number of replicas (pods) to start for `flowlogs-pipeline`, default is 3.
    /// This setting is ignored when `spec.deploymentModel` is `Direct` or when `spec.processor.unmanagedReplicas` is `true`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "consumerReplicas")]
    pub consumer_replicas: Option<i32>,
    /// `deduper` allows you to sample or drop flows identified as duplicates, in order to save on resource usage.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub deduper: Option<FlowCollectorProcessorDeduper>,
    /// `filters` lets you define custom filters to limit the amount of generated flows.
    /// These filters provide more flexibility than the eBPF Agent filters (in `spec.agent.ebpf.flowFilter`), such as allowing to filter by Kubernetes namespace,
    /// but with a lesser improvement in performance.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub filters: Option<Vec<FlowCollectorProcessorFilters>>,
    /// `imagePullPolicy` is the Kubernetes pull policy for the image defined above
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "imagePullPolicy")]
    pub image_pull_policy: Option<FlowCollectorProcessorImagePullPolicy>,
    /// `kafkaConsumerAutoscaler` [deprecated (*)] is the spec of a horizontal pod autoscaler to set up for `flowlogs-pipeline-transformer`, which consumes Kafka messages.
    /// This setting is ignored when Kafka is disabled.
    /// Deprecation notice: managed autoscaler will be removed in a future version. You may configure instead an autoscaler of your choice, and set `spec.processor.unmanagedReplicas` to `true`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kafkaConsumerAutoscaler")]
    pub kafka_consumer_autoscaler: Option<FlowCollectorProcessorKafkaConsumerAutoscaler>,
    /// `kafkaConsumerBatchSize` indicates to the broker the maximum batch size, in bytes, that the consumer accepts. Ignored when not using Kafka. Default: 10MB.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kafkaConsumerBatchSize")]
    pub kafka_consumer_batch_size: Option<i64>,
    /// `kafkaConsumerQueueCapacity` defines the capacity of the internal message queue used in the Kafka consumer client. Ignored when not using Kafka.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kafkaConsumerQueueCapacity")]
    pub kafka_consumer_queue_capacity: Option<i64>,
    /// `kafkaConsumerReplicas` [deprecated (*)] defines the number of replicas (pods) to start for `flowlogs-pipeline-transformer`, which consumes Kafka messages.
    /// This setting is ignored when Kafka is disabled.
    /// Deprecation notice: use `spec.processor.consumerReplicas` instead.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kafkaConsumerReplicas")]
    pub kafka_consumer_replicas: Option<i32>,
    /// `logLevel` of the processor runtime
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "logLevel")]
    pub log_level: Option<FlowCollectorProcessorLogLevel>,
    /// `logTypes` defines the desired record types to generate. Possible values are:<br>
    /// - `Flows` to export regular network flows. This is the default.<br>
    /// - `Conversations` to generate events for started conversations, ended conversations as well as periodic "tick" updates. Note that in this mode, Prometheus metrics are not accurate on long-standing conversations.<br>
    /// - `EndedConversations` to generate only ended conversations events. Note that in this mode, Prometheus metrics are not accurate on long-standing conversations.<br>
    /// - `All` to generate both network flows and all conversations events. It is not recommended due to the impact on resources footprint.<br>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "logTypes")]
    pub log_types: Option<FlowCollectorProcessorLogTypes>,
    /// `Metrics` define the processor configuration regarding metrics
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metrics: Option<FlowCollectorProcessorMetrics>,
    /// Set `multiClusterDeployment` to `true` to enable multi clusters feature. This adds `clusterName` label to flows data
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "multiClusterDeployment")]
    pub multi_cluster_deployment: Option<bool>,
    /// `resources` are the compute resources required by this container.
    /// For more information, see <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resources: Option<FlowCollectorProcessorResources>,
    /// Global configuration managing FlowCollectorSlices custom resources.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "slicesConfig")]
    pub slices_config: Option<FlowCollectorProcessorSlicesConfig>,
    /// `subnetLabels` allows to define custom labels on subnets and IPs or to enable automatic labeling of recognized subnets in OpenShift, which is used to identify cluster external traffic.
    /// When a subnet matches the source or destination IP of a flow, a corresponding field is added: `SrcSubnetLabel` or `DstSubnetLabel`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "subnetLabels")]
    pub subnet_labels: Option<FlowCollectorProcessorSubnetLabels>,
    /// If `unmanagedReplicas` is `true`, the operator will not reconcile `consumerReplicas`. This is useful when using a pod autoscaler.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "unmanagedReplicas")]
    pub unmanaged_replicas: Option<bool>,
}

/// `advanced` allows setting some aspects of the internal configuration of the flow processor.
/// This section is aimed mostly for debugging and fine-grained performance optimizations,
/// such as `GOGC` and `GOMAXPROCS` environment variables. Set these values at your own risk.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvanced {
    /// `conversationEndTimeout` is the time to wait after a network flow is received, to consider the conversation ended.
    /// This delay is ignored when a FIN packet is collected for TCP flows (see `conversationTerminatingTimeout` instead).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "conversationEndTimeout")]
    pub conversation_end_timeout: Option<String>,
    /// `conversationHeartbeatInterval` is the time to wait between "tick" events of a conversation
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "conversationHeartbeatInterval")]
    pub conversation_heartbeat_interval: Option<String>,
    /// `conversationTerminatingTimeout` is the time to wait from detected FIN flag to end a conversation. Only relevant for TCP flows.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "conversationTerminatingTimeout")]
    pub conversation_terminating_timeout: Option<String>,
    /// `dropUnusedFields` [deprecated (*)] this setting is not used anymore.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dropUnusedFields")]
    pub drop_unused_fields: Option<bool>,
    /// `enableKubeProbes` is a flag to enable or disable Kubernetes liveness and readiness probes
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableKubeProbes")]
    pub enable_kube_probes: Option<bool>,
    /// `env` allows passing custom environment variables to underlying components. Useful for passing
    /// some very concrete performance-tuning options, such as `GOGC` and `GOMAXPROCS`, that should not be
    /// publicly exposed as part of the FlowCollector descriptor, as they are only useful
    /// in edge debug or support scenarios.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub env: Option<BTreeMap<String, String>>,
    /// `healthPort` is a collector HTTP port in the Pod that exposes the health check API
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "healthPort")]
    pub health_port: Option<i32>,
    /// Port of the flow collector (host port).
    /// By convention, some values are forbidden. It must be greater than 1024 and different from
    /// 4500, 4789 and 6081.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub port: Option<i32>,
    /// `profilePort` allows setting up a Go pprof profiler listening to this port
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "profilePort")]
    pub profile_port: Option<i32>,
    /// scheduling controls how the pods are scheduled on nodes.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub scheduling: Option<FlowCollectorProcessorAdvancedScheduling>,
    /// Defines secondary networks to be checked for resources identification.
    /// To guarantee a correct identification, indexed values must form an unique identifier across the cluster.
    /// If the same index is used by several resources, those resources might be incorrectly labeled.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "secondaryNetworks")]
    pub secondary_networks: Option<Vec<FlowCollectorProcessorAdvancedSecondaryNetworks>>,
}

/// scheduling controls how the pods are scheduled on nodes.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedScheduling {
    /// If specified, the pod's scheduling constraints. For documentation, refer to <https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling.>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub affinity: Option<FlowCollectorProcessorAdvancedSchedulingAffinity>,
    /// `nodeSelector` allows scheduling of pods only onto nodes that have each of the specified labels.
    /// For documentation, refer to <https://kubernetes.io/docs/concepts/configuration/assign-pod-node/.>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeSelector")]
    pub node_selector: Option<BTreeMap<String, String>>,
    /// If specified, indicates the pod's priority. For documentation, refer to <https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#how-to-use-priority-and-preemption.>
    /// If not specified, default priority is used, or zero if there is no default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "priorityClassName")]
    pub priority_class_name: Option<String>,
    /// `tolerations` is a list of tolerations that allow the pod to schedule onto nodes with matching taints.
    /// For documentation, refer to <https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling.>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tolerations: Option<Vec<FlowCollectorProcessorAdvancedSchedulingTolerations>>,
}

/// If specified, the pod's scheduling constraints. For documentation, refer to <https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling.>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinity {
    /// Describes node affinity scheduling rules for the pod.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nodeAffinity")]
    pub node_affinity: Option<FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinity>,
    /// Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podAffinity")]
    pub pod_affinity: Option<FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinity>,
    /// Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "podAntiAffinity")]
    pub pod_anti_affinity: Option<FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinity>,
}

/// Describes node affinity scheduling rules for the pod.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinity {
    /// The scheduler will prefer to schedule pods to nodes that satisfy
    /// the affinity expressions specified by this field, but it may choose
    /// a node that violates one or more of the expressions. The node that is
    /// most preferred is the one with the greatest sum of weights, i.e.
    /// for each node that meets all of the scheduling requirements (resource
    /// request, requiredDuringScheduling affinity expressions, etc.),
    /// compute a sum by iterating through the elements of this field and adding
    /// "weight" to the sum if the node matches the corresponding matchExpressions; the
    /// node(s) with the highest sum are the most preferred.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    /// If the affinity requirements specified by this field are not met at
    /// scheduling time, the pod will not be scheduled onto the node.
    /// If the affinity requirements specified by this field cease to be met
    /// at some point during pod execution (e.g. due to an update), the system
    /// may or may not try to eventually evict the pod from its node.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution>,
}

/// An empty preferred scheduling term matches all objects with implicit weight 0
/// (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    /// A node selector term, associated with the corresponding weight.
    pub preference: FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference,
    /// Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
    pub weight: i32,
}

/// A node selector term, associated with the corresponding weight.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
    /// A list of node selector requirements by node's labels.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions>>,
    /// A list of node selector requirements by node's fields.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchFields")]
    pub match_fields: Option<Vec<FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// If the affinity requirements specified by this field are not met at
/// scheduling time, the pod will not be scheduled onto the node.
/// If the affinity requirements specified by this field cease to be met
/// at some point during pod execution (e.g. due to an update), the system
/// may or may not try to eventually evict the pod from its node.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    /// Required. A list of node selector terms. The terms are ORed.
    #[serde(rename = "nodeSelectorTerms")]
    pub node_selector_terms: Vec<FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms>,
}

/// A null or empty node selector term matches no objects. The requirements of
/// them are ANDed.
/// The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
    /// A list of node selector requirements by node's labels.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions>>,
    /// A list of node selector requirements by node's fields.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchFields")]
    pub match_fields: Option<Vec<FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A node selector requirement is a selector that contains values, a key, and an operator
/// that relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
    /// The label key that the selector applies to.
    pub key: String,
    /// Represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
    pub operator: String,
    /// An array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. If the operator is Gt or Lt, the values
    /// array must have a single element, which will be interpreted as an integer.
    /// This array is replaced during a strategic merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinity {
    /// The scheduler will prefer to schedule pods to nodes that satisfy
    /// the affinity expressions specified by this field, but it may choose
    /// a node that violates one or more of the expressions. The node that is
    /// most preferred is the one with the greatest sum of weights, i.e.
    /// for each node that meets all of the scheduling requirements (resource
    /// request, requiredDuringScheduling affinity expressions, etc.),
    /// compute a sum by iterating through the elements of this field and adding
    /// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
    /// node(s) with the highest sum are the most preferred.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    /// If the affinity requirements specified by this field are not met at
    /// scheduling time, the pod will not be scheduled onto the node.
    /// If the affinity requirements specified by this field cease to be met
    /// at some point during pod execution (e.g. due to a pod label update), the
    /// system may or may not try to eventually evict the pod from its node.
    /// When there are multiple elements, the lists of nodes corresponding to each
    /// podAffinityTerm are intersected, i.e. all terms must be satisfied.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution>>,
}

/// The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    /// Required. A pod affinity term, associated with the corresponding weight.
    #[serde(rename = "podAffinityTerm")]
    pub pod_affinity_term: FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm,
    /// weight associated with matching the corresponding podAffinityTerm,
    /// in the range 1-100.
    pub weight: i32,
}

/// Required. A pod affinity term, associated with the corresponding weight.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
    /// A label query over a set of resources, in this case pods.
    /// If it's null, this PodAffinityTerm matches with no Pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector>,
    /// MatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
    /// Also, matchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    /// MismatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
    /// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    /// A label query over the set of namespaces that the term applies to.
    /// The term is applied to the union of the namespaces selected by this field
    /// and the ones listed in the namespaces field.
    /// null selector and null or empty namespaces list means "this pod's namespace".
    /// An empty selector ({}) matches all namespaces.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector>,
    /// namespaces specifies a static list of namespace names that the term applies to.
    /// The term is applied to the union of the namespaces listed in this field
    /// and the ones selected by namespaceSelector.
    /// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    /// This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
    /// the labelSelector in the specified namespaces, where co-located is defined as running on a node
    /// whose value of the label with key topologyKey matches that of any node on which any of the
    /// selected pods is running.
    /// Empty topologyKey is not allowed.
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

/// A label query over a set of resources, in this case pods.
/// If it's null, this PodAffinityTerm matches with no Pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A label query over the set of namespaces that the term applies to.
/// The term is applied to the union of the namespaces selected by this field
/// and the ones listed in the namespaces field.
/// null selector and null or empty namespaces list means "this pod's namespace".
/// An empty selector ({}) matches all namespaces.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Defines a set of pods (namely those matching the labelSelector
/// relative to the given namespace(s)) that this pod should be
/// co-located (affinity) or not co-located (anti-affinity) with,
/// where co-located is defined as running on a node whose value of
/// the label with key <topologyKey> matches that of any node on which
/// a pod of the set of pods is running
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    /// A label query over a set of resources, in this case pods.
    /// If it's null, this PodAffinityTerm matches with no Pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector>,
    /// MatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
    /// Also, matchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    /// MismatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
    /// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    /// A label query over the set of namespaces that the term applies to.
    /// The term is applied to the union of the namespaces selected by this field
    /// and the ones listed in the namespaces field.
    /// null selector and null or empty namespaces list means "this pod's namespace".
    /// An empty selector ({}) matches all namespaces.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector>,
    /// namespaces specifies a static list of namespace names that the term applies to.
    /// The term is applied to the union of the namespaces listed in this field
    /// and the ones selected by namespaceSelector.
    /// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    /// This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
    /// the labelSelector in the specified namespaces, where co-located is defined as running on a node
    /// whose value of the label with key topologyKey matches that of any node on which any of the
    /// selected pods is running.
    /// Empty topologyKey is not allowed.
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

/// A label query over a set of resources, in this case pods.
/// If it's null, this PodAffinityTerm matches with no Pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A label query over the set of namespaces that the term applies to.
/// The term is applied to the union of the namespaces selected by this field
/// and the ones listed in the namespaces field.
/// null selector and null or empty namespaces list means "this pod's namespace".
/// An empty selector ({}) matches all namespaces.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinity {
    /// The scheduler will prefer to schedule pods to nodes that satisfy
    /// the anti-affinity expressions specified by this field, but it may choose
    /// a node that violates one or more of the expressions. The node that is
    /// most preferred is the one with the greatest sum of weights, i.e.
    /// for each node that meets all of the scheduling requirements (resource
    /// request, requiredDuringScheduling anti-affinity expressions, etc.),
    /// compute a sum by iterating through the elements of this field and subtracting
    /// "weight" from the sum if the node has pods which matches the corresponding podAffinityTerm; the
    /// node(s) with the highest sum are the most preferred.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "preferredDuringSchedulingIgnoredDuringExecution")]
    pub preferred_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution>>,
    /// If the anti-affinity requirements specified by this field are not met at
    /// scheduling time, the pod will not be scheduled onto the node.
    /// If the anti-affinity requirements specified by this field cease to be met
    /// at some point during pod execution (e.g. due to a pod label update), the
    /// system may or may not try to eventually evict the pod from its node.
    /// When there are multiple elements, the lists of nodes corresponding to each
    /// podAffinityTerm are intersected, i.e. all terms must be satisfied.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requiredDuringSchedulingIgnoredDuringExecution")]
    pub required_during_scheduling_ignored_during_execution: Option<Vec<FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution>>,
}

/// The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
    /// Required. A pod affinity term, associated with the corresponding weight.
    #[serde(rename = "podAffinityTerm")]
    pub pod_affinity_term: FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm,
    /// weight associated with matching the corresponding podAffinityTerm,
    /// in the range 1-100.
    pub weight: i32,
}

/// Required. A pod affinity term, associated with the corresponding weight.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
    /// A label query over a set of resources, in this case pods.
    /// If it's null, this PodAffinityTerm matches with no Pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector>,
    /// MatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
    /// Also, matchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    /// MismatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
    /// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    /// A label query over the set of namespaces that the term applies to.
    /// The term is applied to the union of the namespaces selected by this field
    /// and the ones listed in the namespaces field.
    /// null selector and null or empty namespaces list means "this pod's namespace".
    /// An empty selector ({}) matches all namespaces.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector>,
    /// namespaces specifies a static list of namespace names that the term applies to.
    /// The term is applied to the union of the namespaces listed in this field
    /// and the ones selected by namespaceSelector.
    /// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    /// This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
    /// the labelSelector in the specified namespaces, where co-located is defined as running on a node
    /// whose value of the label with key topologyKey matches that of any node on which any of the
    /// selected pods is running.
    /// Empty topologyKey is not allowed.
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

/// A label query over a set of resources, in this case pods.
/// If it's null, this PodAffinityTerm matches with no Pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A label query over the set of namespaces that the term applies to.
/// The term is applied to the union of the namespaces selected by this field
/// and the ones listed in the namespaces field.
/// null selector and null or empty namespaces list means "this pod's namespace".
/// An empty selector ({}) matches all namespaces.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermNamespaceSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// Defines a set of pods (namely those matching the labelSelector
/// relative to the given namespace(s)) that this pod should be
/// co-located (affinity) or not co-located (anti-affinity) with,
/// where co-located is defined as running on a node whose value of
/// the label with key <topologyKey> matches that of any node on which
/// a pod of the set of pods is running
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
    /// A label query over a set of resources, in this case pods.
    /// If it's null, this PodAffinityTerm matches with no Pods.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "labelSelector")]
    pub label_selector: Option<FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector>,
    /// MatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
    /// Also, matchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabelKeys")]
    pub match_label_keys: Option<Vec<String>>,
    /// MismatchLabelKeys is a set of pod label keys to select which pods will
    /// be taken into consideration. The keys are used to lookup values from the
    /// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
    /// to select the group of existing pods which pods will be taken into consideration
    /// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
    /// pod labels will be ignored. The default value is empty.
    /// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
    /// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "mismatchLabelKeys")]
    pub mismatch_label_keys: Option<Vec<String>>,
    /// A label query over the set of namespaces that the term applies to.
    /// The term is applied to the union of the namespaces selected by this field
    /// and the ones listed in the namespaces field.
    /// null selector and null or empty namespaces list means "this pod's namespace".
    /// An empty selector ({}) matches all namespaces.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespaceSelector")]
    pub namespace_selector: Option<FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector>,
    /// namespaces specifies a static list of namespace names that the term applies to.
    /// The term is applied to the union of the namespaces listed in this field
    /// and the ones selected by namespaceSelector.
    /// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespaces: Option<Vec<String>>,
    /// This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
    /// the labelSelector in the specified namespaces, where co-located is defined as running on a node
    /// whose value of the label with key topologyKey matches that of any node on which any of the
    /// selected pods is running.
    /// Empty topologyKey is not allowed.
    #[serde(rename = "topologyKey")]
    pub topology_key: String,
}

/// A label query over a set of resources, in this case pods.
/// If it's null, this PodAffinityTerm matches with no Pods.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// A label query over the set of namespaces that the term applies to.
/// The term is applied to the union of the namespaces selected by this field
/// and the ones listed in the namespaces field.
/// null selector and null or empty namespaces list means "this pod's namespace".
/// An empty selector ({}) matches all namespaces.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelector {
    /// matchExpressions is a list of label selector requirements. The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions>>,
    /// matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
    /// map is equivalent to an element of matchExpressions, whose key field is "key", the
    /// operator is "In", and the values array contains only "value". The requirements are ANDed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

/// A label selector requirement is a selector that contains values, a key, and an operator that
/// relates the key and values.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionNamespaceSelectorMatchExpressions {
    /// key is the label key that the selector applies to.
    pub key: String,
    /// operator represents a key's relationship to a set of values.
    /// Valid operators are In, NotIn, Exists and DoesNotExist.
    pub operator: String,
    /// values is an array of string values. If the operator is In or NotIn,
    /// the values array must be non-empty. If the operator is Exists or DoesNotExist,
    /// the values array must be empty. This array is replaced during a strategic
    /// merge patch.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

/// The pod this Toleration is attached to tolerates any taint that matches
/// the triple <key,value,effect> using the matching operator <operator>.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSchedulingTolerations {
    /// Effect indicates the taint effect to match. Empty means match all taint effects.
    /// When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub effect: Option<String>,
    /// Key is the taint key that the toleration applies to. Empty means match all taint keys.
    /// If the key is empty, operator must be Exists; this combination means to match all values and all keys.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub key: Option<String>,
    /// Operator represents a key's relationship to the value.
    /// Valid operators are Exists and Equal. Defaults to Equal.
    /// Exists is equivalent to wildcard for value, so that a pod can
    /// tolerate all taints of a particular category.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub operator: Option<String>,
    /// TolerationSeconds represents the period of time the toleration (which must be
    /// of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,
    /// it is not set, which means tolerate the taint forever (do not evict). Zero and
    /// negative values will be treated as 0 (evict immediately) by the system.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tolerationSeconds")]
    pub toleration_seconds: Option<i64>,
    /// Value is the taint value the toleration matches to.
    /// If the operator is Exists, the value should be empty, otherwise just a regular string.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorAdvancedSecondaryNetworks {
    /// `index` is a list of fields to use for indexing the pods. They should form a unique Pod identifier across the cluster.
    /// Can be any of: `MAC`, `IP`, `Interface`.
    /// Fields absent from the 'k8s.v1.cni.cncf.io/network-status' annotation must not be added to the index.
    pub index: Vec<String>,
    /// `name` should match the network name as visible in the pods annotation 'k8s.v1.cni.cncf.io/network-status'.
    pub name: String,
}

/// `deduper` allows you to sample or drop flows identified as duplicates, in order to save on resource usage.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorDeduper {
    /// Set the Processor de-duplication mode. It comes in addition to the Agent-based deduplication, since the Agent cannot de-duplicate same flows reported from different nodes.<br>
    /// - Use `Drop` to drop every flow considered as duplicates, allowing saving more on resource usage but potentially losing some information such as the network interfaces used from peer, or network events.<br>
    /// - Use `Sample` to randomly keep only one flow on 50, which is the default, among the ones considered as duplicates. This is a compromise between dropping every duplicate or keeping every duplicate. This sampling action comes in addition to the Agent-based sampling. If both Agent and Processor sampling values are `50`, the combined sampling is 1:2500.<br>
    /// - Use `Disabled` to turn off Processor-based de-duplication.<br>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub mode: Option<FlowCollectorProcessorDeduperMode>,
    /// `sampling` is the sampling interval when deduper `mode` is `Sample`. For example, a value of `50` means that 1 flow in 50 is sampled.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub sampling: Option<i32>,
}

/// `deduper` allows you to sample or drop flows identified as duplicates, in order to save on resource usage.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorDeduperMode {
    Disabled,
    Drop,
    Sample,
}

/// `FLPFilterSet` defines the desired configuration for FLP-based filtering satisfying all conditions.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorFilters {
    /// If specified, these filters target a single output: `Loki`, `Metrics` or `Exporters`. By default, all outputs are targeted.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "outputTarget")]
    pub output_target: Option<FlowCollectorProcessorFiltersOutputTarget>,
    /// A query that selects the network flows to keep. More information about this query language in <https://github.com/netobserv/flowlogs-pipeline/blob/main/docs/filtering.md.>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub query: Option<String>,
    /// `sampling` is an optional sampling interval to apply to this filter. For example, a value of `50` means that 1 matching flow in 50 is sampled.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub sampling: Option<i32>,
}

/// `FLPFilterSet` defines the desired configuration for FLP-based filtering satisfying all conditions.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorFiltersOutputTarget {
    #[serde(rename = "")]
    KopiumEmpty,
    Loki,
    Metrics,
    Exporters,
}

/// `processor` defines the settings of the component that receives the flows from the agent,
/// enriches them, generates metrics, and forwards them to the Loki persistence layer and/or any available exporter.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorImagePullPolicy {
    IfNotPresent,
    Always,
    Never,
}

/// `kafkaConsumerAutoscaler` [deprecated (*)] is the spec of a horizontal pod autoscaler to set up for `flowlogs-pipeline-transformer`, which consumes Kafka messages.
/// This setting is ignored when Kafka is disabled.
/// Deprecation notice: managed autoscaler will be removed in a future version. You may configure instead an autoscaler of your choice, and set `spec.processor.unmanagedReplicas` to `true`.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscaler {
    /// `maxReplicas` is the upper limit for the number of pods that can be set by the autoscaler; cannot be smaller than MinReplicas.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxReplicas")]
    pub max_replicas: Option<i32>,
    /// Metrics used by the pod autoscaler. For documentation, refer to <https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/horizontal-pod-autoscaler-v2/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metrics: Option<Vec<FlowCollectorProcessorKafkaConsumerAutoscalerMetrics>>,
    /// `minReplicas` is the lower limit for the number of replicas to which the autoscaler
    /// can scale down. It defaults to 1 pod. minReplicas is allowed to be 0 if the
    /// alpha feature gate HPAScaleToZero is enabled and at least one Object or External
    /// metric is configured. Scaling is active as long as at least one metric value is
    /// available.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "minReplicas")]
    pub min_replicas: Option<i32>,
    /// `status` describes the desired status regarding deploying an horizontal pod autoscaler.<br>
    /// - `Disabled` does not deploy an horizontal pod autoscaler.<br>
    /// - `Enabled` deploys an horizontal pod autoscaler.<br>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub status: Option<FlowCollectorProcessorKafkaConsumerAutoscalerStatus>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetrics {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "containerResource")]
    pub container_resource: Option<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsContainerResource>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub external: Option<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternal>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub object: Option<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObject>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub pods: Option<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPods>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resource: Option<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsResource>,
    #[serde(rename = "type")]
    pub r#type: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsContainerResource {
    pub container: String,
    pub name: String,
    pub target: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsContainerResourceTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsContainerResourceTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternal {
    pub metric: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternalMetric,
    pub target: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternalTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternalMetric {
    pub name: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selector: Option<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternalMetricSelector>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternalMetricSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternalMetricSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternalMetricSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsExternalTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObject {
    #[serde(rename = "describedObject")]
    pub described_object: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectDescribedObject,
    pub metric: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectMetric,
    pub target: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectDescribedObject {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "apiVersion")]
    pub api_version: Option<String>,
    pub kind: String,
    pub name: String,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectMetric {
    pub name: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selector: Option<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectMetricSelector>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectMetricSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectMetricSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectMetricSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsObjectTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPods {
    pub metric: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPodsMetric,
    pub target: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPodsTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPodsMetric {
    pub name: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub selector: Option<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPodsMetricSelector>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPodsMetricSelector {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchExpressions")]
    pub match_expressions: Option<Vec<FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPodsMetricSelectorMatchExpressions>>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<BTreeMap<String, String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPodsMetricSelectorMatchExpressions {
    pub key: String,
    pub operator: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub values: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsPodsTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsResource {
    pub name: String,
    pub target: FlowCollectorProcessorKafkaConsumerAutoscalerMetricsResourceTarget,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorKafkaConsumerAutoscalerMetricsResourceTarget {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageUtilization")]
    pub average_utilization: Option<i32>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "averageValue")]
    pub average_value: Option<IntOrString>,
    #[serde(rename = "type")]
    pub r#type: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<IntOrString>,
}

/// `kafkaConsumerAutoscaler` [deprecated (*)] is the spec of a horizontal pod autoscaler to set up for `flowlogs-pipeline-transformer`, which consumes Kafka messages.
/// This setting is ignored when Kafka is disabled.
/// Deprecation notice: managed autoscaler will be removed in a future version. You may configure instead an autoscaler of your choice, and set `spec.processor.unmanagedReplicas` to `true`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorKafkaConsumerAutoscalerStatus {
    Disabled,
    Enabled,
}

/// `processor` defines the settings of the component that receives the flows from the agent,
/// enriches them, generates metrics, and forwards them to the Loki persistence layer and/or any available exporter.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorLogLevel {
    #[serde(rename = "trace")]
    Trace,
    #[serde(rename = "debug")]
    Debug,
    #[serde(rename = "info")]
    Info,
    #[serde(rename = "warn")]
    Warn,
    #[serde(rename = "error")]
    Error,
    #[serde(rename = "fatal")]
    Fatal,
    #[serde(rename = "panic")]
    Panic,
}

/// `processor` defines the settings of the component that receives the flows from the agent,
/// enriches them, generates metrics, and forwards them to the Loki persistence layer and/or any available exporter.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorLogTypes {
    Flows,
    Conversations,
    EndedConversations,
    All,
}

/// `Metrics` define the processor configuration regarding metrics
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorMetrics {
    /// `disableAlerts` is a list of alert groups that should be disabled from the default set of alerts.
    /// Possible values are: `NetObservNoFlows`, `NetObservLokiError`, `PacketDropsByKernel`, `PacketDropsByDevice`, `IPsecErrors`, `NetpolDenied`,
    /// `LatencyHighTrend`, `DNSErrors`, `DNSNxDomain`, `ExternalEgressHighTrend`, `ExternalIngressHighTrend`.
    /// More information on alerts: <https://github.com/netobserv/network-observability-operator/blob/main/docs/Alerts.md>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "disableAlerts")]
    pub disable_alerts: Option<Vec<String>>,
    /// `healthRules` is a list of health rules to be created for Prometheus, organized by templates and variants.
    /// Each health rule can be configured to generate either alerts or recording rules based on the mode field.
    /// More information on health rules: <https://github.com/netobserv/network-observability-operator/blob/main/docs/Alerts.md>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "healthRules")]
    pub health_rules: Option<Vec<FlowCollectorProcessorMetricsHealthRules>>,
    /// `includeList` is a list of metric names to specify which ones to generate.
    /// The names correspond to the names in Prometheus without the prefix. For example,
    /// `namespace_egress_packets_total` shows up as `netobserv_namespace_egress_packets_total` in Prometheus.
    /// Note that the more metrics you add, the bigger is the impact on Prometheus workload resources.
    /// Metrics enabled by default are:
    /// `namespace_flows_total`, `node_ingress_bytes_total`, `node_egress_bytes_total`, `workload_ingress_bytes_total`,
    /// `workload_egress_bytes_total`, `namespace_drop_packets_total` (when `PacketDrop` feature is enabled),
    /// `namespace_rtt_seconds` (when `FlowRTT` feature is enabled), `namespace_dns_latency_seconds` (when `DNSTracking` feature is enabled),
    /// `namespace_network_policy_events_total` (when `NetworkEvents` feature is enabled).
    /// More information, with full list of available metrics: <https://github.com/netobserv/network-observability-operator/blob/main/docs/Metrics.md>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "includeList")]
    pub include_list: Option<Vec<String>>,
    /// Metrics server endpoint configuration for Prometheus scraper
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub server: Option<FlowCollectorProcessorMetricsServer>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorMetricsHealthRules {
    /// Mode defines whether this health rule should be generated as an alert or a recording rule.
    /// Possible values are: `Alert` (default), `Recording`.
    /// Recording rules violations are visible in the Network Health dashboard without generating any Prometheus alert.
    /// This provides an alternative way of getting Health information for SRE and cluster admins who may find
    /// many new alerts burdensome.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub mode: Option<FlowCollectorProcessorMetricsHealthRulesMode>,
    /// Health rule template name.
    /// Possible values are: `PacketDropsByKernel`, `PacketDropsByDevice`, `IPsecErrors`, `NetpolDenied`,
    /// `LatencyHighTrend`, `DNSErrors`, `DNSNxDomain`, `ExternalEgressHighTrend`, `ExternalIngressHighTrend`.
    /// Note: `NetObservNoFlows` and `NetObservLokiError` are alert-only and cannot be used as health rules.
    /// More information on health rules: <https://github.com/netobserv/network-observability-operator/blob/main/docs/Alerts.md>
    pub template: FlowCollectorProcessorMetricsHealthRulesTemplate,
    /// A list of variants for this template
    pub variants: Vec<FlowCollectorProcessorMetricsHealthRulesVariants>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorMetricsHealthRulesMode {
    Alert,
    Recording,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorMetricsHealthRulesTemplate {
    PacketDropsByKernel,
    PacketDropsByDevice,
    IPsecErrors,
    NetpolDenied,
    LatencyHighTrend,
    #[serde(rename = "DNSErrors")]
    DnsErrors,
    #[serde(rename = "DNSNxDomain")]
    DnsNxDomain,
    ExternalEgressHighTrend,
    ExternalIngressHighTrend,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorMetricsHealthRulesVariants {
    /// Optional grouping criteria, possible values are: `Node`, `Namespace`, `Workload`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "groupBy")]
    pub group_by: Option<FlowCollectorProcessorMetricsHealthRulesVariantsGroupBy>,
    /// The low volume threshold allows to ignore metrics with a too low volume of traffic, in order to improve signal-to-noise.
    /// It is provided as an absolute rate (bytes per second or packets per second, depending on the context).
    /// When provided, it must be parsable as a float.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "lowVolumeThreshold")]
    pub low_volume_threshold: Option<String>,
    /// Thresholds of the health rule per severity.
    /// They are expressed as a percentage of errors above which the alert is triggered. They must be parsable as floats.
    /// Required for both alert and recording modes
    pub thresholds: FlowCollectorProcessorMetricsHealthRulesVariantsThresholds,
    /// For trending health rules, the duration interval for baseline comparison. For example, "2h" means comparing against a 2-hours average. Defaults to 2h.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "trendDuration")]
    pub trend_duration: Option<String>,
    /// For trending health rules, the time offset for baseline comparison. For example, "1d" means comparing against yesterday. Defaults to 1d.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "trendOffset")]
    pub trend_offset: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorMetricsHealthRulesVariantsGroupBy {
    #[serde(rename = "")]
    KopiumEmpty,
    Node,
    Namespace,
    Workload,
}

/// Thresholds of the health rule per severity.
/// They are expressed as a percentage of errors above which the alert is triggered. They must be parsable as floats.
/// Required for both alert and recording modes
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorMetricsHealthRulesVariantsThresholds {
    /// Threshold for severity `critical`. Leave empty to not generate a Critical alert.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub critical: Option<String>,
    /// Threshold for severity `info`. Leave empty to not generate an Info alert.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub info: Option<String>,
    /// Threshold for severity `warning`. Leave empty to not generate a Warning alert.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub warning: Option<String>,
}

/// Metrics server endpoint configuration for Prometheus scraper
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorMetricsServer {
    /// The metrics server HTTP port.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub port: Option<i32>,
    /// TLS configuration.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<FlowCollectorProcessorMetricsServerTls>,
}

/// TLS configuration.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorProcessorMetricsServerTls {
    /// `insecureSkipVerify` allows skipping client-side verification of the provided certificate.
    /// If set to `true`, the `providedCaFile` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// TLS configuration when `type` is set to `Provided`.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub provided: Option<FlowCollectorProcessorMetricsServerTlsProvided>,
    /// Reference to the CA file when `type` is set to `Provided`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "providedCaFile")]
    pub provided_ca_file: Option<FlowCollectorProcessorMetricsServerTlsProvidedCaFile>,
    /// Select the type of TLS configuration:<br>
    /// - `Disabled` (default) to not configure TLS for the endpoint.
    /// - `Provided` to manually provide cert file and a key file. [Unsupported (*)].
    /// - `Auto` to use OpenShift auto generated certificate using annotations.
    #[serde(rename = "type")]
    pub r#type: FlowCollectorProcessorMetricsServerTlsType,
}

/// TLS configuration when `type` is set to `Provided`.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorMetricsServerTlsProvided {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorProcessorMetricsServerTlsProvidedType>,
}

/// TLS configuration when `type` is set to `Provided`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorMetricsServerTlsProvidedType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// Reference to the CA file when `type` is set to `Provided`.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorMetricsServerTlsProvidedCaFile {
    /// File name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub file: Option<String>,
    /// Name of the config map or secret containing the file.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing the file. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the file reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorProcessorMetricsServerTlsProvidedCaFileType>,
}

/// Reference to the CA file when `type` is set to `Provided`.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorMetricsServerTlsProvidedCaFileType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// TLS configuration.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorMetricsServerTlsType {
    Disabled,
    Provided,
    Auto,
}

/// `resources` are the compute resources required by this container.
/// For more information, see <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorResources {
    /// Claims lists the names of resources, defined in spec.resourceClaims,
    /// that are used by this container.
    /// 
    /// This field depends on the
    /// DynamicResourceAllocation feature gate.
    /// 
    /// This field is immutable. It can only be set for containers.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub claims: Option<Vec<FlowCollectorProcessorResourcesClaims>>,
    /// Limits describes the maximum amount of compute resources allowed.
    /// More info: <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub limits: Option<BTreeMap<String, IntOrString>>,
    /// Requests describes the minimum amount of compute resources required.
    /// If Requests is omitted for a container, it defaults to Limits if that is explicitly specified,
    /// otherwise to an implementation-defined value. Requests cannot exceed Limits.
    /// More info: <https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub requests: Option<BTreeMap<String, IntOrString>>,
}

/// ResourceClaim references one entry in PodSpec.ResourceClaims.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorResourcesClaims {
    /// Name must match the name of one entry in pod.spec.resourceClaims of
    /// the Pod where this field is used. It makes that resource available
    /// inside a container.
    pub name: String,
    /// Request is the name chosen for a request in the referenced claim.
    /// If empty, everything from the claim is made available, otherwise
    /// only the result of this request.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub request: Option<String>,
}

/// Global configuration managing FlowCollectorSlices custom resources.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorSlicesConfig {
    /// `collectionMode` determines how the FlowCollectorSlice custom resources impacts the flow collection process:<br>
    /// - When set to `AlwaysCollect`, all flows are collected regardless of the presence of FlowCollectorSlice.<br>
    /// - When set to `AllowList`, only the flows related to namespaces where a FlowCollectorSlice resource is present, or configured via the global `namespacesAllowList`, are collected.<br>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "collectionMode")]
    pub collection_mode: Option<FlowCollectorProcessorSlicesConfigCollectionMode>,
    /// `enable` determines if the FlowCollectorSlice feature is enabled. If not, all resources of kind FlowCollectorSlice are simply ignored.
    pub enable: bool,
    /// `namespacesAllowList` is a list of namespaces for which flows are always collected, regardless of the presence of FlowCollectorSlice in those namespaces.
    /// An entry enclosed by slashes, such as `/openshift-.*/`, is matched as a regular expression.
    /// This setting is ignored if `collectionMode` is different from `AllowList`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "namespacesAllowList")]
    pub namespaces_allow_list: Option<Vec<String>>,
}

/// Global configuration managing FlowCollectorSlices custom resources.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorProcessorSlicesConfigCollectionMode {
    AlwaysCollect,
    AllowList,
}

/// `subnetLabels` allows to define custom labels on subnets and IPs or to enable automatic labeling of recognized subnets in OpenShift, which is used to identify cluster external traffic.
/// When a subnet matches the source or destination IP of a flow, a corresponding field is added: `SrcSubnetLabel` or `DstSubnetLabel`.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorSubnetLabels {
    /// `customLabels` allows you to customize subnets and IPs labeling, such as to identify cluster external workloads or web services.
    /// External subnets must be labeled with the prefix `EXT:`, or not labeled at all, in order to work with default quick filters and some metrics examples provided.<br/>
    /// If `openShiftAutoDetect` is disabled or you are not using OpenShift, it is recommended to manually configure labels for the cluster subnets, to distinguish internal traffic from external traffic.<br/>
    /// If `openShiftAutoDetect` is enabled, `customLabels` overrides the detected subnets when they overlap.<br/>
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "customLabels")]
    pub custom_labels: Option<Vec<FlowCollectorProcessorSubnetLabelsCustomLabels>>,
    /// `openShiftAutoDetect` allows, when set to `true`, to detect automatically the machines, pods and services subnets based on the
    /// OpenShift install configuration and the Cluster Network Operator configuration. Indirectly, this is a way to accurately detect
    /// external traffic: flows that are not labeled for those subnets are external to the cluster. Enabled by default on OpenShift.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "openShiftAutoDetect")]
    pub open_shift_auto_detect: Option<bool>,
}

/// SubnetLabel allows to label subnets and IPs, such as to identify cluster-external workloads or web services.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorProcessorSubnetLabelsCustomLabels {
    /// List of CIDRs, such as `["1.2.3.4/32"]`.
    pub cidrs: Vec<String>,
    /// Label name, used to flag matching flows.
    pub name: String,
}

/// `prometheus` defines Prometheus settings, such as querier configuration used to fetch metrics from the Console plugin.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorPrometheus {
    /// Prometheus querying configuration, such as client settings, used in the Console plugin.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub querier: Option<FlowCollectorPrometheusQuerier>,
}

/// Prometheus querying configuration, such as client settings, used in the Console plugin.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FlowCollectorPrometheusQuerier {
    /// When `enable` is `true`, the Console plugin queries flow metrics from Prometheus instead of Loki whenever possible.
    /// It is enbaled by default: set it to `false` to disable this feature.
    /// The Console plugin can use either Loki or Prometheus as a data source for metrics (see also `spec.loki`), or both.
    /// Not all queries are transposable from Loki to Prometheus. Hence, if Loki is disabled, some features of the plugin are disabled as well,
    /// such as getting per-pod information or viewing raw flows.
    /// If both Prometheus and Loki are enabled, Prometheus takes precedence and Loki is used as a fallback for queries that Prometheus cannot handle.
    /// If they are both disabled, the Console plugin is not deployed.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// Prometheus configuration for `Manual` mode.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub manual: Option<FlowCollectorPrometheusQuerierManual>,
    /// `mode` must be set according to the type of Prometheus installation that stores NetObserv metrics:<br>
    /// - Use `Auto` to try configuring automatically. In OpenShift, it uses the Thanos querier from OpenShift Cluster Monitoring.<br>
    /// - Use `Manual` for a manual setup.<br>
    pub mode: FlowCollectorPrometheusQuerierMode,
    /// `timeout` is the read timeout for console plugin queries to Prometheus.
    /// A timeout of zero means no timeout.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub timeout: Option<String>,
}

/// Prometheus configuration for `Manual` mode.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorPrometheusQuerierManual {
    /// AlertManager configuration. This is used in the console to query silenced alerts, for displaying health information.
    /// When used in OpenShift it can be left empty to use the Console API instead.
    /// [Unsupported (*)].
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "alertManager")]
    pub alert_manager: Option<FlowCollectorPrometheusQuerierManualAlertManager>,
    /// Set `true` to forward logged in user token in queries to Prometheus
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "forwardUserToken")]
    pub forward_user_token: Option<bool>,
    /// TLS client configuration for Prometheus URL.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<FlowCollectorPrometheusQuerierManualTls>,
    /// `url` is the address of an existing Prometheus service to use for querying metrics.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub url: Option<String>,
}

/// AlertManager configuration. This is used in the console to query silenced alerts, for displaying health information.
/// When used in OpenShift it can be left empty to use the Console API instead.
/// [Unsupported (*)].
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorPrometheusQuerierManualAlertManager {
    /// TLS client configuration for Prometheus AlertManager URL.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tls: Option<FlowCollectorPrometheusQuerierManualAlertManagerTls>,
    /// `url` is the address of an existing Prometheus AlertManager service to use for querying alerts.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub url: Option<String>,
}

/// TLS client configuration for Prometheus AlertManager URL.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorPrometheusQuerierManualAlertManagerTls {
    /// `caCert` defines the reference of the certificate for the Certificate Authority.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "caCert")]
    pub ca_cert: Option<FlowCollectorPrometheusQuerierManualAlertManagerTlsCaCert>,
    /// Enable TLS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `insecureSkipVerify` allows skipping client-side verification of the server certificate.
    /// If set to `true`, the `caCert` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userCert")]
    pub user_cert: Option<FlowCollectorPrometheusQuerierManualAlertManagerTlsUserCert>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorPrometheusQuerierManualAlertManagerTlsCaCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorPrometheusQuerierManualAlertManagerTlsCaCertType>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorPrometheusQuerierManualAlertManagerTlsCaCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorPrometheusQuerierManualAlertManagerTlsUserCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorPrometheusQuerierManualAlertManagerTlsUserCertType>,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorPrometheusQuerierManualAlertManagerTlsUserCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// TLS client configuration for Prometheus URL.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorPrometheusQuerierManualTls {
    /// `caCert` defines the reference of the certificate for the Certificate Authority.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "caCert")]
    pub ca_cert: Option<FlowCollectorPrometheusQuerierManualTlsCaCert>,
    /// Enable TLS
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enable: Option<bool>,
    /// `insecureSkipVerify` allows skipping client-side verification of the server certificate.
    /// If set to `true`, the `caCert` field is ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "insecureSkipVerify")]
    pub insecure_skip_verify: Option<bool>,
    /// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userCert")]
    pub user_cert: Option<FlowCollectorPrometheusQuerierManualTlsUserCert>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorPrometheusQuerierManualTlsCaCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorPrometheusQuerierManualTlsCaCertType>,
}

/// `caCert` defines the reference of the certificate for the Certificate Authority.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorPrometheusQuerierManualTlsCaCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorPrometheusQuerierManualTlsUserCert {
    /// `certFile` defines the path to the certificate file name within the config map or secret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certFile")]
    pub cert_file: Option<String>,
    /// `certKey` defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "certKey")]
    pub cert_key: Option<String>,
    /// Name of the config map or secret containing certificates.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where NetObserv is deployed.
    /// If the namespace is different, the config map or the secret is copied so that it can be mounted as required.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
    /// Type for the certificate reference: `configmap` or `secret`.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<FlowCollectorPrometheusQuerierManualTlsUserCertType>,
}

/// `userCert` defines the user certificate reference and is used for mTLS. When you use one-way TLS, you can ignore this property.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorPrometheusQuerierManualTlsUserCertType {
    #[serde(rename = "configmap")]
    Configmap,
    #[serde(rename = "secret")]
    Secret,
}

/// Prometheus querying configuration, such as client settings, used in the Console plugin.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub enum FlowCollectorPrometheusQuerierMode {
    Manual,
    Auto,
}

/// `FlowCollectorStatus` defines the observed state of FlowCollector
#[derive(Serialize, Deserialize, Clone, Debug, Default, PartialEq)]
pub struct FlowCollectorStatus {
    /// `conditions` represents the latest available observations of an object's state
    pub conditions: Vec<Condition>,
    /// Namespace where console plugin and flowlogs-pipeline have been deployed.
    /// Deprecated: annotations are used instead
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub namespace: Option<String>,
}

